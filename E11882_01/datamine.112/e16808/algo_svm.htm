<!DOCTYPE html>
<html lang="en" >
<head>
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta charset="utf-8">
<title>Support Vector Machines</title>
<meta name="generator" content="Oracle DARB XHTML Converter (Mode = document) - Version 5.1.2 Build 735" />
<meta name="dcterms.created" content="2013-06-29T13:13:17Z" />
<meta name="robots" content="all" />
<meta name="dcterms.title" content="Data Mining Concepts" />
<meta name="dcterms.identifier" content="E16808-07" />
<meta name="dcterms.isVersionOf" content="DMCON" />
<meta name="dcterms.rights" content="Copyright&nbsp;&copy;&nbsp;2005, 2013,&nbsp;Oracle&nbsp;and/or&nbsp;its&nbsp;affiliates.&nbsp;All&nbsp;rights&nbsp;reserved." />
<link rel="Start" href="../../index.htm" title="Home" type="text/html" />
<link rel="Copyright" href="../../dcommon/html/cpyr.htm" title="Copyright" type="text/html" />

<script type="application/javascript"  src="../../dcommon/js/headfoot.js"></script>
<script type="application/javascript"  src="../../nav/js/doccd.js"></script>
<link rel="Contents" href="toc.htm" title="Contents" type="text/html" />
<link rel="Index" href="index.htm" title="Index" type="text/html" />
<link rel="Glossary" href="glossary.htm" title="Glossary" type="text/html" />
<link rel="Prev" href="algo_oc.htm" title="Previous" type="text/html" />
<link rel="Next" href="part4.htm" title="Next" type="text/html" />
<link rel="alternate" href="../e16808.pdf" title="PDF version" type="application/pdf" />
<link rel="schema.dcterms" href="http://purl.org/dc/terms/" />
<link rel="stylesheet" href="../../dcommon/css/fusiondoc.css">
<link rel="stylesheet" type="text/css"  href="../../dcommon/css/header.css">
<link rel="stylesheet" type="text/css"  href="../../dcommon/css/footer.css">
<link rel="stylesheet" type="text/css"  href="../../dcommon/css/fonts.css">
<link rel="stylesheet" href="../../dcommon/css/foundation.css">
<link rel="stylesheet" href="../../dcommon/css/codemirror.css">
<link rel="stylesheet" type="text/css" title="Default" href="../../nav/css/html5.css">
<link rel="stylesheet" href="../../dcommon/css/respond-480-tablet.css">
<link rel="stylesheet" href="../../dcommon/css/respond-768-laptop.css">
<link rel="stylesheet" href="../../dcommon/css/respond-1140-deskop.css">
<script type="application/javascript" src="../../dcommon/js/modernizr.js"></script>
<script type="application/javascript" src="../../dcommon/js/codemirror.js"></script>
<script type="application/javascript" src="../../dcommon/js/jquery.js"></script>
<script type="application/javascript" src="../../dcommon/js/foundation.min.js"></script>
<script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-552992c80ef99c8d" async="async"></script>
<script type="application/javascript" src="../../dcommon/js/jqfns.js"></script>
<script type="application/javascript" src="../../dcommon/js/ohc-inline-videos.js"></script>
<!-- Add fancyBox -->
<link rel="stylesheet" href="../../dcommon/fancybox/jquery.fancybox.css?v=2.1.5" type="text/css" media="screen" />
<script type="text/javascript" src="../../dcommon/fancybox/jquery.fancybox.pack.js?v=2.1.5"></script>
<!-- Optionally add helpers - button, thumbnail and/or media -->
<link rel="stylesheet"  href="../../dcommon/fancybox/helpers/jquery.fancybox-buttons.css?v=1.0.5"  type="text/css" media="screen" />
<script type="text/javascript" src="../../dcommon/fancybox/helpers/jquery.fancybox-buttons.js?v=1.0.5"></script>
<script type="text/javascript" src="../../dcommon/fancybox/helpers/jquery.fancybox-media.js?v=1.0.6"></script>
<link rel="stylesheet"  href="../../dcommon/fancybox/helpers/jquery.fancybox-thumbs.css?v=1.0.7"  type="text/css" media="screen" />
<script type="text/javascript" src="../../dcommon/fancybox/helpers/jquery.fancybox-thumbs.js?v=1.0.7"></script>
</head>
<body>
<a href="#BEGIN" class="accessibility-top skipto" tabindex="0">Go to main content</a><header><!--
<div class="zz-skip-header"><a id="top" href="#BEGIN">Go to main content</a>--></header>
<div class="row" id="CONTENT">
<div class="IND large-9 medium-8 columns" dir="ltr">
<a id="BEGIN" name="BEGIN"></a>
<span id="PAGE" style="display:none;">28/34</span> <!-- End Header -->
<div id="DMCON025" class="chapter"><a id="CHDBDHFB"></a>
<h1 class="chapter"><span class="secnum">18</span> Support Vector Machines</h1>
<p><a id="ABC4413216"></a>This chapter describes <a id="sthref518"></a>Support Vector Machines, a powerful algorithm based on statistical learning theory. Support Vector Machines is implemented by Oracle Data Mining for classification, regression, and anomaly detection.</p>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<p><a href="classify.htm#BABEJGDC">Chapter 5, "Classification"</a></p>
<p><a href="regress.htm#BABGFEJG">Chapter 4, "Regression"</a></p>
<p><a href="anomalies.htm#CIHEGFBB">Chapter 6, "Anomaly Detection"</a></p>
</div>
<div class="infobox-note">
<p class="notep1">Reference:</p>
<p>Milenova, B.L., Yarmus, J.S., Campos, M.M., "SVM in Oracle Database 10<span class="italic">g</span>: Removing the Barriers to Widespread Adoption of Support Vector Machines", Proceedings of the 31st VLDB Conference, Trondheim, Norway, 2005.</p>
<p><code><a href="http://www.oracle.com/technology/products/bi/odm/">http://www.oracle.com/technology/products/bi/odm/</a></code></p>
</div>
<p>This chapter contains the following sections:</p>
<ul>
<li>
<p><a href="#CHDDJFDJ">About Support Vector Machines</a></p>
</li>
<li>
<p><a href="#CHDGHJAE">Tuning an SVM Model</a></p>
</li>
<li>
<p><a href="#i1006563">Data Preparation for SVM</a></p>
</li>
<li>
<p><a href="#CHDDFBBA">SVM Classification</a></p>
</li>
<li>
<p><a href="#CIHDJHHH">One-Class SVM</a></p>
</li>
<li>
<p><a href="#BABCGFGB">SVM Regression</a></p>
</li>
</ul>
<a id="CHDDJFDJ"></a>
<div id="DMCON356" class="sect1"><!-- infolevel="all" infotype="General" -->
<h2 class="sect1">About Support Vector Machines</h2>
<p>Support Vector Machines (SVM) is a powerful, state-of-the-art algorithm with strong theoretical foundations based on the Vapnik-Chervonenkis theory. SVM has strong <span class="bold">regularization</span> properties. Regularization refers to the generalization of the model to new data.</p>
<div id="DMCON357" class="sect2"><a id="sthref519"></a>
<h3 class="sect2">Advantages of SVM</h3>
<p>SVM models have similar functional form to <a id="sthref520"></a>neural networks and <a id="sthref521"></a>radial basis functions, both popular data mining techniques. However, neither of these algorithms has the well-founded theoretical approach to regularization that forms the basis of SVM. The quality of generalization and ease of training of SVM is far beyond the capacities of these more traditional methods.</p>
<p>SVM can model complex, real-world problems such as text and image classification, hand-writing recognition, and bioinformatics and biosequence analysis.</p>
<p>SVM performs well on data sets that have many attributes, even if there are very few cases on which to train the model. There is no upper limit on the number of attributes; the only constraints are those imposed by hardware. Traditional neural nets do not perform well under these circumstances.</p>
</div>
<!-- class="sect2" -->
<div id="DMCON358" class="sect2"><!-- infolevel="all" infotype="General" --><a id="sthref522"></a>
<h3 class="sect2">Advantages of SVM in Oracle Data Mining</h3>
<p>Oracle Data Mining has its own proprietary implementation of SVM, which exploits the many benefits of the algorithm while compensating for some of the limitations inherent in the SVM framework. Oracle Data Mining SVM provides the scalability and usability that are needed in a production quality data mining system.</p>
<div id="DMCON359" class="sect3"><a id="sthref523"></a>
<h4 class="sect3">Usability</h4>
<p>Usability is a major enhancement, because SVM has often been viewed as a tool for experts. The algorithm typically requires data preparation, tuning, and optimization. Oracle Data Mining minimizes these requirements. You do not need to be an expert to build a quality SVM model in Oracle Data Mining. For example:</p>
<ul>
<li>
<p>Data preparation is not required in most cases. (See <a href="#i1006563">"Data Preparation for SVM"</a> .)</p>
</li>
<li>
<p>Default tuning parameters are generally adequate. (See <a href="#CHDGHJAE">"Tuning an SVM Model"</a> .)</p>
</li>
</ul>
</div>
<!-- class="sect3" -->
<div id="DMCON360" class="sect3"><a id="sthref524"></a>
<h4 class="sect3">Scalability</h4>
<p>When dealing with very large data sets, sampling is often required. However, sampling is not required with Oracle Data Mining SVM, because the algorithm itself uses stratified sampling to reduce the size of the training data as needed.</p>
<p>Oracle Data Mining SVM is highly optimized. It builds a model incrementally by optimizing small working sets toward a global solution. The model is trained until convergence on the current working set, then the model adapts to the new data. The process continues iteratively until the convergence conditions are met. The Gaussian kernel uses caching techniques to manage the working sets. See <a href="#BABHDHDC">"Kernel-Based Learning"</a>.</p>
<p>Oracle Data Mining SVM supports <span class="bold">active learning</span>, an optimization method that builds a smaller, more compact model while reducing the time and memory resources required for training the model. See <a href="#BABGCCEG">"Active Learning"</a>.</p>
</div>
<!-- class="sect3" --></div>
<!-- class="sect2" -->
<a id="BABHDHDC"></a>
<div id="DMCON361" class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2">Kernel-Based Learning</h3>
<p>SVM is a kernel-based algorithm. A <span class="bold">kernel</span> is a function that transforms the input data to a high-dimensional space where the problem is solved. Kernel functions can be linear or nonlinear.</p>
<p>Oracle Data Mining supports linear and Gaussian (nonlinear) kernels.</p>
<p>In Oracle Data Mining, the <span class="bold">linear kernel</span> function reduces to a linear equation on the original attributes in the training data. A linear kernel works well when there are many attributes in the training data.</p>
<p>The <span class="bold">Gaussian kernel</span> transforms each case in the training data to a point in an <span class="italic">n</span>-dimensional space, where <span class="italic">n</span> is the number of cases. The algorithm attempts to separate the points into subsets with homogeneous target values. The Gaussian kernel uses nonlinear separators, but within the kernel space it constructs a linear equation.</p>
</div>
<!-- class="sect2" -->
<a id="BABGCCEG"></a>
<div id="DMCON362" class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2">Active Learning</h3>
<p>Active learning is an optimization method for controlling model growth and reducing model build time. Without active learning, SVM m<a id="sthref525"></a>odels grow as the size of the build data set increases, which effectively limits SVM models to small and medium size training sets (less than 100,000 cases). Active learning provides a way to overcome this restriction. With active learning, SVM models can be built on very large training sets.</p>
<p>Active learning forces the SVM algorithm to restrict learning to the most informative training examples and not to attempt to use the entire body of data. In most cases, the resulting models have predictive accuracy comparable to that of a standard (exact) SVM model.</p>
<p>Active learning provides a significant improvement in both linear and Gaussian SVM models, whether for classification, regression, or anomaly detection. However, active learning is especially advantageous for the Gaussian kernel, because nonlinear models can otherwise grow to be very large and can place considerable demands on memory and other system resources.</p>
</div>
<!-- class="sect2" --></div>
<!-- class="sect1" -->
<a id="CHDGHJAE"></a>
<div id="DMCON363" class="sect1"><!-- infolevel="all" infotype="General" -->
<h2 class="sect1">Tuning an SVM Model</h2>
<p>SVM has built-in mechanisms that automatically choose appropriate settings based on the data. You may need to override the system-determined settings for some domains.</p>
<p>The build settings described in <a href="#BABCHGAF">Table 18-1</a> are available for configuring SVM models. Settings pertain to regression, classification, and anomaly detection unless otherwise specified.</p>
<div id="DMCON364" class="tblformal">
<p class="titleintable"><a id="sthref526"></a><a id="BABCHGAF"></a>Table 18-1 Build Settings for Support Vector Machines</p>
<table class="cellalignment1321" title="Build Settings for Support Vector Machines" summary="Build settings for tuning SVM models" dir="ltr">
<thead>
<tr class="cellalignment1312">
<th class="cellalignment1322" id="r1c1-t4">Setting Name</th>
<th class="cellalignment1322" id="r1c2-t4">Configures....</th>
<th class="cellalignment1322" id="r1c3-t4">Description</th>
</tr>
</thead>
<tbody>
<tr class="cellalignment1312">
<td class="cellalignment1318" id="r2c1-t4" headers="r1c1-t4">
<p><code>SVMS_KERNEL_FUNCTION</code></p>
</td>
<td class="cellalignment1318" headers="r2c1-t4 r1c2-t4">
<p>Kernel</p>
</td>
<td class="cellalignment1318" headers="r2c1-t4 r1c3-t4">
<p>Linear or Gaussian. The algorithm automatically uses the kernel function that is most appropriate to the data.</p>
<p>SVM uses the linear kernel when there are many attributes (more than 100) in the training data, otherwise it uses the Gaussian kernel. See <a href="#BABHDHDC">"Kernel-Based Learning"</a>.</p>
<p>The number of attributes does not correspond to the number of columns in the training data. SVM explodes categorical attributes to binary, numeric attributes. In addition, Oracle Data Mining interprets each row in a nested column as a separate attribute. See <a href="#i1006563">"Data Preparation for SVM"</a>.</p>
</td>
</tr>
<tr class="cellalignment1312">
<td class="cellalignment1318" id="r3c1-t4" headers="r1c1-t4">
<p><code>SVMS_STD_DEV</code></p>
</td>
<td class="cellalignment1318" headers="r3c1-t4 r1c2-t4">
<p>Standard deviation for Gaussian kernel</p>
</td>
<td class="cellalignment1318" headers="r3c1-t4 r1c3-t4">
<p>Controls the spread of the Gaussian kernel function.</p>
<p>SVM uses a data-driven approach to find a standard deviation value that is on the same scale as distances between typical cases.</p>
</td>
</tr>
<tr class="cellalignment1312">
<td class="cellalignment1318" id="r4c1-t4" headers="r1c1-t4">
<p><code>SVMS_KERNEL_CACHE_SIZE</code></p>
</td>
<td class="cellalignment1318" headers="r4c1-t4 r1c2-t4">
<p>Cache size for Gaussian kernel</p>
</td>
<td class="cellalignment1318" headers="r4c1-t4 r1c3-t4">
<p>Amount of memory allocated to the Gaussian kernel cache maintained in memory to improve model build time. The default cache size is 50 MB.</p>
</td>
</tr>
<tr class="cellalignment1312">
<td class="cellalignment1318" id="r5c1-t4" headers="r1c1-t4">
<p><code>SVMS_ACTIVE_LEARNING</code></p>
</td>
<td class="cellalignment1318" headers="r5c1-t4 r1c2-t4">
<p>Active learning</p>
</td>
<td class="cellalignment1318" headers="r5c1-t4 r1c3-t4">
<p>Whether or not to use active learning. This setting is especially important for nonlinear (Gaussian) SVM models.</p>
<p>By default, active learning is enabled. See <a href="#BABGCCEG">"Active Learning"</a>.</p>
</td>
</tr>
<tr class="cellalignment1312">
<td class="cellalignment1318" id="r6c1-t4" headers="r1c1-t4">
<p><code>SVMS_COMPLEXITY_FACTOR</code></p>
</td>
<td class="cellalignment1318" headers="r6c1-t4 r1c2-t4">
<p>Complexity factor</p>
</td>
<td class="cellalignment1318" headers="r6c1-t4 r1c3-t4">
<p>Regularization setting that balances the complexity of the model against model robustness to achieve good generalization on new data. SVM uses a data-driven approach to finding the complexity factor.</p>
</td>
</tr>
<tr class="cellalignment1312">
<td class="cellalignment1318" id="r7c1-t4" headers="r1c1-t4">
<p><code>SVMS_CONVERGENCE_TOLERANCE</code></p>
</td>
<td class="cellalignment1318" headers="r7c1-t4 r1c2-t4">
<p>Convergence tolerance</p>
</td>
<td class="cellalignment1318" headers="r7c1-t4 r1c3-t4">
<p>The criterion for completing the model training process. The default is 0.001.</p>
</td>
</tr>
<tr class="cellalignment1312">
<td class="cellalignment1318" id="r8c1-t4" headers="r1c1-t4">
<p><code>SVMS_EPSILON</code></p>
</td>
<td class="cellalignment1318" headers="r8c1-t4 r1c2-t4">
<p>Epsilon factor for regression</p>
</td>
<td class="cellalignment1318" headers="r8c1-t4 r1c3-t4">
<p>Regularization setting for regression, similar to complexity factor. Epsilon specifies the allowable residuals, or noise, in the data.</p>
</td>
</tr>
<tr class="cellalignment1312">
<td class="cellalignment1318" id="r9c1-t4" headers="r1c1-t4">
<p><code>SVMS_OUTLIER_RATE</code></p>
</td>
<td class="cellalignment1318" headers="r9c1-t4 r1c2-t4">
<p>Outliers for anomaly detection</p>
</td>
<td class="cellalignment1318" headers="r9c1-t4 r1c3-t4">
<p>The expected outlier rate in anomaly detection. The default rate is 0.1.</p>
</td>
</tr>
</tbody>
</table>
<br /></div>
<!-- class="tblformal" -->
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<a class="olink ARPLS613" href="../../appdev.112/e40758/d_datmin.htm#ARPLS613"><span class="italic">Oracle Database PL/SQL Packages and Types Reference</span></a> for details about SVM settings</div>
</div>
<!-- class="sect1" -->
<a id="i1006563"></a>
<div id="DMCON365" class="sect1">
<h2 class="sect1">Data Preparation for SVM</h2>
<p>The SVM algorithm operates natively on numeric attributes. The algorithm automatically "explodes" categorical data into a set of binary attributes, one per category value. For example, a character column for marital status with values <code>married</code> or <code>single</code> would be transformed to two numeric attributes: <code>married</code> and <code>single</code>. The new attributes could have the value 1 (true) or 0 (false).</p>
<p>When there are missing values in columns with simple data types (not nested), SVM interprets them as missing at random. The algorithm automatically replaces missing categorical values with the mode and missing numerical values with the mean.</p>
<p>When there are missing values in nested columns, SVM interprets them as sparse. The algorithm automatically replaces sparse numerical data with zeros and sparse categorical data with zero vectors.</p>
<div id="DMCON366" class="sect2"><!-- infolevel="all" infotype="General" --><a id="sthref527"></a>
<h3 class="sect2">Normalization</h3>
<p>SVM requires the normalization of numeric input. Normalization places the values of numeric attributes on the same scale and prevents attributes with a large original scale from biasing the solution. Normalization also minimizes the likelihood of overflows and underflows. Furthermore, normalization brings the numerical attributes to the same scale (0,1) as the exploded categorical data.</p>
</div>
<!-- class="sect2" -->
<div id="DMCON367" class="sect2"><!-- infolevel="all" infotype="General" --><a id="sthref528"></a>
<h3 class="sect2">SVM and Automatic Data Preparation</h3>
<p>The SVM algorithm automatically handles missing value treatment and the transformation of categorical data, but normalization and outlier detection must be handled by ADP or prepared manually. ADP performs min-max normalization for SVM.</p>
<div class="infobox-note">
<p class="notep1">Note:</p>
Oracle recommends that you use Automatic Data Preparation with SVM. The transformations performed by ADP are appropriate for most models.
<p>See <a href="xform_data.htm#BABGADFF">Chapter 19, "Automatic and Embedded Data Preparation"</a>.</p>
</div>
</div>
<!-- class="sect2" --></div>
<!-- class="sect1" -->
<a id="CHDDFBBA"></a>
<div id="DMCON021" class="sect1"><!-- infolevel="all" infotype="General" -->
<h2 class="sect1">SVM Classification</h2>
<p><a id="sthref529"></a><a id="sthref530"></a>SVM classification is based on the concept of decision planes that define decision boundaries. A decision plane is one that separates between a set of objects having different class memberships. SVM finds the vectors ("support vectors") that define the separators giving the widest separation of classes.</p>
<p>SVM classification supports both binary and multiclass targets.</p>
<a id="CHDBHDGF"></a>
<div id="DMCON036" class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2">Class Weights</h3>
<p>In SVM classification, weights are a biasing mechanism for specifying the relative importance of target values (classes).</p>
<p>SVM models are automatically initialized to achieve the best average prediction across all classes. However, if the training data does not represent a realistic distribution, you can bias the model to compensate for class values that are under-represented. If you increase the weight for a class, the percent of correct predictions for that class should increase.</p>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<a href="classify.htm#i1005760">"Priors"</a></div>
</div>
<!-- class="sect2" --></div>
<!-- class="sect1" -->
<a id="CIHDJHHH"></a>
<div id="DMCON027" class="sect1"><!-- infolevel="all" infotype="General" -->
<h2 class="sect1"><a id="sthref531"></a>One-Class SVM</h2>
<p><a id="sthref532"></a>Oracle <a id="sthref533"></a>Data Mining uses SVM as the one-class classifier for anomaly detection. When SVM is used for anomaly detection, it has the classification mining function but no target.</p>
<p>One-class SVM models, when applied, produce a prediction and a probability for each case in the scoring data. If the prediction is 1, the case is considered typical. If the prediction is 0, the case is considered anomalous. This behavior reflects the fact that the model is trained with normal data.</p>
<p>You can specify the percentage of the data that you expect to be anomalous with the <code>SVMS_OUTLIER_RATE</code> build setting. If you have some knowledge that the number of "suspicious" cases is a certain percentage of your population, then you can set the outlier rate to that percentage. The model will identify approximately that many "rare" cases when applied to the general population. The default is 10%, which is probably high for many anomaly detection problems.</p>
</div>
<!-- class="sect1" -->
<a id="BABCGFGB"></a>
<div id="DMCON026" class="sect1"><!-- infolevel="all" infotype="General" -->
<h2 class="sect1">SVM Regression</h2>
<p><a id="sthref534"></a><a id="sthref535"></a>SVM uses an epsilon-insensitive loss function to solve regression problems.</p>
<p>SVM regression tries to find a continuous function such that the maximum number of data points lie within the epsilon-wide insensitivity tube. Predictions falling within epsilon distance of the true target value are not interpreted as errors.</p>
<p><a id="sthref536"></a>The epsilon factor is a regularization setting for SVM regression. It balances the margin of error with model robustness to achieve the best generalization to new data. See <a href="#BABCHGAF">Table 18-1</a> for descriptions of build settings for SVM.</p>
</div>
<!-- class="sect1" --></div>
<!-- class="chapter" --></div>
<!-- class="ind" -->
<!-- Start Footer -->
</div>
<!-- add extra wrapper close div-->
<footer><!--
<hr />
<table class="cellalignment1311">
<tr>
<td class="cellalignment1318">
<table class="cellalignment1316">
<tr>
<td class="cellalignment1315"><a href="algo_oc.htm"><img width="24" height="24" src="../../dcommon/gifs/leftnav.gif" alt="Go to previous page" /><br />
<span class="icon">Previous</span></a></td>
<td class="cellalignment1315"><a href="part4.htm"><img width="24" height="24" src="../../dcommon/gifs/rightnav.gif" alt="Go to next page" /><br />
<span class="icon">Next</span></a></td>
</tr>
</table>
</td>
<td class="cellalignment-copyrightlogo"><img width="144" height="18" src="../../dcommon/gifs/oracle.gif" alt="Oracle" /><br />
Copyright&nbsp;&copy;&nbsp;2005, 2013,&nbsp;Oracle&nbsp;and/or&nbsp;its&nbsp;affiliates.&nbsp;All&nbsp;rights&nbsp;reserved.<br />
<a href="../../dcommon/html/cpyr.htm">Legal Notices</a></td>
<td class="cellalignment1320">
<table class="cellalignment1314">
<tr>
<td class="cellalignment1315"><a href="../../index.htm"><img width="24" height="24" src="../../dcommon/gifs/doclib.gif" alt="Go to Documentation Home" /><br />
<span class="icon">Home</span></a></td>
<td class="cellalignment1315"><a href="../../nav/portal_booklist.htm"><img width="24" height="24" src="../../dcommon/gifs/booklist.gif" alt="Go to Book List" /><br />
<span class="icon">Book List</span></a></td>
<td class="cellalignment1315"><a href="toc.htm"><img width="24" height="24" src="../../dcommon/gifs/toc.gif" alt="Go to Table of Contents" /><br />
<span class="icon">Contents</span></a></td>
<td class="cellalignment1315"><a href="index.htm"><img width="24" height="24" src="../../dcommon/gifs/index.gif" alt="Go to Index" /><br />
<span class="icon">Index</span></a></td>
<td class="cellalignment1315"><a href="../../nav/mindx.htm"><img width="24" height="24" src="../../dcommon/gifs/masterix.gif" alt="Go to Master Index" /><br />
<span class="icon">Master Index</span></a></td>
<td class="cellalignment1315"><a href="../../dcommon/html/feedback.htm"><img width="24" height="24" src="../../dcommon/gifs/feedbck2.gif" alt="Go to Feedback page" /><br />
<span class="icon">Contact Us</span></a></td>
</tr>
</table>
</td>
</tr>
</table>
--></footer>
<noscript>
<p>Scripting on this page enhances content navigation, but does not change the content in any way.</p>
</noscript>
</body>
</html>
