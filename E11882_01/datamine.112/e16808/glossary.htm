<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta charset="utf-8">
<title>Glossary</title>
<meta name="generator" content="Oracle DARB XHTML Converter (Mode = document) - Version 5.1.2 Build 735" />
<meta name="dcterms.created" content="2013-06-29T13:13:17Z" />
<meta name="robots" content="all" />
<meta name="dcterms.title" content="Data Mining Concepts" />
<meta name="dcterms.identifier" content="E16808-07" />
<meta name="dcterms.isVersionOf" content="DMCON" />
<meta name="dcterms.rights" content="Copyright&nbsp;&copy;&nbsp;2005, 2013,&nbsp;Oracle&nbsp;and/or&nbsp;its&nbsp;affiliates.&nbsp;All&nbsp;rights&nbsp;reserved." />
<link rel="Start" href="../../index.htm" title="Home" type="text/html" />
<link rel="Copyright" href="../../dcommon/html/cpyr.htm" title="Copyright" type="text/html" />

<script type="application/javascript"  src="../../dcommon/js/headfoot.js"></script>
<script type="application/javascript"  src="../../nav/js/doccd.js"></script>
<link rel="Contents" href="toc.htm" title="Contents" type="text/html" />
<link rel="Index" href="index.htm" title="Index" type="text/html" />
<link rel="Glossary" href="glossary.htm" title="Glossary" type="text/html" />
<link rel="Prev" href="text.htm" title="Previous" type="text/html" />
<link rel="Next" href="index.htm" title="Next" type="text/html" />
<link rel="alternate" href="../e16808.pdf" title="PDF version" type="application/pdf" />
<link rel="schema.dcterms" href="http://purl.org/dc/terms/" />
<link rel="stylesheet" href="../../dcommon/css/fusiondoc.css">
<link rel="stylesheet" type="text/css"  href="../../dcommon/css/header.css">
<link rel="stylesheet" type="text/css"  href="../../dcommon/css/footer.css">
<link rel="stylesheet" type="text/css"  href="../../dcommon/css/fonts.css">
<link rel="stylesheet" href="../../dcommon/css/foundation.css">
<link rel="stylesheet" href="../../dcommon/css/codemirror.css">
<link rel="stylesheet" type="text/css" title="Default" href="../../nav/css/html5.css">
<link rel="stylesheet" href="../../dcommon/css/respond-480-tablet.css">
<link rel="stylesheet" href="../../dcommon/css/respond-768-laptop.css">
<link rel="stylesheet" href="../../dcommon/css/respond-1140-deskop.css">
<script type="application/javascript" src="../../dcommon/js/modernizr.js"></script>
<script type="application/javascript" src="../../dcommon/js/codemirror.js"></script>
<script type="application/javascript" src="../../dcommon/js/jquery.js"></script>
<script type="application/javascript" src="../../dcommon/js/foundation.min.js"></script>
<script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-552992c80ef99c8d" async="async"></script>
<script type="application/javascript" src="../../dcommon/js/jqfns.js"></script>
<script type="application/javascript" src="../../dcommon/js/ohc-inline-videos.js"></script>
<!-- Add fancyBox -->
<link rel="stylesheet" href="../../dcommon/fancybox/jquery.fancybox.css?v=2.1.5" type="text/css" media="screen" />
<script type="text/javascript" src="../../dcommon/fancybox/jquery.fancybox.pack.js?v=2.1.5"></script>
<!-- Optionally add helpers - button, thumbnail and/or media -->
<link rel="stylesheet"  href="../../dcommon/fancybox/helpers/jquery.fancybox-buttons.css?v=1.0.5"  type="text/css" media="screen" />
<script type="text/javascript" src="../../dcommon/fancybox/helpers/jquery.fancybox-buttons.js?v=1.0.5"></script>
<script type="text/javascript" src="../../dcommon/fancybox/helpers/jquery.fancybox-media.js?v=1.0.6"></script>
<link rel="stylesheet"  href="../../dcommon/fancybox/helpers/jquery.fancybox-thumbs.css?v=1.0.7"  type="text/css" media="screen" />
<script type="text/javascript" src="../../dcommon/fancybox/helpers/jquery.fancybox-thumbs.js?v=1.0.7"></script>
</head>
<body>
<a href="#BEGIN" class="accessibility-top skipto" tabindex="0">Go to main content</a><header><!--
<div class="zz-skip-header"><a id="top" href="#BEGIN">Go to main content</a>--></header>
<div class="row" id="CONTENT">
<div class="IND large-9 medium-8 columns">
<a id="BEGIN" name="BEGIN"></a>
<span id="PAGE" style="display:none;">33/34</span> <!-- End Header -->
<div id="DMCON013" class="glossary"><a id="CHDHICFF"></a>
<h1 class="glossary">Glossary</h1>
<div id="DMCON420" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref629"></a>active learning</p>
<p>A feature of the <a href="#CHDBGHHB"><span class="xrefglossterm">Support Vector Machine</span></a> algorithm that provides a way to deal with large training data sets.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON421" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref630"></a>ADP</p>
<p>See <a href="#CHDGHFED"><span class="xrefglossterm">Automatic Data Transformation</span></a>,</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON422" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref631"></a>aggregation</p>
<p>The process of consolidating data values into a smaller number of values. For example, sales data could be collected on a daily basis and then be totalled to the week level.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON423" class="glossentry">
<p class="glossterm"><a id="sthref632"></a>algorithm</p>
<p>A sequence of steps for solving a problem. See <a href="#CHDIDEJI"><span class="xrefglossterm">data mining algorithm</span></a>. The Oracle Data Mining programmatic interfaces support the following algorithms: <a href="#CHDHCABG"><span class="xrefglossterm">MDL</span></a>, <a href="#CHDBCFCJ"><span class="xrefglossterm">Apriori</span></a>, <a href="#CHDFEGBG"><span class="xrefglossterm">Decision Tree</span></a>, <a href="#CHDHAGDE"><span class="xrefglossterm"><span class="italic">k</span>-Means</span></a>, <a href="#CHDFJBIB"><span class="xrefglossterm">Naive Bayes</span></a>, <a href="#CHDFBDFG"><span class="xrefglossterm">GLM</span></a>, <a href="#CHDEABIE"><span class="xrefglossterm">O-Cluster</span></a>, and <a href="#CHDBGHHB"><span class="xrefglossterm">Support Vector Machine</span></a>.</p>
</div>
<!-- class="glossentry" -->
<a id="i939602"></a>
<div id="DMCON424" class="glossentry">
<p class="glossterm"><a id="sthref633"></a>algorithm settings</p>
<p>The settings that specify algorithm-specific behavior for model building.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON425" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="CHDCDFAB"></a>anomaly detection</p>
<p>The detection of outliers or atypical cases. To build an anomaly detection model using the Data Mining programmatic interfaces, specify classification as the mining function, SVM as the algorithm, and pass a <code>NULL</code> or empty string as the target column name.</p>
</div>
<!-- class="glossentry" -->
<a id="CHDFAHGB"></a>
<div id="DMCON426" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref634"></a>apply</p>
<p>The data mining operation that scores data, that is, uses the model with new data to predict results.</p>
</div>
<!-- class="glossentry" -->
<a id="CHDIJGEC"></a>
<div id="DMCON428" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="CHDBCFCJ"></a>Apriori</p>
<p>Uses frequent itemsets to calculate associations.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON429" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref635"></a>association</p>
<p>A machine learning technique that identifies relationships among items.</p>
</div>
<!-- class="glossentry" -->
<a id="i941197"></a>
<div id="DMCON430" class="glossentry">
<p class="glossterm"><a id="sthref636"></a>association rules</p>
<p>A mining function that captures co-occurrence of items among transactions. A typical rule is an implication of the form A -&gt; B, which means that the presence of itemset A implies the presence of itemset B with certain support and confidence. The support of the rule is the ratio of the number of transactions where the itemsets A and B are present to the total number of transactions. The confidence of the rule is the ratio of the number of transactions where the itemsets A and B are present to the number of transactions where itemset A is present. Oracle Data Mining uses the Apriori algorithm for association models.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON431" class="glossentry">
<p class="glossterm"><a id="CHDDAJAC"></a>attribute</p>
<p>An attribute is a predictor in a predictive model or an item of descriptive information in a descriptive model. <span class="bold">Data attributes</span> are the columns used to build a model. Data attributes undergo transformations so that they can be used as categoricals or numericals by the model. Categoricals and numericals are <span class="bold">model attributes</span>. See also <a href="#CHDFFBBE"><span class="xrefglossterm">target</span></a>.</p>
</div>
<!-- class="glossentry" -->
<a id="i939272"></a>
<div id="DMCON432" class="glossentry">
<p class="glossterm"><a id="CHDBGFDC"></a>attribute importance</p>
<p>A mining function providing a measure of the importance of an attribute in predicting a specified target. The measure of different attributes of a training data table enables users to select the attributes that are found to be most relevant to a mining model. A smaller set of attributes results in a faster model build; the resulting model could be more accurate. Oracle Data Mining uses the <a href="#i939879"><span class="xrefglossterm">Minimum Description Length</span></a> to discover important attributes. Sometimes referred to as <span class="italic">feature selection</span> or <span class="italic">key fields</span>.</p>
</div>
<!-- class="glossentry" -->
<a id="BGBGHGAB"></a>
<div id="DMCON433" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="CHDGHFED"></a>Automatic Data Transformation</p>
<p>Mining models can be created in Automatic Data Preparation (ADP) mode. ADP transforms the build data according to the requirements of the algorithm, embeds the transformation instructions in the model, and uses the instructions to transform the test or scoring data when the model is applied.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON434" class="glossentry">
<p class="glossterm"><a id="sthref637"></a>binning</p>
<p>See <a href="#i939743"><span class="xrefglossterm">discretization</span></a>.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON435" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="BGBIHGBI"></a>build data</p>
<p>Data used to build (train) a model. Also called <span class="italic">training data</span>.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON437" class="glossentry">
<p class="glossterm"><a id="CHDEAGED"></a>case</p>
<p>All the data collected about a specific transaction or related set of values. A data set is a collection of cases. Cases are also called <span class="italic">records</span> or <span class="italic">examples</span>. In the simplest situation, a case corresponds to a row in a table.</p>
</div>
<!-- class="glossentry" -->
<a id="BGBHIEEF"></a>
<div id="DMCON438" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref638"></a>case table</p>
<p>A table or view in single-record case format. All the data for each case is contained in a single row. The case table may include a case ID column that holds a unique identifier for each row. Mining data must be presented as a case table.</p>
</div>
<!-- class="glossentry" -->
<a id="CHDCBJJD"></a>
<div id="DMCON439" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="CHDCIEIC"></a>categorical attribute</p>
<p>An attribute whose values correspond to discrete categories. For example, <span class="italic">state</span> is a categorical attribute with discrete values (CA, NY, MA). Categorical attributes are either non-ordered (nominal) like state or gender, or ordered (ordinal) such as high, medium, or low temperatures.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON441" class="glossentry">
<p class="glossterm"><a id="sthref639"></a>centroid</p>
<p>See <a href="#i939902"><span class="xrefglossterm">cluster centroid</span></a>.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON442" class="glossentry">
<p class="glossterm"><a id="CHDIGDCB"></a>classification</p>
<p>A mining function for predicting categorical target values for new records using a model built from records with known target values. Oracle Data Mining supports the following algorithms for classification: Naive Bayes, Decision Tree, and Support Vector Machines.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON443" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref640"></a>clipping</p>
<p>See <a href="#CHDECFAH"><span class="xrefglossterm">trimming</span></a>.</p>
</div>
<!-- class="glossentry" -->
<a id="i939902"></a>
<div id="DMCON444" class="glossentry">
<p class="glossterm"><a id="sthref641"></a>cluster centroid</p>
<p>The vector that encodes, for each attribute, either the mean (if the attribute is numerical) or the mode (if the attribute is categorical) of the cases in the training data assigned to a cluster. A cluster centroid is often referred to as "the centroid."</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON445" class="glossentry">
<p class="glossterm"><a id="CHDDIGDB"></a>clustering</p>
<p>A mining function for finding naturally occurring groupings in data. More precisely, given a set of data points, each having a set of attributes, and a similarity measure among them, clustering is the process of grouping the data points into different clusters such that data points in the same cluster are more similar to one another and data points in different clusters are less similar to one another. Oracle Data Mining supports two algorithms for clustering, <a href="#CHDHAGDE"><span class="xrefglossterm"><span class="italic">k</span>-Means</span></a> and <a href="#i940912"><span class="xrefglossterm">Orthogonal Partitioning Clustering</span></a>.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON446" class="glossentry">
<p class="glossterm"><a id="sthref642"></a>confusion matrix</p>
<p>Measures the correctness of predictions made by a model from a test task. The row indexes of a confusion matrix correspond to <span class="italic">actual values</span> observed and provided in the test data. The column indexes correspond to <span class="italic">predicted values</span> produced by applying the model to the test data. For any pair of actual/predicted indexes, the value indicates the number of records classified in that pairing.</p>
<p>When predicted value equals actual value, the model produces correct predictions. All other entries indicate errors.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON448" class="glossentry">
<p class="glossterm"><a id="sthref643"></a>cost matrix</p>
<p>An <span class="italic">n</span> by <span class="italic">n</span> table that defines the cost associated with a prediction versus the actual value. A cost matrix is typically used in classification models, where <span class="italic">n</span> is the number of distinct values in the target, and the columns and rows are labeled with target values. The rows are the actual values; the columns are the predicted values.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON449" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref644"></a>counterexample</p>
<p>Negative instance of a target. Counterexamples are required for classification models, except for <a href="#CHDDEHCH"><span class="xrefglossterm">one-class Support Vector Machine</span></a>s.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON450" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref645"></a>data mining</p>
<p>Data mining is the practice of automatically searching large stores of data to discover patterns and trends that go beyond simple analysis. Data mining uses sophisticated mathematical algorithms to segment the data and evaluate the probability of future events. Data mining is also known as <span class="italic">Knowledge Discovery in Data</span> (<a id="sthref646"></a>KDD).</p>
<p>A data mining <span class="italic">model</span> implements a data mining algorithm to solve a given type of problem for a given set of data.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON451" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="CHDIDEJI"></a>data mining algorithm</p>
<p>A specific technique or procedure for producing a data mining model. An algorithm uses a specific data representation and a specific <a href="#CHDDAIHH"><span class="xrefglossterm">mining function</span></a>.</p>
<p>The algorithms in the Oracle Data Mining programming interfaces are <a href="#CHDEDCDI"><span class="xrefglossterm">Naive Bayes</span></a>, <a href="#i940884"><span class="xrefglossterm">Support Vector Machine</span></a>, <a href="#CHDGIFDG"><span class="xrefglossterm">Generalized Linear Model</span></a>, and <a href="#CHDEGEEC"><span class="xrefglossterm">Decision Tree</span></a> for classification; <a href="#i940884"><span class="xrefglossterm">Support Vector Machine</span></a> and <a href="#CHDGIFDG"><span class="xrefglossterm">Generalized Linear Model</span></a> for regression; <a href="#CHDBHIJF"><span class="xrefglossterm"><span class="italic">k</span>-Means</span></a> and <a href="#CHDGIADE"><span class="xrefglossterm">O-Cluster</span></a> for clustering; <a href="#i939879"><span class="xrefglossterm">Minimum Description Length</span></a> for attribute importance; <a href="#CHDGEAAB"><span class="xrefglossterm">Non-Negative Matrix Factorization</span></a> for feature extraction; <a href="#CHDIJGEC"><span class="xrefglossterm">Apriori</span></a> for associations, and <a href="#CHDHBGEB"><span class="xrefglossterm">one-class Support Vector Machine</span></a> for anomaly detection.</p>
</div>
<!-- class="glossentry" -->
<a id="i939265"></a>
<div id="DMCON452" class="glossentry">
<p class="glossterm"><a id="sthref647"></a>data mining server</p>
<p>The component of the Oracle database that implements the data mining engine and persistent metadata repository. You must connect to a data mining server before performing data mining tasks.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON453" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref648"></a>data set</p>
<p>In general, a collection of data. A data set is a collection of <a href="#CHDEAGED"><span class="xrefglossterm">case</span></a>s.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON454" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="CHDJEECF"></a>descriptive model</p>
<p>A descriptive model helps in understanding underlying processes or behavior. For example, an association model describes consumer behavior. See also <a href="#CHDHEHCA"><span class="xrefglossterm">mining model</span></a>.</p>
</div>
<!-- class="glossentry" -->
<a id="i939743"></a>
<div id="DMCON455" class="glossentry">
<p class="glossterm"><a id="sthref649"></a>discretization</p>
<p>Discretization groups related values together under a single value (or bin). This reduces the number of distinct values in a column. Fewer bins result in models that build faster. Many Oracle Data Mining algorithms (for example NB) may benefit from input data that is <span class="italic">discretized</span> prior to model building, testing, computing lift, and applying (scoring). Different algorithms may require different types of binning. Oracle Data Mining includes transformations that perform <a href="#CHDEHABC"><span class="xrefglossterm">top N frequency binning</span></a> for categorical attributes and <a href="#CHDGFAIA"><span class="xrefglossterm">equi-width binning</span></a> and <a href="#CHDFBAAJ"><span class="xrefglossterm">quantile binning</span></a> for numerical attributes.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON456" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref650"></a>distance-based (clustering algorithm)</p>
<p>Distance-based algorithms rely on a distance metric (function) to measure the similarity between data points. Data points are assigned to the nearest cluster according to the distance metric used.</p>
</div>
<!-- class="glossentry" -->
<a id="CHDEGEEC"></a>
<div id="DMCON457" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="CHDFEGBG"></a>Decision Tree</p>
<p>A decision tree is a representation of a classification system or supervised model. The tree is structured as a sequence of questions; the answers to the questions trace a path down the tree to a leaf, which yields the prediction.</p>
<p>Decision trees are a way of representing a series of questions that lead to a class or value. The top node of a decision tree is called the root node; terminal nodes are called leaf nodes. Decision trees are grown through an iterative splitting of data into discrete groups, where the goal is to maximize the distance between groups at each split.</p>
<p>An important characteristic of the decision tree models is that they are transparent; that is, there are rules that explain the classification.</p>
<p>See also <a href="#CHDCGEDE"><span class="xrefglossterm">rule</span></a>.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON458" class="glossentry">
<p class="glossterm"><a id="sthref651"></a>DMS</p>
<p>See <a href="#i939265"><span class="xrefglossterm">data mining server</span></a>.</p>
</div>
<!-- class="glossentry" -->
<a id="CHDGFAIA"></a>
<div id="DMCON459" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref652"></a>equi-width binning</p>
<p>Equi-width binning determines bins for numerical attributes by dividing the range of values into a specified number of bins of equal size.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON460" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref653"></a>explode</p>
<p>For a <a href="#CHDCIEIC"><span class="xrefglossterm">categorical attribute</span></a>, replace a multi-value categorical column with several binary categorical columns. To explode the attribute, create a new binary column for each distinct value that the attribute takes on. In the new columns, 1 indicates that the value of the attribute takes on the value of the column; 0, that it does not. For example, suppose that a categorical attribute takes on the values {1, 2, 3}. To explode this attribute, create three new columns, <code>col_1</code>, <code>col_2</code>, and <code>col_3</code>. If the attribute takes on the value 1, the value in <code>col_1</code> is 1; the values in the other two columns is 0.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON461" class="glossentry">
<p class="glossterm"><a id="sthref654"></a>feature</p>
<p>A combination of attributes in the data that is of special interest and that captures important characteristics of the data. See <a href="#CHDCJAEF"><span class="xrefglossterm">feature extraction</span></a>.</p>
<p>See also <a href="#CHDBFCEF"><span class="xrefglossterm">text feature</span></a>.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON462" class="glossentry">
<p class="glossterm"><a id="CHDCJAEF"></a>feature extraction</p>
<p>Creates a new set of features by decomposing the original data. Feature extraction lets you describe the data with a number of features that is usually far smaller than the number of original attributes. See also <a href="#i941025"><span class="xrefglossterm">Non-Negative Matrix Factorization</span></a>.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON463" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="CHDGIFDG"></a>Generalized Linear Model</p>
<p>A statistical technique for linear modeling. Generalized linear models (GLM) include and extend the class of simple linear models. Oracle Data Mining supports logistic regression for GLM classification and linear regression for GLM regression.</p>
</div>
<!-- class="glossentry" -->
<a id="BGBDAHFF"></a>
<div id="DMCON464" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="CHDFBDFG"></a>GLM</p>
<p>See <a href="#CHDGIFDG"><span class="xrefglossterm">Generalized Linear Model</span></a>.</p>
</div>
<!-- class="glossentry" -->
<a id="CHDBHIJF"></a>
<div id="DMCON467" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="CHDHAGDE"></a><span class="italic">k</span>-Means</p>
<p>A distance-based clustering algorithm that partitions the data into a predetermined number of clusters (provided there are enough distinct cases). Distance-based algorithms rely on a distance metric (function) to measure the similarity between data points. Data points are assigned to the nearest cluster according to the distance metric used. Oracle Data Mining provides an enhanced version of <span class="italic">k</span>-Means.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON468" class="glossentry">
<p class="glossterm"><a id="sthref655"></a>lift</p>
<p>A measure of how much better prediction results are using a model than could be obtained by chance. For example, suppose that 2% of the customers mailed a catalog make a purchase; suppose also that when you use a model to select catalog recipients, 10% make a purchase. Then the lift for the model is 10/2 or 5. Lift may also be used as a measure to compare different data mining models. Since lift is computed using a data table with actual outcomes, lift compares how well a model performs with respect to this data on predicted outcomes. Lift indicates how well the model improved the predictions over a random selection given actual results. Lift allows a user to infer how a model will perform on new data.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON469" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref656"></a>lineage</p>
<p>The sequence of transformations performed on a data set during the data preparation phase of the model build process.</p>
</div>
<!-- class="glossentry" -->
<a id="BGBBCEFG"></a>
<div id="DMCON578" class="glossentry">
<p class="glossterm"><a id="sthref657"></a>linear regression</p>
<p>The <a href="#BGBDAHFF">GLM</a> regression algorithm supported by Oracle Data Mining.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON579" class="glossentry">
<p class="glossterm"><a id="sthref658"></a>logistic regression</p>
<p>The <a href="#BGBDAHFF">GLM</a> classification algorithm supported by Oracle Data Mining.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON470" class="glossentry">
<p class="glossterm"><a id="CHDHCABG"></a>MDL</p>
<p>See <a href="#i939879"><span class="xrefglossterm">Minimum Description Length</span></a>.</p>
</div>
<!-- class="glossentry" -->
<a id="CHDCHCHH"></a>
<div id="DMCON471" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref659"></a>min-max normalization</p>
<p>Normalize numerical attributes using this transformation:</p>
<pre>
 <span class="codeinlineitalic">x_new</span> = (<span class="codeinlineitalic">x_old</span>-min) / (max-min) 
</pre></div>
<!-- class="glossentry" -->
<a id="i939879"></a>
<div id="DMCON472" class="glossentry">
<p class="glossterm"><a id="sthref660"></a>Minimum Description Length</p>
<p>Given a sample of data and an effective enumeration of the appropriate alternative theories to explain the data, the best theory is the one that minimizes the sum of</p>
<ul>
<li>
<p>The length, in bits, of the description of the theory</p>
</li>
<li>
<p>The length, in bits, of the data when encoded with the help of the theory</p>
</li>
</ul>
<p>This principle is used to select the attributes that most influence target value discrimination in <a href="#i939272"><span class="xrefglossterm">attribute importance</span></a>.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON473" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="CHDDAIHH"></a>mining function</p>
<p>A major subdomain of data mining that shares common high level characteristics. The Oracle Data Mining programming interfaces support the following mining functions: <a href="#CHDIGDCB"><span class="xrefglossterm">classification</span></a>, <a href="#CHDIDGBJ"><span class="xrefglossterm">regression</span></a>, <a href="#CHDBGFDC"><span class="xrefglossterm">attribute importance</span></a>, <a href="#CHDCJAEF"><span class="xrefglossterm">feature extraction</span></a>, and <a href="#CHDDIGDB"><span class="xrefglossterm">clustering</span></a>. In both programming interfaces, anomaly detection is supported as classification.</p>
</div>
<!-- class="glossentry" -->
<a id="i939677"></a>
<div id="DMCON474" class="glossentry">
<p class="glossterm"><a id="CHDHEHCA"></a>mining model</p>
<p>An important function of data mining is the production of a model. A model can be a <a href="#i941253"><span class="xrefglossterm">supervised model</span></a> or an <a href="#i940106"><span class="xrefglossterm">unsupervised model</span></a>. Technically, a mining model is the result of building a model from mining settings. The representation of the model is specific to the algorithm specified by the user or selected by the DMS. A model can be used for direct inspection, for example, to examine the rules produced from an association model, or to score data.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON475" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref661"></a>mining object</p>
<p>Mining tasks, models, settings, and their components.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON476" class="glossentry">
<p class="glossterm"><a id="sthref662"></a>mining result</p>
<p>The end product(s) of a mining task. For example, a build task produces a mining model; a test task produces a test result.</p>
</div>
<!-- class="glossentry" -->
<a id="BGBDGGFH"></a>
<div id="DMCON478" class="glossentry">
<p class="glossterm"><a id="sthref663"></a>missing value</p>
<p>A data value that is missing at random. It could be missing because it is unavailable, unknown, or because it was lost. Oracle Data Mining interprets missing values in columns with simple data types (not nested) as missing at random. Oracle Data Mining interprets missing values in nested columns as sparse.</p>
<p>Data mining algorithms vary in the way they treat missing values. There are several typical ways to treat them: ignore them, omit any records containing missing values, replace missing values with the mode or mean, or infer missing values from existing values. See also <a href="#BGBBBAIB"><span class="xrefglossterm">sparse data</span></a>.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON479" class="glossentry">
<p class="glossterm"><a id="sthref664"></a>model</p>
<p>See <a href="#i939677"><span class="xrefglossterm">mining model</span></a>.</p>
</div>
<!-- class="glossentry" -->
<a id="i940957"></a>
<div id="DMCON480" class="glossentry">
<p class="glossterm"><a id="sthref665"></a>multi-record case</p>
<p>Each case in the data table is stored in multiple rows. Also known as <a href="#i939696"><span class="xrefglossterm">transactional data</span></a>. See also <a href="#i940951"><span class="xrefglossterm">single-record case</span></a>.</p>
</div>
<!-- class="glossentry" -->
<a id="CHDEDCDI"></a>
<div id="DMCON481" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="CHDFJBIB"></a>Naive Bayes</p>
<p>An algorithm for classification that is based on Bayes's theorem. Naive Bayes makes the assumption that each attribute is conditionally independent of the others: given a particular value of the target, the distribution of each predictor is independent of the other predictors.</p>
</div>
<!-- class="glossentry" -->
<a id="BGBJDJGF"></a>
<div id="DMCON482" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="BGBCDACA"></a>nested data</p>
<p>Oracle Data Mining supports <a href="#i939696"><span class="xrefglossterm">transactional data</span></a> in nested columns of name/value pairs. Multidimensional data that expresses a one-to-many relationship can be loaded into a nested column and mined along with single-record case data in a <a href="#BGBHIEEF">case table</a>.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON483" class="glossentry">
<p class="glossterm"><a id="sthref666"></a>NMF</p>
<p>See <a href="#i941025"><span class="xrefglossterm">Non-Negative Matrix Factorization</span></a>.</p>
</div>
<!-- class="glossentry" -->
<a id="i941025"></a>
<div id="DMCON484" class="glossentry">
<p class="glossterm"><a id="CHDGEAAB"></a>Non-Negative Matrix Factorization</p>
<p>A feature extraction algorithm that decomposes multivariate data by creating a user-defined number of features, which results in a reduced representation of the original data.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON485" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref667"></a>normalization</p>
<p>Normalization consists of transforming numerical values into a specific range, such as [&ndash;1.0,1.0] or [0.0,1.0] such that <code>x_new = (x_old-shift)/scale</code>. Normalization applies only to numerical attributes. Oracle Data Mining provides transformations that perform <a href="#CHDCHCHH"><span class="xrefglossterm">min-max normalization</span></a>, <a href="#CHDFAAHC"><span class="xrefglossterm">scale normalization</span></a>, and <a href="#CHDEDJJF"><span class="xrefglossterm">z-score normalization</span></a>.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON486" class="glossentry">
<p class="glossterm"><a id="sthref668"></a>numerical attribute</p>
<p>An attribute whose values are numbers. The numeric value can be either an integer or a real number. Numerical attribute values can be manipulated as continuous values. See also <a href="#CHDCBJJD"><span class="xrefglossterm">categorical attribute</span></a>.</p>
</div>
<!-- class="glossentry" -->
<a id="CHDGIADE"></a>
<div id="DMCON487" class="glossentry">
<p class="glossterm"><a id="CHDEABIE"></a>O-Cluster</p>
<p>See <a href="#i940912"><span class="xrefglossterm">Orthogonal Partitioning Clustering</span></a>.</p>
</div>
<!-- class="glossentry" -->
<a id="CHDDEHCH"></a>
<div id="DMCON488" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="CHDHBGEB"></a>one-class Support Vector Machine</p>
<p>The version of the <a href="#i940884"><span class="xrefglossterm">Support Vector Machine</span></a> model used to solve <a href="#CHDCDFAB"><span class="xrefglossterm">anomaly detection</span></a> problems. The Oracle Data Mining programmatic interfaces implement the one-class algorithm as classification.</p>
</div>
<!-- class="glossentry" -->
<a id="i940912"></a>
<div id="DMCON489" class="glossentry">
<p class="glossterm"><a id="sthref669"></a>Orthogonal Partitioning Clustering</p>
<p>An Oracle proprietary clustering algorithm that creates a hierarchical grid-based clustering model, that is, it creates axis-parallel (orthogonal) partitions in the input attribute space. The algorithm operates recursively. The resulting hierarchical structure represents an irregular grid that tessellates the attribute space into clusters.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON490" class="glossentry">
<p class="glossterm"><a id="sthref670"></a>outlier</p>
<p>A data value that does not come from the typical population of data; in other words, extreme values. In a normal distribution, outliers are typically at least 3 standard deviations from the mean.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON492" class="glossentry">
<p class="glossterm"><a id="sthref671"></a>positive target value</p>
<p>In binary classification problems, you may designate one of the two classes (target values) as positive, the other as negative. When Oracle Data Mining computes a model's lift, it calculates the density of positive target values among a set of test instances for which the model predicts positive values with a given degree of confidence.</p>
</div>
<!-- class="glossentry" -->
<a id="CHDGEJHI"></a>
<div id="DMCON493" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="CHDBIBHC"></a>predictive model</p>
<p>A predictive model is an equation or set of rules that makes it possible to predict an unseen or unmeasured value (the dependent variable or output) from other, known values (independent variables or input). The form of the equation or rules is suggested by mining data collected from the process under study. Some training or estimation technique is used to estimate the parameters of the equation or rules. A predictive model is a <a href="#i941253"><span class="xrefglossterm">supervised model</span></a>.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON494" class="glossentry">
<p class="glossterm"><a id="sthref672"></a>predictor</p>
<p>An attribute used as input to a supervised model or algorithm to build a model.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON495" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref673"></a>prepared data</p>
<p>Data that is suitable for model building using a specified algorithm. Data preparation often accounts for much of the time spent in a data mining project. Oracle Data Mining supports transformations binning, normalization, and missing value treatment. Oracle Data Mining can automatically perform algorithm-appropriate transformations when <a href="#BGBGHGAB"><span class="xrefglossterm">Automatic Data Transformation</span></a> is enabled.</p>
</div>
<!-- class="glossentry" -->
<a id="i939183"></a>
<div id="DMCON496" class="glossentry">
<p class="glossterm"><a id="sthref674"></a>prior probabilities</p>
<p>The set of prior probabilities specifies the distribution of examples of the various classes in the original source data. Also referred to as <span class="italic">priors</span>, these could be different from the distribution observed in the data set provided for model build.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON497" class="glossentry">
<p class="glossterm"><a id="sthref675"></a>priors</p>
<p>See <a href="#i939183"><span class="xrefglossterm">prior probabilities</span></a>.</p>
</div>
<!-- class="glossentry" -->
<a id="CHDFBAAJ"></a>
<div id="DMCON498" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref676"></a>quantile binning</p>
<p>A numerical attribute is divided into bins such that each bin contains approximately the same number of cases.</p>
</div>
<!-- class="glossentry" -->
<a id="CHDHDDGC"></a>
<div id="DMCON499" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref677"></a>random sample</p>
<p>A sample in which every element of the data set has an equal chance of being selected.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON500" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref678"></a>recode</p>
<p>Literally "change or rearrange the code." Recoding can be useful in many instances in data mining. Here are some examples:</p>
<ul>
<li>
<p>Missing values treatment: Missing values may be indicated by something other than <code>NULL</code>, such as "0000" or "9999" or "NA" or some other string. One way to treat the missing value is to recode, for example, "0000" to <code>NULL</code>. Then the Oracle Data Mining algorithms and the database recognize the value as missing.</p>
</li>
<li>
<p>Change data type of variable: For example, change "Y" or "Yes" to 1 and "N" or "No" to 0.</p>
</li>
<li>
<p>Establish a cutoff value: For example, recode all incomes less than $20,000 to the same value.</p>
</li>
<li>
<p>Group items: For example, group individual US states into regions. The "New England region" might consist of ME, VT, NH, MA, CT, and RI; to implement this, recode the five states to, say, NE (for New England).</p>
</li>
</ul>
</div>
<!-- class="glossentry" -->
<div id="DMCON501" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref679"></a>record</p>
<p>See <a href="#CHDEAGED"><span class="xrefglossterm">case</span></a>.</p>
</div>
<!-- class="glossentry" -->
<a id="i940182"></a>
<div id="DMCON502" class="glossentry">
<p class="glossterm"><a id="CHDIDGBJ"></a>regression</p>
<p>A data mining function for predicting continuous target values for new records using a model built from records with known target values. Oracle Data Mining supports <a href="#BGBBCEFG"><span class="xrefglossterm">linear regression</span></a> (GLM) and <a href="#i940884"><span class="xrefglossterm">Support Vector Machine</span></a> algorithms for regression.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON503" class="glossentry">
<p class="glossterm"><a id="CHDCGEDE"></a>rule</p>
<p>An expression of the general form <span class="italic">if X, then Y</span>. An output of certain algorithms, such as clustering, association, and decision tree. The predicate <span class="italic">X</span> may be a compound predicate.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON504" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref680"></a>sample</p>
<p>See <a href="#CHDHDDGC"><span class="xrefglossterm">random sample</span></a>.</p>
</div>
<!-- class="glossentry" -->
<a id="CHDFAAHC"></a>
<div id="DMCON505" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref681"></a>scale normalization</p>
<p>Normalize numerical attributes using this transformation:</p>
<pre>
 <span class="italic">x_new</span> = (<span class="italic">x_old</span> - 0) / (max(abs(max),abs(min))) 
</pre></div>
<!-- class="glossentry" -->
<div id="DMCON506" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref682"></a>schema</p>
<p>A collection of objects in an Oracle database, including logical structures such as tables, views, sequences, stored procedures, synonyms, indexes, clusters, and database links. A schema is associated with a specific database user.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON507" class="glossentry">
<p class="glossterm"><a id="sthref683"></a>score</p>
<p>Scoring data means applying a data mining model to data to generate predictions.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON508" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref684"></a>settings</p>
<p>See <a href="#i939602"><span class="xrefglossterm">algorithm settings</span></a>.</p>
</div>
<!-- class="glossentry" -->
<a id="i940951"></a>
<div id="DMCON509" class="glossentry">
<p class="glossterm"><a id="sthref685"></a>single-record case</p>
<p>Each case in the data table is stored in one row. Contrast with <a href="#i940957"><span class="xrefglossterm">multi-record case</span></a>.</p>
</div>
<!-- class="glossentry" -->
<a id="BGBBBAIB"></a>
<div id="DMCON510" class="glossentry">
<p class="glossterm"><a id="sthref686"></a>sparse data</p>
<p>Data for which only a small fraction of the attributes are non-zero or non-null in any given case. Market basket data and text mining data are typically sparse. Oracle Data Mining interprets <a href="#BGBJDJGF">nested data</a> as sparse. See also <a href="#BGBDGGFH"><span class="xrefglossterm">missing value</span></a>.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON511" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref687"></a>split</p>
<p>Divide a data set into several disjoint subsets. For example, in a classification problem, a data set is often divided in to a training data set and a test data set.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON512" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref688"></a>stratified sample</p>
<p>Divide the data set into disjoint subsets (strata) and then take a random sample from each of the subsets. This technique is used when the distribution of target values is skewed greatly. For example, response to a marketing campaign may have a positive target value 1% of the time or less. A stratified sample provides the data mining algorithms with enough positive examples to learn the factors that differentiate positive from negative target values. See also <a href="#CHDHDDGC"><span class="xrefglossterm">random sample</span></a>.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON513" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref689"></a>supermodel</p>
<p>Mining models that contain instructions for their own data preparation. Oracle Data Mining provides <a href="#BGBGHGAB"><span class="xrefglossterm">Automatic Data Transformation</span></a> and embedded data transformation, which together provide support for supermodels.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON514" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref690"></a>supervised learning</p>
<p>See <a href="#CHDHAHDJ"><span class="xrefglossterm">supervised model</span></a>.</p>
</div>
<!-- class="glossentry" -->
<a id="i941253"></a>
<div id="DMCON515" class="glossentry">
<p class="glossterm"><a id="CHDHAHDJ"></a>supervised model</p>
<p>A data mining model that is built using a known dependent variable, also referred to as the target. Classification and regression techniques are examples of supervised mining. See <a href="#i940106"><span class="xrefglossterm">unsupervised model</span></a>. Also referred to as <a href="#CHDGEJHI"><span class="xrefglossterm">predictive model</span></a>.</p>
</div>
<!-- class="glossentry" -->
<a id="i940884"></a>
<div id="DMCON516" class="glossentry">
<p class="glossterm"><a id="CHDBGHHB"></a>Support Vector Machine</p>
<p>An algorithm that uses machine learning theory to maximize predictive accuracy while automatically avoiding over-fit to the data. Support vector machines can make predictions with sparse data, that is, in domains that have a large number of predictor columns and relatively few rows, as is the case with bioinformatics data. Support vector machine can be used for classification, regression, and anomaly detection.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON517" class="glossentry">
<p class="glossterm"><a id="sthref691"></a>SVM</p>
<p>See <a href="#i940884"><span class="xrefglossterm">Support Vector Machine</span></a>.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON518" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref692"></a>table</p>
<p>The basic unit of data storage in an Oracle database. Table data is stored in rows and columns.</p>
</div>
<!-- class="glossentry" -->
<a id="CHDDBGBA"></a>
<div id="DMCON519" class="glossentry">
<p class="glossterm"><a id="CHDFFBBE"></a>target</p>
<p>In supervised learning, the identified attribute that is to be predicted. Sometimes called <span class="italic">target value</span> or <span class="italic">target attribute</span>. See also <a href="#CHDDAJAC"><span class="xrefglossterm">attribute</span></a>.</p>
</div>
<!-- class="glossentry" -->
<a id="CHDBFCEF"></a>
<div id="DMCON522" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref693"></a>text feature</p>
<p>A combination of words that captures important attributes of a document or class of documents. Text features are usually keywords, frequencies of words, or other document-derived features. A document typically contains a large number of words and a much smaller number of features.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON523" class="glossentry">
<p class="glossterm"><a id="sthref694"></a>text mining</p>
<p>Conventional data mining done using text features. Text features are usually keywords, frequencies of words, or other document-derived features. Once you derive text features, you mine them just as you would any other data. Both Oracle Data Mining and Oracle Text support text mining.</p>
</div>
<!-- class="glossentry" -->
<a id="CHDEHABC"></a>
<div id="DMCON524" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref695"></a>top N frequency binning</p>
<p>This type of binning bins categorical attributes. The bin definition for each attribute is computed based on the occurrence frequency of values that are computed from the data. The user specifies a particular number of bins, say N. Each of the bins bin_1,..., bin_N corresponds to the values with top frequencies. The bin bin_N+1 corresponds to all remaining values.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON525" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="BGBFJHFA"></a>training data</p>
<p>See <a href="#BGBIHGBI"><span class="xrefglossterm">build data</span></a>.</p>
</div>
<!-- class="glossentry" -->
<a id="i939696"></a>
<div id="DMCON526" class="glossentry">
<p class="glossterm"><a id="sthref696"></a>transactional data</p>
<p>The data for one case is contained in several rows. An example is market basket data, in which a case represents one basket that contains multiple items. Oracle Data Mining supports transactional data in nested columns of attribute name/value pairs. See also <a href="#BGBCDACA"><span class="xrefglossterm">nested data</span></a>, <a href="#i940957"><span class="xrefglossterm">multi-record case</span></a>, and <a href="#i940951"><span class="xrefglossterm">single-record case</span></a>.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON527" class="glossentry">
<p class="glossterm"><a id="sthref697"></a>transformation</p>
<p>A function applied to data resulting in a new representation of the data. For example, discretization and normalization are transformations on data.</p>
</div>
<!-- class="glossentry" -->
<a id="CHDECFAH"></a>
<div id="DMCON528" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref698"></a>trimming</p>
<p>A technique used for dealing with outliers. Trimming removes values in the tails of a distribution in the sense that trimmed values are ignored in further computations. This is achieved by setting the tails to <code>NULL</code>.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON529" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref699"></a>unstructured data</p>
<p>Images, audio, video, geospatial mapping data, and documents or text data are collectively known as unstructured data. Oracle Data Mining supports the mining of unstructured text data.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON530" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref700"></a>unsupervised learning</p>
<p>See <a href="#CHDIIDJH"><span class="xrefglossterm">unsupervised model</span></a>.</p>
</div>
<!-- class="glossentry" -->
<a id="i940106"></a>
<div id="DMCON531" class="glossentry">
<p class="glossterm"><a id="CHDIIDJH"></a>unsupervised model</p>
<p>A data mining model built without the guidance (supervision) of a known, correct result. In supervised learning, this correct result is provided in the <a href="#CHDDBGBA"><span class="xrefglossterm">target</span></a> attribute. Unsupervised learning has no such target attribute. Clustering and association are examples of unsupervised mining functions. See <a href="#i941253"><span class="xrefglossterm">supervised model</span></a>.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON532" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref701"></a>view</p>
<p>A view takes the output of a query and treats it as a table. Therefore, a view can be thought of as a stored query or a virtual table. You can use views in most places where a table can be used.</p>
</div>
<!-- class="glossentry" -->
<div id="DMCON533" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref702"></a>winsorizing</p>
<p>A way of dealing with outliers. Winsorizing involves setting the tail values of an particular attribute to some specified value. For example, for a 90% Winsorization, the bottom 5% of values are set equal to the minimum value in the 6th percentile, while the upper 5% are set equal to the maximum value in the 95th percentile.</p>
</div>
<!-- class="glossentry" -->
<a id="CHDEDJJF"></a>
<div id="DMCON534" class="glossentry"><!-- infolevel="all" -->
<p class="glossterm"><a id="sthref703"></a>z-score normalization</p>
<p>Normalize numerical attributes using this transformation:</p>
<pre>
<span class="codeinlineitalic">x_new</span> = (<span class="codeinlineitalic">x_old</span>-mean) / standard_deviation 
</pre></div>
<!-- class="glossentry" --></div>
<!-- class="glossary" --></div>
<!-- class="ind" -->
<!-- Start Footer -->
</div>
<!-- add extra wrapper close div-->
<footer><!--
<hr />
<table class="cellalignment1311">
<tr>
<td class="cellalignment1318">
<table class="cellalignment1316">
<tr>
<td class="cellalignment1315"><a href="text.htm"><img width="24" height="24" src="../../dcommon/gifs/leftnav.gif" alt="Go to previous page" /><br />
<span class="icon">Previous</span></a></td>
<td class="cellalignment1315"><a href="index.htm"><img width="24" height="24" src="../../dcommon/gifs/rightnav.gif" alt="Go to next page" /><br />
<span class="icon">Next</span></a></td>
</tr>
</table>
</td>
<td class="cellalignment-copyrightlogo"><img width="144" height="18" src="../../dcommon/gifs/oracle.gif" alt="Oracle" /><br />
Copyright&nbsp;&copy;&nbsp;2005, 2013,&nbsp;Oracle&nbsp;and/or&nbsp;its&nbsp;affiliates.&nbsp;All&nbsp;rights&nbsp;reserved.<br />
<a href="../../dcommon/html/cpyr.htm">Legal Notices</a></td>
<td class="cellalignment1320">
<table class="cellalignment1314">
<tr>
<td class="cellalignment1315"><a href="../../index.htm"><img width="24" height="24" src="../../dcommon/gifs/doclib.gif" alt="Go to Documentation Home" /><br />
<span class="icon">Home</span></a></td>
<td class="cellalignment1315"><a href="../../nav/portal_booklist.htm"><img width="24" height="24" src="../../dcommon/gifs/booklist.gif" alt="Go to Book List" /><br />
<span class="icon">Book List</span></a></td>
<td class="cellalignment1315"><a href="toc.htm"><img width="24" height="24" src="../../dcommon/gifs/toc.gif" alt="Go to Table of Contents" /><br />
<span class="icon">Contents</span></a></td>
<td class="cellalignment1315"><a href="index.htm"><img width="24" height="24" src="../../dcommon/gifs/index.gif" alt="Go to Index" /><br />
<span class="icon">Index</span></a></td>
<td class="cellalignment1315"><a href="../../nav/mindx.htm"><img width="24" height="24" src="../../dcommon/gifs/masterix.gif" alt="Go to Master Index" /><br />
<span class="icon">Master Index</span></a></td>
<td class="cellalignment1315"><a href="../../dcommon/html/feedback.htm"><img width="24" height="24" src="../../dcommon/gifs/feedbck2.gif" alt="Go to Feedback page" /><br />
<span class="icon">Contact Us</span></a></td>
</tr>
</table>
</td>
</tr>
</table>
--></footer>
<noscript>
<p>Scripting on this page enhances content navigation, but does not change the content in any way.</p>
</noscript>
</body>
</html>
