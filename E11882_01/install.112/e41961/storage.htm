<!DOCTYPE html>
<html lang="en" >
<head>
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta charset="utf-8">
<title>Configuring Storage for Oracle Grid Infrastructure for a Cluster and Oracle RAC</title>
<meta name="generator" content="Oracle DARB XHTML Converter (Mode = document) - Merged Version 1093" />
<meta name="dcterms.created" content="2017-09-10T22:46:13Z" />
<meta name="robots" content="all" />
<meta name="dcterms.title" content="Grid Infrastructure Installation Guide" />
<meta name="dcterms.identifier" content="E41961-10" />
<meta name="dcterms.isVersionOf" content="CWLIN" />
<meta name="dcterms.rights" content="Copyright&nbsp;&copy;&nbsp;2007, 2017,&nbsp;Oracle&nbsp;and/or&nbsp;its&nbsp;affiliates.&nbsp;All&nbsp;rights&nbsp;reserved." />
<link rel="Start" href="../../index.htm" title="Home" type="text/html" />
<link rel="Copyright" href="../../dcommon/html/cpyr.htm" title="Copyright" type="text/html" />

<script type="application/javascript"  src="../../dcommon/js/headfoot.js"></script>
<script type="application/javascript"  src="../../nav/js/doccd.js"></script>
<link rel="Contents" href="toc.htm" title="Contents" type="text/html" />
<link rel="Index" href="index.htm" title="Index" type="text/html" />
<link rel="Prev" href="prelinux.htm" title="Previous" type="text/html" />
<link rel="Next" href="crsunix.htm" title="Next" type="text/html" />
<link rel="alternate" href="../e41961.pdf" title="PDF version" type="application/pdf" />
<link rel="schema.dcterms" href="http://purl.org/dc/terms/" />
<link rel="stylesheet" href="../../dcommon/css/fusiondoc.css">
<link rel="stylesheet" type="text/css"  href="../../dcommon/css/header.css">
<link rel="stylesheet" type="text/css"  href="../../dcommon/css/footer.css">
<link rel="stylesheet" type="text/css"  href="../../dcommon/css/fonts.css">
<link rel="stylesheet" href="../../dcommon/css/foundation.css">
<link rel="stylesheet" href="../../dcommon/css/codemirror.css">
<link rel="stylesheet" type="text/css" title="Default" href="../../nav/css/html5.css">
<link rel="stylesheet" href="../../dcommon/css/respond-480-tablet.css">
<link rel="stylesheet" href="../../dcommon/css/respond-768-laptop.css">
<link rel="stylesheet" href="../../dcommon/css/respond-1140-deskop.css">
<script type="application/javascript" src="../../dcommon/js/modernizr.js"></script>
<script type="application/javascript" src="../../dcommon/js/codemirror.js"></script>
<script type="application/javascript" src="../../dcommon/js/jquery.js"></script>
<script type="application/javascript" src="../../dcommon/js/foundation.min.js"></script>
<script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-552992c80ef99c8d" async="async"></script>
<script type="application/javascript" src="../../dcommon/js/jqfns.js"></script>
<script type="application/javascript" src="../../dcommon/js/ohc-inline-videos.js"></script>
<!-- Add fancyBox -->
<link rel="stylesheet" href="../../dcommon/fancybox/jquery.fancybox.css?v=2.1.5" type="text/css" media="screen" />
<script type="text/javascript" src="../../dcommon/fancybox/jquery.fancybox.pack.js?v=2.1.5"></script>
<!-- Optionally add helpers - button, thumbnail and/or media -->
<link rel="stylesheet"  href="../../dcommon/fancybox/helpers/jquery.fancybox-buttons.css?v=1.0.5"  type="text/css" media="screen" />
<script type="text/javascript" src="../../dcommon/fancybox/helpers/jquery.fancybox-buttons.js?v=1.0.5"></script>
<script type="text/javascript" src="../../dcommon/fancybox/helpers/jquery.fancybox-media.js?v=1.0.6"></script>
<link rel="stylesheet"  href="../../dcommon/fancybox/helpers/jquery.fancybox-thumbs.css?v=1.0.7"  type="text/css" media="screen" />
<script type="text/javascript" src="../../dcommon/fancybox/helpers/jquery.fancybox-thumbs.js?v=1.0.7"></script>
</head>
<body>
<a href="#BEGIN" class="accessibility-top skipto" tabindex="0">Go to main content</a><header><!--
<div class="zz-skip-header"><a id="top" href="#BEGIN">Go to main content</a>--></header>
<div class="row" id="CONTENT">
<div class="IND large-9 medium-8 columns" dir="ltr">
<a id="BEGIN" name="BEGIN"></a>
<span id="PAGE" style="display:none;">8/18</span> <!-- End Header -->
<script  >
<!-- // <![CDATA[
window.name='storage'
// ]]> -->
</script> <script  >
// <![CDATA[
function footdisplay(footnum,footnote) {
    var msg = window.open('', 'NewWindow' + footnum,
        'directories=no,height=100,location=no,menubar=no,resizable=yes,' +
        'scrollbars=yes,status=no,toolbar=no,width=598');
    msg.document.open('text/html');
    msg.document.write('<!DOCTYPE html ');
    msg.document.write('PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" ');

    msg.document.write('"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">');
    msg.document.write('<html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><title>');
    msg.document.write('Footnote&nbsp; ' + footnum);
    msg.document.write('<\/title><meta http-equiv="Content-Type" ');
    msg.document.write('content="text/html; charset=utf-8" />');
    msg.document.write('');
    msg.document.write('<style> <![CDATA[ ');
    msg.document.write('h1 {text-align: center; font-size: 14pt;}');
    msg.document.write('fieldset {border: none;}');
    msg.document.write('form {text-align: center;}');
    msg.document.write(' ]]\u003e <\/style>');
    msg.document.write('<\/head><body><div id="footnote"><h1>Footnote&nbsp; ' + footnum + '<\/h1><p>');
    msg.document.write(footnote);
    msg.document.write('<\/p><form action="" method="post"><fieldset>');
    msg.document.write('<input type="button" value="OK" ');
    msg.document.write('onclick="window.close();" />');
    msg.document.write('<\/fieldset><\/form><\/div><\/body><\/html>');
    msg.document.close();
    setTimeout(function() { var height = msg.document.getElementById('footnote').offsetHeight; msg.resizeTo(598, height + 100); }, 100);
    msg.focus();
}
// ]]>
</script> <noscript>
<p>The script content on this page is for navigation purposes only and does not alter the content in any way.</p>
</noscript>
<div id="CWLIN003|Configuring the Shared Disks; explains how to configure the shared disk subsystem for ORACs." class="chapter"><a id="CDECEBGH"></a>
<h1 class="chapter"><span class="secnum">3</span> Configuring Storage for Oracle Grid Infrastructure for a Cluster and Oracle RAC</h1>
<p>This chapter describes the storage configuration tasks that you must complete before you start the installer to install Oracle Clusterware and Oracle Automatic Storage Management (Oracle ASM), and that you must complete before adding an Oracle Real Application Clusters (Oracle RAC) installation to the cluster.</p>
<p>This chapter contains the following topics:</p>
<ul>
<li>
<p><a href="#BABHIJDF">Reviewing Oracle Grid Infrastructure Storage Options</a></p>
</li>
<li>
<p><a href="#CDEDAHGB">Shared File System Storage Configuration</a></p>
</li>
<li>
<p><a href="#CDEEJBFE">Oracle Automatic Storage Management Storage Configuration</a></p>
</li>
<li>
<p><a href="#CDECFFAD">Desupport of Block and Raw Devices</a></p>
</li>
<li>
<p><a href="#CHDJEFAA">Configuring Raw Logical Volumes on IBM: Linux on System z</a></p>
</li>
</ul>
<a id="BABHIJDF"></a>
<div id="CWLIN257" class="sect1">
<h2 class="sect1"><span class="secnum">3.1</span> Reviewing Oracle Grid Infrastructure Storage Options</h2>
<p>This section describes supported options for storing Oracle Grid Infrastructure for a cluster storage options. It contains the following sections:</p>
<ul>
<li>
<p><a href="#CDECCFJC">Overview of Oracle Clusterware and Oracle RAC Storage Options</a></p>
</li>
<li>
<p><a href="#CHDJFFGA">Oracle ACFS and Oracle ADVM Support</a></p>
</li>
<li>
<p><a href="#CHDDGHHD">General Information About Oracle ACFS</a></p>
</li>
<li>
<p><a href="#CDEFCHAD">General Storage Considerations for Oracle Grid Infrastructure and Oracle RAC</a></p>
</li>
<li>
<p><a href="#CHDEBHID">Guidelines for Using Oracle ASM Disk Groups for Storage</a></p>
</li>
<li>
<p><a href="#CHDGEIIB">Using Logical Volume Managers with Oracle Grid Infrastructure and Oracle RAC</a></p>
</li>
<li>
<p><a href="#CDEBGJAG">Supported Storage Options</a></p>
</li>
<li>
<p><a href="#CDEIDJEE">After You Have Selected Disk Storage Options</a></p>
</li>
</ul>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
The Oracle Certification site on My Oracle Support for the most current information about certified storage options:
<pre >
<a href="https://support.oracle.com">https://support.oracle.com</a>
</pre></div>
<a id="CDECCFJC"></a>
<div id="CWLIN258" class="sect2">
<h3 class="sect2"><span class="secnum">3.1.1</span> Overview of Oracle Clusterware and Oracle RAC Storage Options</h3>
<p>There are two ways of storing Oracle Clusterware files:</p>
<ul>
<li>
<p><a id="sthref473"></a><a id="sthref474"></a><span class="bold">Oracle Automatic Storage Management (Oracle ASM)</span>: You can install Oracle Clusterware files (Oracle Cluster Registry and voting disk files) in Oracle ASM disk groups.</p>
<p>Oracle ASM is the required database storage option for Typical installations, and for Standard Edition Oracle RAC installations. It is an integrated, high-performance database file system and disk manager for Oracle Clusterware and Oracle Database files. It performs striping and mirroring of database files automatically.</p>
</li>
<li>
<p><span class="bold">A supported shared file system</span>: Supported file systems include the following:</p>
<ul>
<li>
<p><span class="bold">Network File System (NFS)</span>: Note that if you intend to use NFS for your data files, then you should create partitions large enough for the database files when you create partitions for Oracle Grid Infrastructure. NFS mounts differ for software binaries, Oracle Clusterware files, and database files.</p>
<div class="infobox-note">
<p class="notep1">Note:</p>
<a id="sthref475"></a><a id="sthref476"></a>Placing Oracle Grid Infrastructure for a cluster binaries on a cluster file system is not supported.
<p>You can no longer use OUI to install Oracle Clusterware or Oracle Database files on block or raw devices.</p>
</div>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
My Oracle Support for supported file systems and NFS or NAS filers</div>
</li>
</ul>
</li>
</ul>
</div>
<!-- class="sect2" -->
<a id="CHDJFFGA"></a>
<div id="CWLIN2944" class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2"><span class="secnum">3.1.2</span> Oracle ACFS and Oracle ADVM Support</h3>
<p>Oracle Automatic Storage Management Cluster File System (Oracle ACFS) extends Oracle ASM technology to support of all of your application data in both single instance and cluster configurations. Oracle Automatic Storage Management Dynamic Volume Manager (Oracle ADVM) provides volume management services and a standard disk device driver interface to clients. Oracle Automatic Storage Management Cluster File System is layered on Oracle ASM through the Oracle Automatic Storage Management Dynamic Volume Manager interface.</p>
<p>Oracle ACFS and Oracle ADVM are supported on Oracle Linux 5 and Red Hat Enterprise Linux 5 for Linux x86 and Linux x86-64. Table 3-1 lists the releases, platforms and kernel versions that support Oracle ACFS and Oracle ADVM.</p>
<div id="CWLIN2945" class="tblformal">
<p class="titleintable"><a id="sthref477"></a><a id="sthref478"></a>Table 3-1 Platforms that Support Oracle ACFS and Oracle ADVM</p>
<table class="cellalignment2507" title="Platforms that Support Oracle ACFS and Oracle ADVM" summary="Platform support information for Oracle ACFS and Oracle ADFM" dir="ltr">
<thead>
<tr class="cellalignment2496">
<th class="cellalignment2508" id="r1c1-t5">Release</th>
<th class="cellalignment2508" id="r1c2-t5">Platform/Operating system</th>
<th class="cellalignment2508" id="r1c3-t5"><br /></th>
</tr>
</thead>
<tbody>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r2c1-t5" headers="r1c1-t5">
<p>11.2.x</p>
</td>
<td class="cellalignment2502" headers="r2c1-t5 r1c2-t5">
<p><span class="bold">Linux x86</span>: Oracle Linux 5 and Red Hat Enterprise Linux 5</p>
</td>
<td class="cellalignment2502" headers="r2c1-t5 r1c3-t5">
<p>2.6.18, and later updates to 2.6.18</p>
</td>
</tr>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r3c1-t5" headers="r1c1-t5">
<p>11.2.0.1</p>
</td>
<td class="cellalignment2502" headers="r3c1-t5 r1c2-t5">
<p><span class="bold">Linux x86-64</span>: Oracle Linux 5 and Red Hat Enterprise Linux 5</p>
</td>
<td class="cellalignment2502" headers="r3c1-t5 r1c3-t5">
<p>2.6.18, and later updates to 2.6.18</p>
</td>
</tr>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r4c1-t5" headers="r1c1-t5">
<p>11.2.0.2</p>
</td>
<td class="cellalignment2502" headers="r4c1-t5 r1c2-t5">
<p><span class="bold">Linux x86-64:</span> Oracle Linux 5, Red Hat Enterprise Linux 5, SUSE Linux Enterprise Server 10 SP3 and later</p>
</td>
<td class="cellalignment2502" headers="r4c1-t5 r1c3-t5">
<p>2.6.18, and later updates to 2.6.18</p>
</td>
</tr>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r5c1-t5" headers="r1c1-t5">
<p>11.2.0.3</p>
</td>
<td class="cellalignment2502" headers="r5c1-t5 r1c2-t5">
<p><span class="bold">Linux x86-64:</span> Oracle Linux 5, Red Hat Enterprise Linux 5, SUSE Linux Enterprise Server 10 SP3 and later, SUSE Linux Enterprise Server 11 SP1</p>
</td>
<td class="cellalignment2502" headers="r5c1-t5 r1c3-t5">
<p>2.6.18, and later updates to 2.6.18</p>
<p>Oracle Unbreakable Enterprise Kernel 2.6.32-100.34.1 and later updates to 2.6.32-100</p>
</td>
</tr>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r6c1-t5" headers="r1c1-t5">
<p>11.2.0.3</p>
</td>
<td class="cellalignment2502" headers="r6c1-t5 r1c2-t5">
<p><span class="bold">Linux x86-64:</span> Oracle Linux 6 (with Oracle Unbreakable Linux Kernel)</p>
</td>
<td class="cellalignment2502" headers="r6c1-t5 r1c3-t5">
<p>Oracle Unbreakable Enterprise kernel 2.6.32-100.34.1 and later updates to 2.6.32-100</p>
</td>
</tr>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r7c1-t5" headers="r1c1-t5">
<p>11.2.0.3.3 (Oracle Grid Infrastructure PSU)</p>
</td>
<td class="cellalignment2502" headers="r7c1-t5 r1c2-t5">
<p><span class="bold">Linux x86-64:</span> Red Hat Enterprise Linux 6 , Oracle Linux with the Red Hat Compatible Kernel</p>
</td>
<td class="cellalignment2502" headers="r7c1-t5 r1c3-t5">
<p>6.0, 6.1, 6.2</p>
</td>
</tr>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r8c1-t5" headers="r1c1-t5">
<p>11.2.0.3.4 (Oracle Grid Infrastructure PSU)</p>
</td>
<td class="cellalignment2502" headers="r8c1-t5 r1c2-t5">
<p><span class="bold">Linux x86-64:</span> Red Hat Enterprise Linux 6, Oracle Linux with the Red Hat Compatible Kernel</p>
</td>
<td class="cellalignment2502" headers="r8c1-t5 r1c3-t5">
<p>6.3 and later</p>
</td>
</tr>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r9c1-t5" headers="r1c1-t5">
<p>11.2.0.3.7 (Oracle Grid Infrastructure PSU)</p>
</td>
<td class="cellalignment2502" headers="r9c1-t5 r1c2-t5">
<p><span class="bold">Linux x86-64:</span> Oracle Linux 6 (with Oracle Unbreakable Enterprise Kernel), SUSE Linux Enterprise Server 11 SP2</p>
</td>
<td class="cellalignment2502" headers="r9c1-t5 r1c3-t5">
<p>Oracle Unbreakable Enterprise Kernel 2.6.39-100 and later updates to 2.6.39-100</p>
</td>
</tr>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r10c1-t5" headers="r1c1-t5">
<p>11.2.0.4</p>
</td>
<td class="cellalignment2502" headers="r10c1-t5 r1c2-t5">
<p><span class="bold">Linux x86-64:</span> SUSE Linux Enterprise Server 11 SP3</p>
</td>
<td class="cellalignment2502" headers="r10c1-t5 r1c3-t5">&nbsp;</td>
</tr>
</tbody>
</table>
<br /></div>
<!-- class="tblformal" -->
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<ul>
<li>For current information on platforms and releases that support Oracle ACFS and Oracle ADVM refer to My Oracle Support Note 1369107.1:
<p><code dir="ltr"><a href="https://support.oracle.com/CSP/main/article?cmd=show&amp;type=NOT&amp;id=1369107.1">https://support.oracle.com/CSP/main/article?cmd=show&amp;type=NOT&amp;id=1369107.1</a></code></p>
</li>
<li>
<p>For current Patch Set Update (PSU) release and support information refer to the PSU document on My Oracle Support.</p>
</li>
</ul>
</div>
<div class="infobox-note">
<p class="notep1">Note:</p>
Deployment of Security Enhanced Linux (SELinux) is not supported on Oracle ACFS file systems.</div>
</div>
<!-- class="sect2" -->
<a id="CHDDGHHD"></a>
<div id="CWLIN2946" class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2"><span class="secnum">3.1.3</span> General Information About Oracle ACFS</h3>
<p>Oracle Automatic Storage Management Cluster File System (Oracle ACFS) provides a general purpose file system. You can place Oracle Database binaries on this system, but you cannot place Oracle data files or Oracle Clusterware files on Oracle ACFS.</p>
<p>Note the following about Oracle ACFS:</p>
<ul>
<li>
<p>Oracle Restart does not support root-based Oracle Clusterware resources. For this reason, the following restrictions apply if you run Oracle ACFS on an Oracle Restart Configuration</p>
<ul>
<li>
<p>You must manually load and unload Oracle ACFS drivers.</p>
</li>
<li>
<p>You must manually mount and unmount Oracle ACFS file systems, after the Oracle ASM instance is running</p>
</li>
<li>
<p>You can place Oracle ACFS database home file systems into the Oracle ACFS mount registry, along with other registered Oracle ACFS file systems.</p>
</li>
</ul>
</li>
<li>
<p>You cannot put Oracle Clusterware binaries and files on Oracle ACFS.</p>
</li>
<li>
<p>You cannot put Oracle Database files on Oracle ACFS.</p>
</li>
<li>
<p>You can put Oracle Database binaries and administrative files (for example, trace files) on Oracle ACFS.</p>
</li>
<li>
<p>Oracle ACFS provides a general purpose file system for other files.</p>
</li>
</ul>
</div>
<!-- class="sect2" -->
<a id="CDEFCHAD"></a>
<div id="CWLIN259" class="sect2">
<h3 class="sect2"><span class="secnum">3.1.4</span> General Storage Considerations for Oracle Grid Infrastructure and Oracle RAC</h3>
<p><a id="sthref479"></a><a id="sthref480"></a><a id="sthref481"></a><a id="sthref482"></a><a id="sthref483"></a>For all installations, you must choose the storage option to use for Oracle Grid Infrastructure (Oracle Clusterware and Oracle ASM), and Oracle Real Application Clusters (Oracle RAC) databases. To enable automated backups during the installation, you must also choose the storage option to use for recovery files (the Fast Recovery Area). You do not have to use the same storage option for each file type.</p>
<div id="CWLIN260" class="sect3"><a id="sthref484"></a>
<h4 class="sect3"><span class="secnum">3.1.4.1</span> General Storage Considerations for Oracle Clusterware</h4>
<p>Oracle Clusterware voting disks are used to monitor cluster node status, and Oracle Cluster Registry (OCR) files contain configuration information about the cluster. You can place voting disks and OCR files either in an Oracle ASM disk group, or on a cluster file system or shared network file system. Storage must be shared; any node that does not have access to an absolute majority of voting disks (more than half) will be restarted.</p>
</div>
<!-- class="sect3" -->
<div id="CWLIN261" class="sect3"><a id="sthref485"></a>
<h4 class="sect3"><span class="secnum">3.1.4.2</span> General Storage Considerations for Oracle RAC</h4>
<p>Use the following guidelines when choosing the storage options to use for each file type:</p>
<ul>
<li>
<p>You can choose any combination of the supported storage options for each file type provided that you satisfy all requirements listed for the chosen storage options.</p>
</li>
<li>
<p>If you plan to install an Oracle RAC home on a shared OCFS2 location, then you must upgrade OCFS2 to at least version 1.4.1, which supports shared writable mmaps.</p>
</li>
<li>
<p>Oracle recommends that you choose Oracle ASM as the storage option for database and recovery files.</p>
</li>
<li>
<p>For Standard Edition Oracle RAC installations, Oracle ASM is the only supported storage option for database or recovery files.</p>
</li>
<li>
<p>If you intend to use Oracle ASM with Oracle RAC, and you are configuring a new Oracle ASM instance, then your system must meet the following conditions:</p>
<ul>
<li>
<p>All nodes on the cluster have Oracle Clusterware and Oracle ASM 11<span class="italic">g</span> release 2 (11.2) installed as part of an Oracle Grid Infrastructure for a cluster installation.</p>
</li>
<li>
<p>Any existing Oracle ASM instance on any node in the cluster is shut down.</p>
</li>
</ul>
</li>
<li>
<p><a id="sthref486"></a><a id="sthref487"></a><a id="sthref488"></a><a id="sthref489"></a>Raw or block devices are supported only when upgrading an existing installation using the partitions already configured. On new installations, using raw or block device partitions is not supported by Oracle Automatic Storage Management Configuration Assistant (ASMCA) or Oracle Universal Installer (OUI), but is supported by the software if you perform manual configuration.</p>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<a class="olink UPGRD" href="../../server.112/e23633/toc.htm"><span class="italic">Oracle Database Upgrade Guide</span></a> for information about how to prepare for upgrading an existing database</div>
</li>
<li>
<p>If you do not have a storage option that provides external file redundancy, then you must configure at least three voting disk areas to provide voting disk redundancy.</p>
</li>
</ul>
</div>
<!-- class="sect3" --></div>
<!-- class="sect2" -->
<a id="CHDEBHID"></a>
<div id="CWLIN2947" class="sect2">
<h3 class="sect2"><span class="secnum">3.1.5</span> Guidelines for Using Oracle ASM Disk Groups for Storage</h3>
<p>During Oracle Grid Infrastructure installation, you can create one disk group. After the Oracle Grid Infrastructure installation, you can create additional disk groups using ASMCA, SQL*Plus, or ASMCMD. Note that with Oracle Database 11g release 2 (11.2) and later releases, Oracle Database Configuration Assistant (DBCA) does not have the functionality to create disk groups for Oracle ASM.</p>
<p>If you install Oracle Database or Oracle RAC after you install Oracle Grid Infrastructure, then you can either use the same disk group for database files, OCR, and voting disk files, or you can use different disk groups. If you create multiple disk groups before installing Oracle RAC or before creating a database, then you can decide to do one of the following:</p>
<ul>
<li>
<p>Place the data files in the same disk group as the Oracle Clusterware files.</p>
</li>
<li>
<p>Use the same Oracle ASM disk group for data files and recovery files.</p>
</li>
<li>
<p>Use different disk groups for each file type.</p>
</li>
</ul>
<p>If you create only one disk group for storage, then the OCR and voting disk files, database files, and recovery files are contained in the one disk group. If you create multiple disk groups for storage, then you can choose to place files in different disk groups.</p>
<div class="infobox-note">
<p class="notep1">Note:</p>
The Oracle ASM instance that manages the existing disk group should be running in the Grid home.</div>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<p><a class="olink OSTMG" href="../../server.112/e18951/toc.htm"><span class="italic">Oracle Automatic Storage Management Administrator's Guide</span></a> for information about creating disk groups</p>
</div>
</div>
<!-- class="sect2" -->
<a id="CHDGEIIB"></a>
<div id="CWLIN2948" class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2"><span class="secnum">3.1.6</span> Using Logical Volume Managers with Oracle Grid Infrastructure and Oracle RAC</h3>
<p>Oracle Grid Infrastructure and Oracle RAC only support cluster-aware volume managers. This means, the volume manager that you want to use comes with a certain vendor cluster solution. To confirm that a volume manager you want to use is supported, look under the Certifications tab on My Oracle Support whether the associated cluster solution is certified for Oracle RAC. My Oracle Support is available at the following URL:</p>
<pre dir="ltr">
<a href="https://support.oracle.com">https://support.oracle.com</a>
</pre></div>
<!-- class="sect2" -->
<a id="CDEBGJAG"></a>
<div id="CWLIN262" class="sect2">
<h3 class="sect2"><span class="secnum">3.1.7</span> Supported Storage Options</h3>
<p>The following table shows the storage options supported for storing Oracle Clusterware and Oracle RAC files.</p>
<div class="infobox-note">
<p class="notep1">Note:</p>
For information about OCFS2, refer to the following Web site:
<pre dir="ltr">
<a href="http://oss.oracle.com/projects/ocfs2/">http://oss.oracle.com/projects/ocfs2/</a>
</pre>
<p>If you plan to install an Oracle RAC home on a shared OCFS2 location, then you must upgrade OCFS2 to at least version 1.4.1, which supports shared writable <code dir="ltr">mmaps</code>.</p>
<p>For OCFS2 certification status, and for other cluster file system support, refer to the Certify page on My Oracle Support.</p>
</div>
<div id="CWLIN263" class="tblformalwidemax">
<p class="titleintable"><a id="sthref490"></a><a id="sthref491"></a>Table 3-2 Supported Storage Options<a id="sthref492"></a><a id="sthref493"></a><a id="sthref494"></a><a id="sthref495"></a> for Oracle Clusterware and Oracle RAC<a id="sthref496"></a><a id="sthref497"></a></p>
<table class="cellalignment2509" title="Supported Storage Options for Oracle Clusterware and Oracle RAC " summary="storage options for Oracle software and files" dir="ltr">
<thead>
<tr class="cellalignment2496">
<th class="cellalignment2508" id="r1c1-t12">Storage Option</th>
<th class="cellalignment2508" id="r1c2-t12">OCR and Voting Disk Files</th>
<th class="cellalignment2508" id="r1c3-t12">Oracle Clusterware binaries</th>
<th class="cellalignment2508" id="r1c4-t12">Oracle RAC binaries</th>
<th class="cellalignment2508" id="r1c5-t12">Oracle Database Files</th>
<th class="cellalignment2508" id="r1c6-t12">Oracle Recovery Files</th>
</tr>
</thead>
<tbody>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r2c1-t12" headers="r1c1-t12">
<p>Oracle Automatic Storage Management (Oracle ASM)</p>
<p><span class="bold">Note</span>: Loopback devices are not supported for use with Oracle ASM</p>
</td>
<td class="cellalignment2502" headers="r2c1-t12 r1c2-t12">
<p>Yes</p>
</td>
<td class="cellalignment2502" headers="r2c1-t12 r1c3-t12">
<p>No</p>
</td>
<td class="cellalignment2502" headers="r2c1-t12 r1c4-t12">
<p>No</p>
</td>
<td class="cellalignment2502" headers="r2c1-t12 r1c5-t12">
<p>Yes</p>
</td>
<td class="cellalignment2502" headers="r2c1-t12 r1c6-t12">
<p>Yes</p>
</td>
</tr>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r3c1-t12" headers="r1c1-t12">
<p>Oracle Automatic Storage Management Cluster File System (Oracle ACFS)</p>
</td>
<td class="cellalignment2502" headers="r3c1-t12 r1c2-t12">
<p>No</p>
</td>
<td class="cellalignment2502" headers="r3c1-t12 r1c3-t12">
<p>No</p>
</td>
<td class="cellalignment2502" headers="r3c1-t12 r1c4-t12">
<p>Yes</p>
</td>
<td class="cellalignment2502" headers="r3c1-t12 r1c5-t12">
<p>No</p>
</td>
<td class="cellalignment2502" headers="r3c1-t12 r1c6-t12">
<p>No</p>
</td>
</tr>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r4c1-t12" headers="r1c1-t12">
<p>Local file system</p>
</td>
<td class="cellalignment2502" headers="r4c1-t12 r1c2-t12">
<p>No</p>
</td>
<td class="cellalignment2502" headers="r4c1-t12 r1c3-t12">
<p>Yes</p>
</td>
<td class="cellalignment2502" headers="r4c1-t12 r1c4-t12">
<p>Yes</p>
</td>
<td class="cellalignment2502" headers="r4c1-t12 r1c5-t12">
<p>No</p>
</td>
<td class="cellalignment2502" headers="r4c1-t12 r1c6-t12">
<p>No</p>
</td>
</tr>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r5c1-t12" headers="r1c1-t12">
<p>NFS file system on a certified NAS filer</p>
<p><span class="bold">Note:</span> Direct NFS Client does not support Oracle Clusterware files.</p>
</td>
<td class="cellalignment2502" headers="r5c1-t12 r1c2-t12">
<p>Yes</p>
</td>
<td class="cellalignment2502" headers="r5c1-t12 r1c3-t12">
<p>Yes</p>
</td>
<td class="cellalignment2502" headers="r5c1-t12 r1c4-t12">
<p>Yes</p>
</td>
<td class="cellalignment2502" headers="r5c1-t12 r1c5-t12">
<p>Yes</p>
</td>
<td class="cellalignment2502" headers="r5c1-t12 r1c6-t12">
<p>Yes</p>
</td>
</tr>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r6c1-t12" headers="r1c1-t12">
<p>Shared disk partitions (block devices or raw devices)</p>
</td>
<td class="cellalignment2502" headers="r6c1-t12 r1c2-t12">
<p>Not supported by OUI or ASMCA, but supported by the software. They can be added or removed after installation.</p>
</td>
<td class="cellalignment2502" headers="r6c1-t12 r1c3-t12">
<p>No</p>
</td>
<td class="cellalignment2502" headers="r6c1-t12 r1c4-t12">
<p>No</p>
</td>
<td class="cellalignment2502" headers="r6c1-t12 r1c5-t12">
<p>Not supported by OUI or ASMCA, but supported by the software. They can be added or removed after installation.</p>
</td>
<td class="cellalignment2502" headers="r6c1-t12 r1c6-t12">
<p>No</p>
</td>
</tr>
</tbody>
</table>
<br /></div>
<!-- class="tblformalwidemax" -->
<p>Use the following guidelines when choosing storage options:</p>
<ul>
<li>
<p>You can choose any combination of the supported storage options for each file type provided that you satisfy all requirements listed for the chosen storage options.</p>
</li>
<li>
<p><a id="sthref498"></a>You can use Oracle ASM 11<span class="italic">g</span> release 2 (11.2) and later to store Oracle Clusterware files. You cannot use prior Oracle ASM releases to do this.</p>
</li>
<li>
<p>If you do not have a storage option that provides external file redundancy, then you must configure at least three voting disk locations and at least three Oracle Cluster Registry locations to provide redundancy.</p>
</li>
</ul>
</div>
<!-- class="sect2" -->
<a id="CDEIDJEE"></a>
<div id="CWLIN264" class="sect2">
<h3 class="sect2"><span class="secnum">3.1.8</span> After You Have Selected Disk Storage Options</h3>
<p>When you have determined your disk storage options, configure shared storage:<a id="sthref499"></a><a id="sthref500"></a><a id="sthref501"></a><a id="sthref502"></a><a id="sthref503"></a><a id="sthref504"></a></p>
<ul>
<li>
<p><span class="bold">To use a file system</span>, refer to <a href="#CDEDAHGB">Shared File System Storage Configuration</a>.</p>
</li>
<li>
<p><span class="bold">To use Oracle Automatic Storage Management</span>, refer to <a href="#CDEDGAFJ">"Using Disk Groups with Oracle Database Files on Oracle ASM"</a></p>
</li>
</ul>
</div>
<!-- class="sect2" --></div>
<!-- class="sect1" -->
<a id="CDEDAHGB"></a>
<div id="CWLIN265" class="sect1">
<h2 class="sect1"><span class="secnum">3.2</span> Shared File System Storage Configuration</h2>
<p>The installer does not suggest a default location for the Oracle Cluster Registry (OCR) or the Oracle Clusterware voting disk. If you choose to create these files on a file system, then review the following sections to complete storage requirements for Oracle Clusterware files:</p>
<ul>
<li>
<p><a href="#CDEEBBHE">Requirements for Using a Shared File System</a></p>
</li>
<li>
<p><a href="#CDECHFJC">Deciding to Use a Cluster File System for Oracle Clusterware Files</a></p>
</li>
<li>
<p><a href="#CDEHCDDG">Deciding to Use Direct NFS Client for Data Files</a></p>
</li>
<li>
<p><a href="#CDEIEEFC">Deciding to Use NFS for Data Files</a></p>
</li>
<li>
<p><a href="#CDEIIGJD">Configuring Storage NFS Mount and Buffer Size Parameters</a></p>
</li>
<li>
<p><a href="#CDECEBBF">Checking NFS Mount and Buffer Size Parameters for Oracle Clusterware</a></p>
</li>
<li>
<p><a href="#CDEFJEJA">Checking NFS Mount and Buffer Size Parameters for Oracle RAC</a></p>
</li>
<li>
<p><a href="#CDEFBADH">Enabling Direct NFS Client Oracle Disk Manager Control of NFS</a></p>
</li>
<li>
<p><a href="#CHDIECFC">Enabling Hybrid Columnar Compression on Direct NFS Client</a></p>
</li>
<li>
<p><a href="#CDEEBADI">Creating Directories for Oracle Clusterware Files on Shared File Systems</a></p>
</li>
<li>
<p><a href="#CDEHCJID">Creating Directories for Oracle Database Files on Shared File Systems</a></p>
</li>
<li>
<p><a href="#CDECHIJI">Disabling Direct NFS Client Oracle Disk Management Control of NFS</a></p>
</li>
</ul>
<div class="infobox-note">
<p class="notep1">Note:</p>
The OCR is a file that contains the configuration information and status of the cluster. The installer automatically initializes the OCR during the Oracle Clusterware installation. Database Configuration Assistant uses the OCR for storing the configurations for the cluster databases that it creates.</div>
<a id="CDEEBBHE"></a>
<div id="CWLIN266" class="sect2">
<h3 class="sect2"><span class="secnum">3.2.1</span> Requirements for Using a Shared File System</h3>
<p>To use a shared file system for Oracle Clusterware, Oracle ASM, and Oracle RAC, the file system must comply with the following requirements:</p>
<ul>
<li>
<p>To use an <a id="sthref505"></a>NFS file system, it must be on a supported NAS device. Log in to My Oracle Support at the following URL, and click the Certification tab to find the most current information about supported NAS devices:</p>
<p><code dir="ltr"><a href="https://support.oracle.com">https://support.oracle.com</a></code></p>
</li>
<li>
<p>If you choose to place your Oracle Cluster Registry (OCR) files on a shared file system, then Oracle recommends that one of the following is true:</p>
<ul>
<li>
<p>The disks used for the file system are on a highly available storage device, (for example, a RAID device).</p>
</li>
<li>
<p>At least two file systems are mounted, and use the features of Oracle Clusterware 11<span class="italic">g</span> release 2 (11.2) to provide redundancy for the OCR.</p>
</li>
</ul>
</li>
<li>
<p>If you choose to place your database files on a shared file system, then one of the following should be true:</p>
<ul>
<li>
<p>The disks used for the file system are on a highly available storage device, (for example, a RAID<a id="sthref506"></a><a id="sthref507"></a><a id="sthref508"></a> device).</p>
</li>
<li>
<p>The file systems consist of at least two independent file systems, with the database files on one file system, and the recovery files on a different file system.</p>
</li>
</ul>
</li>
<li>
<p>The user account with which you perform the installation (<code dir="ltr">oracle</code> or <code dir="ltr">grid</code>) must have write permissions to create the files in the path that you specify.</p>
</li>
</ul>
<div class="infobox-note">
<p class="notep1">Note:</p>
Upgrading from Oracle9<span class="italic">i</span> release 2 using the raw device or shared file for the OCR that you used for the SRVM configuration repository is not supported.
<p><a id="sthref509"></a><a id="sthref510"></a><a id="sthref511"></a><a id="sthref512"></a><a id="sthref513"></a><a id="sthref514"></a>If you are upgrading Oracle Clusterware, and your existing cluster uses 100 MB OCR and 20 MB voting disk partitions, then you must extend these partitions to at least 300 MB. Oracle recommends that you do not use partitions, but instead place OCR and voting disks in disk groups marked as QUORUM disk groups.</p>
<p>All storage products must be supported by both your server and storage vendors.</p>
</div>
<p>Use <a href="#CDEFGCFC">Table 3-3</a> and <a href="#CDEEFJGC">Table 3-4</a> to determine the minimum size for shared file systems:</p>
<div id="CWLIN267" class="tblformal">
<p class="titleintable"><a id="sthref515"></a><a id="CDEFGCFC"></a>Table 3-3 Oracle Clusterware Shared File System Volume Size Requirements</p>
<table class="cellalignment2507" title="Oracle Clusterware Shared File System Volume Size Requirements" summary="Lists minimum partition sizes for shared file systems for Oracle Clusterware, including minimum sizes for database files if these are also stored on shared filesystem partitions" dir="ltr">
<thead>
<tr class="cellalignment2496">
<th class="cellalignment2508" id="r1c1-t15">File Types Stored</th>
<th class="cellalignment2508" id="r1c2-t15">Number of Volumes</th>
<th class="cellalignment2508" id="r1c3-t15">Volume Size</th>
</tr>
</thead>
<tbody>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r2c1-t15" headers="r1c1-t15">
<p>Voting disks with external redundancy</p>
</td>
<td class="cellalignment2502" headers="r2c1-t15 r1c2-t15">
<p>3</p>
</td>
<td class="cellalignment2502" headers="r2c1-t15 r1c3-t15">
<p>At least 300 MB for each voting disk volume.</p>
</td>
</tr>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r3c1-t15" headers="r1c1-t15">
<p>Oracle Cluster Registry (OCR) with external redundancy</p>
</td>
<td class="cellalignment2502" headers="r3c1-t15 r1c2-t15">
<p>1</p>
</td>
<td class="cellalignment2502" headers="r3c1-t15 r1c3-t15">
<p>At least 300 MB for each OCR volume</p>
</td>
</tr>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r4c1-t15" headers="r1c1-t15">
<p>Oracle Clusterware files (OCR and voting disks) with redundancy provided by Oracle software.</p>
</td>
<td class="cellalignment2502" headers="r4c1-t15 r1c2-t15">
<p>1</p>
</td>
<td class="cellalignment2502" headers="r4c1-t15 r1c3-t15">
<p>At least 300 MB for each OCR volume</p>
<p>At least 300 MB for each voting disk volume</p>
</td>
</tr>
</tbody>
</table>
<br /></div>
<!-- class="tblformal" -->
<div id="CWLIN268" class="tblformal">
<p class="titleintable"><a id="sthref516"></a><a id="CDEEFJGC"></a>Table 3-4 Oracle RAC Shared File System Volume Size Requirements</p>
<table class="cellalignment2507" title="Oracle RAC Shared File System Volume Size Requirements" summary="Lists minimum partition sizes for shared file systems for Oracle Clusterware, including minimum sizes for database files if these are also stored on shared filesystem partitions" dir="ltr">
<thead>
<tr class="cellalignment2496">
<th class="cellalignment2508" id="r1c1-t16">File Types Stored</th>
<th class="cellalignment2508" id="r1c2-t16">Number of Volumes</th>
<th class="cellalignment2508" id="r1c3-t16">Volume Size</th>
</tr>
</thead>
<tbody>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r2c1-t16" headers="r1c1-t16">
<p>Oracle Database files</p>
</td>
<td class="cellalignment2502" headers="r2c1-t16 r1c2-t16">
<p>1</p>
</td>
<td class="cellalignment2502" headers="r2c1-t16 r1c3-t16">
<p>At least 1.5 GB for each volume</p>
</td>
</tr>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r3c1-t16" headers="r1c1-t16">
<p>Recovery files</p>
<p><span class="bold">Note</span>: Recovery files must be on a different volume than database files</p>
</td>
<td class="cellalignment2502" headers="r3c1-t16 r1c2-t16">
<p>1</p>
</td>
<td class="cellalignment2502" headers="r3c1-t16 r1c3-t16">
<p>At least 2 GB for each volume</p>
</td>
</tr>
</tbody>
</table>
<br /></div>
<!-- class="tblformal" -->
<p>In <a href="#CDEFGCFC">Table 3-3</a> and <a href="#CDEEFJGC">Table 3-4</a>, the total required volume size is cumulative. For example, to store all Oracle Clusterware files on the shared file system with normal redundancy, you should have at least 2 GB of storage available over a minimum of three volumes (three separate volume locations for the OCR and two OCR mirrors, and one voting disk on each volume). You should have a minimum of three physical disks, each at least 500 MB, to ensure that voting disks and OCR files are on separate physical disks. If you add Oracle RAC using one volume for database files and one volume for recovery files, then you should have at least 3.5 GB available storage over two volumes, and at least 5.5 GB available total for all volumes.</p>
<div class="infobox-note">
<p class="notep1">Note:</p>
If you create partitions on shared partitions with <code dir="ltr">fdisk</code> by specifying a device size, such as <code dir="ltr">+300M</code>, the actual device created may be smaller than the size requested, based on the cylinder geometry of the disk. This is due to current fdisk restrictions. Oracle recommends that you partition the entire disk that you allocate for use by Oracle ASM.</div>
</div>
<!-- class="sect2" -->
<a id="CDECHFJC"></a>
<div id="CWLIN269" class="sect2">
<h3 class="sect2"><span class="secnum">3.2.2</span> Deciding to Use a Cluster File System for Oracle Clusterware Files</h3>
<p>For new installations, Oracle recommends that you use Oracle Automatic Storage Management (Oracle ASM) to store voting disk and OCR files. For Linux x86 (32-bit) and x86-64 (64-bit) platforms, Oracle provides a cluster file system, OCFS2. However, Oracle does not recommend using OCFS2 for Oracle Clusterware files.</p>
</div>
<!-- class="sect2" -->
<a id="CDEHCDDG"></a>
<div id="CWLIN270" class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2"><span class="secnum">3.2.3</span> Deciding to Use Direct NFS Client for Data Files<a id="sthref517"></a><a id="sthref518"></a></h3>
<p>Direct NFS Client is an alternative to using kernel-managed NFS. This section contains the following information about Direct NFS Client:</p>
<ul>
<li>
<p><a href="#CDECDFJH">About Direct NFS Client Storage</a></p>
</li>
<li>
<p><a href="#CDEDBEDA">Using the oranfstab File with Direct NFS Client</a></p>
</li>
<li>
<p><a href="#CDEHIGAE">Mounting NFS Storage Devices with Direct NFS Client</a></p>
</li>
<li>
<p><a href="#CHDEFABE">Specifying Network Paths with the oranfstab File</a></p>
</li>
</ul>
<a id="CDECDFJH"></a>
<div id="CWLIN271" class="sect3">
<h4 class="sect3"><span class="secnum">3.2.3.1</span> About Direct NFS Client Storage</h4>
<p>With Oracle Database 11<span class="italic">g</span> release 2 (11.2), instead of using the operating system kernel NFS client, you can configure Oracle Database to access NFS V3 servers directly using an Oracle internal Direct NFS Client.</p>
<p>To enable Oracle Database to use Direct NFS Client, the NFS file systems must be mounted and available over regular NFS mounts before you start installation. Direct NFS Client manages settings after installation. You should still set the kernel mount options as a backup, but for normal operation, Direct NFS Client will manage NFS mounts.</p>
<p>Refer to your vendor documentation to complete NFS configuration and mounting.</p>
<p>Some NFS file servers require NFS clients to connect using reserved ports. If your filer is running with reserved port checking, then you must disable it for Direct NFS Client to operate. To disable reserved port checking, consult your NFS file server documentation.</p>
<p>For NFS servers that restrict port range, you can use the <code dir="ltr">insecure</code> option to enable clients other than <code dir="ltr">root</code> to connect to the NFS server. Alternatively, you can disable Direct NFS Client as described in <a href="#CDECHIJI">Section 3.2.12, "Disabling Direct NFS Client Oracle Disk Management Control of NFS"</a>.</p>
<div class="infobox-note">
<p class="notep1">Note:</p>
Use NFS servers supported for Oracle RAC. Refer to the following URL for support information:
<p><code dir="ltr"><a href="https://support.oracle.com">https://support.oracle.com</a></code></p>
</div>
</div>
<!-- class="sect3" -->
<a id="CDEDBEDA"></a>
<div id="CWLIN272" class="sect3"><!-- infolevel="all" infotype="General" -->
<h4 class="sect3"><span class="secnum">3.2.3.2</span> Using the oranfstab File with Direct NFS Client</h4>
<p>If you use Direct NFS Client, then you can choose to use a new file specific for Oracle data file management, <code dir="ltr">oranfstab</code>, to specify additional options specific for Oracle Database to Direct NFS Client. For example, you can use <code dir="ltr">oranfstab</code> to specify additional paths for a mount point. You can add the <code dir="ltr">oranfstab</code> file either to <code dir="ltr">/etc</code> or to <code dir="ltr">$ORACLE_HOME/dbs</code>.</p>
<p>With shared Oracle homes, when the <code dir="ltr">oranfstab</code> file is placed in <code dir="ltr">$ORACLE_HOME/dbs</code>, the entries in the file are specific to a single database. In this case, all nodes running an Oracle RAC database use the same <code dir="ltr">$ORACLE_HOME/dbs/oranfstab</code> file. In non-shared Oracle RAC installs, <code dir="ltr">oranfstab</code> must be replicated on all nodes.</p>
<p>When the <code dir="ltr">oranfstab</code> file is placed in <code dir="ltr">/etc</code>, then it is globally available to all Oracle databases, and can contain mount points used by all Oracle databases running on nodes in the cluster, including standalone databases. However, on Oracle RAC systems, if the <code dir="ltr">oranfstab</code> file is placed in <code dir="ltr">/etc</code>, then you must replicate the file <code dir="ltr">/etc/oranfstab</code> file on all nodes, and keep each <code dir="ltr">/etc/oranfstab</code> file synchronized on all nodes, just as you must with the <code dir="ltr">/etc/fstab</code> file.</p>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<a href="#CDEIIGJD">Section 3.2.5, "Configuring Storage NFS Mount and Buffer Size Parameters"</a> for information about configuring <code dir="ltr">/etc/fstab</code></div>
<p>In all cases, mount points must be mounted by the kernel NFS system, even when they are being served using Direct NFS Client.</p>
<div class="infobox-note">
<p class="notep1"><a id="sthref519"></a><a id="sthref520"></a><a id="sthref521"></a>Caution:</p>
Direct NFS Client will not serve an NFS server with write size values (<code dir="ltr">wtmax</code>) less than 32768.</div>
</div>
<!-- class="sect3" -->
<a id="CDEHIGAE"></a>
<div id="CWLIN273" class="sect3">
<h4 class="sect3"><span class="secnum">3.2.3.3</span> Mounting NFS Storage Devices with Direct NFS Client</h4>
<p>Direct NFS Client determines mount point settings to NFS storage devices based on the configurations in <code dir="ltr">/etc/mtab</code>, which are changed with configuring the <code dir="ltr">/etc/fstab</code> file.</p>
<p>Direct NFS Client searches for mount entries in the following order:</p>
<ol>
<li>
<p><code dir="ltr">$ORACLE_HOME/dbs/oranfstab</code></p>
</li>
<li>
<p><code dir="ltr">/etc/oranfstab</code></p>
</li>
<li>
<p><code dir="ltr">/etc/mtab</code></p>
</li>
</ol>
<p>Direct NFS Client uses the first matching entry found.</p>
<p><a id="sthref522"></a>Oracle Database is not shipped with Direct NFS Client enabled by default. To enable Direct NFS Client, complete the following steps:</p>
<ol>
<li>
<p>Change the directory to <code dir="ltr">$ORACLE_HOME/rdbms/lib</code>.</p>
</li>
<li>
<p>Enter the following command:</p>
<pre dir="ltr">
make -f ins_rdbms.mk dnfs_on
</pre></li>
</ol>
<div class="infobox-note">
<p class="notep1">Note:</p>
You can have only one active Direct NFS Client implementation for each instance. Using Direct NFS Client on an instance will prevent another Direct NFS Client implementation.</div>
<p>If Oracle Database uses Direct NFS Client mount points configured using <code dir="ltr">oranfstab</code>, then it first verifies kernel NFS mounts by cross-checking entries in <code dir="ltr">oranfstab</code> with operating system NFS mount points. If a mismatch exists, then Direct NFS logs an informational message, and does not operate.</p>
<p>If Oracle Database cannot open an NFS server using Direct NFS Client, then Oracle Database uses the platform operating system kernel NFS client. In this case, the kernel NFS mount options must be set up as defined in <a href="#CDEFJEJA">"Checking NFS Mount and Buffer Size Parameters for Oracle RAC"</a>. Additionally, an informational message is logged into the Oracle alert and trace files indicating that Direct NFS Client could not connect to an NFS server.</p>
<p><a href="#CDEBGJAG">Section 3.1.7, "Supported Storage Options"</a> lists the file types that are supported by Direct NFS.</p>
<p>The Oracle files resident on the NFS server that are served by the Direct NFS Client are also accessible through the operating system kernel NFS client.</p>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<a class="olink ADMIN" href="../../server.112/e25494/toc.htm"><span class="italic">Oracle Database Administrator's Guide</span></a> for guidelines to follow regarding managing Oracle database data files created with Direct NFS Client or kernel NFS</div>
</div>
<!-- class="sect3" -->
<a id="CHDEFABE"></a>
<div id="CWLIN274" class="sect3"><!-- infolevel="all" infotype="General" -->
<h4 class="sect3"><span class="secnum">3.2.3.4</span> Specifying Network Paths with the oranfstab File</h4>
<p>Direct NFS Client can use up to four network paths defined in the <code dir="ltr">oranfstab</code> file for an NFS server. Direct NFS Client performs load balancing across all specified paths. If a specified path fails, then Direct NFS Client reissues I/O commands over any remaining paths.</p>
<p>Use the following SQL*Plus views for managing Direct NFS Client in a cluster environment:</p>
<ul>
<li>
<p><span class="bold">gv$dnfs_servers</span>: Shows a table of servers accessed using Direct NFS Client.</p>
</li>
<li>
<p><span class="bold">gv$dnfs_files</span>: Shows a table of files currently open using Direct NFS Client.</p>
</li>
<li>
<p><span class="bold">gv$dnfs_channels</span>: Shows a table of open network paths (or channels) to servers for which Direct NFS Client is providing files.</p>
</li>
<li>
<p><span class="bold">gv$dnfs_stats</span>: Shows a table of performance statistics for Direct NFS Client.</p>
</li>
</ul>
<div class="infobox-note">
<p class="notep1">Note:</p>
Use <code dir="ltr">v$</code> views for single instances, and <code dir="ltr">gv$</code> views for Oracle Clusterware and Oracle RAC storage.</div>
</div>
<!-- class="sect3" --></div>
<!-- class="sect2" -->
<a id="CDEIEEFC"></a>
<div id="CWLIN275" class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2"><span class="secnum">3.2.4</span> Deciding to Use <a id="sthref523"></a><a id="sthref524"></a>NFS for Data Files</h3>
<p>Network-attached storage (NAS) systems use NFS to access data. You can store data files on a supported NFS system.</p>
<p>NFS file systems must be mounted and available over NFS mounts before you start installation. Refer to your vendor documentation to complete NFS configuration and mounting.</p>
<p>Be aware that the performance of Oracle software and databases stored on NAS devices depends on the performance of the network connection between the Oracle server and the NAS device.</p>
<p>For this reason, Oracle recommends that you connect the server to the NAS device using a private dedicated network connection, which should be Gigabit Ethernet or better.</p>
</div>
<!-- class="sect2" -->
<a id="CDEIIGJD"></a>
<div id="CWLIN276" class="sect2">
<h3 class="sect2"><span class="secnum">3.2.5</span> Configuring Storage <a id="sthref525"></a>NFS Mount and Buffer Size Parameters</h3>
<p>If you are using NFS for the Grid home or Oracle RAC home, then you must set up the NFS mounts on the storage so that they allow <code dir="ltr">root</code> on the clients mounting to the storage to be considered <code dir="ltr">root</code> instead of being mapped to an anonymous user, and allow <code dir="ltr">root</code> on the client server to create files on the NFS filesystem that are owned by <code dir="ltr">root</code>.</p>
<p>On NFS, you can obtain <code dir="ltr">root</code> access for clients writing to the storage by enabling <code dir="ltr">no_root_squash</code> on the server side. For example, to set up Oracle Clusterware file storage in the path <code dir="ltr">/vol/grid</code>, with nodes node1, node 2, and node3 in the domain <code dir="ltr">mycluster.example.com</code>, add a line similar to the following to the <code dir="ltr">/etc/exports</code> file:</p>
<pre dir="ltr">
/vol/grid/ node1.mycluster.example.com(rw,no_root_squash)
node2.mycluster.example.com(rw,no_root_squash) node3.mycluster.example.com
(rw,no_root_squash) 
</pre>
<p>If the domain or DNS is secure so that no unauthorized system can obtain an IP address on it, then you can grant <code dir="ltr">root</code> access by domain, rather than specifying particular cluster member nodes:</p>
<p>For example:</p>
<pre dir="ltr">
/vol/grid/ *.mycluster.example.com(rw,no_root_squash)
</pre>
<p>Oracle recommends that you use a secure DNS or domain, and grant <code dir="ltr">root</code> access to cluster member nodes using the domain, as using this syntax allows you to add or remove nodes without the need to reconfigure the NFS server.</p>
<p>If you use Grid Naming Service (GNS), then the subdomain allocated for resolution by GNS within the cluster is a secure domain. Any server without a correctly signed Grid Plug and Play (GPnP) profile cannot join the cluster, so an unauthorized system cannot obtain or use names inside the GNS subdomain.</p>
<div class="infobox-note">
<p class="notep1">Caution:</p>
Granting <code dir="ltr">root</code> access by domain can be used to obtain unauthorized access to systems. System administrators should refer to their operating system documentation for the risks associated with using <code dir="ltr">no_root_squash</code>.</div>
<p>After changing <code dir="ltr">/etc/exports</code>, reload the file system mount using the following command:</p>
<pre dir="ltr">
# /usr/sbin/exportfs -avr
</pre></div>
<!-- class="sect2" -->
<a id="CDECEBBF"></a>
<div id="CWLIN277" class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2"><span class="secnum">3.2.6</span> Checking NFS Mount and Buffer Size Parameters for Oracle Clusterware</h3>
<p>On the cluster member nodes, you must set the values for the NFS buffer size parameters <code dir="ltr"><a id="sthref526"></a><a id="sthref527"></a><a id="sthref528"></a><a id="sthref529"></a>rsize</code> and <code dir="ltr">wsize</code> to 32768.</p>
<p>The NFS client-side mount options for binaries are:</p>
<pre dir="ltr">
rw,bg,hard,nointr,tcp,vers=3,timeo=600,rsize=32768,wsize=32768,actimeo=0
</pre>
<div class="infobox-note">
<p class="notep1">Note:</p>
The <code dir="ltr">intr</code> and <code dir="ltr">nointr</code> mount options are deprecated with Oracle Linux re deprecated in Oracle Unbreakable Enterprise Linux and Oracle Linux kernels, 2.6.32 and later.</div>
<p>If you have Oracle Grid Infrastructure binaries on an NFS mount, then you must include the <code dir="ltr">suid</code> option.</p>
<p>The NFS client-side mount options for Oracle Clusterware files (OCR and voting disk files) are:</p>
<pre dir="ltr">
rw,bg,hard,nointr,rsize=32768,wsize=32768,tcp,noac,vers=3,timeo=600,actimeo=0
</pre>
<p>Update the <code dir="ltr">/etc/fstab</code> file on each node with an entry containing the NFS mount options for your platform. For example, if your platform is x86-64, and you are creating a mount point for Oracle Clusterware files, then update the <code dir="ltr">/etc/fstab</code> files with an entry similar to the following:</p>
<pre dir="ltr">
nfs_server:/vol/grid  /u02/oracle/cwfiles nfs \
rw,bg,hard,nointr,tcp,vers=3,timeo=600,actimeo=0,rsize=32768,wsize=32768 0 0
</pre>
<p>Note that mount point options are different for Oracle software binaries, Oracle Clusterware files (OCR and voting disks), and data files.</p>
<p>To create a mount point for binaries only, provide an entry similar to the following for a binaries mount point:</p>
<pre dir="ltr">
<span class="italic">nfs_server</span>:/vol/bin /u02/oracle/grid nfs \
rw,bg,hard,nointr,rsize=32768,wsize=32768,tcp,vers=3,timeo=600,actimeo=0,suid
</pre>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
My Oracle Support bulletin 359515.1, "Mount Options for Oracle Files When Used with NAS Devices" for the most current information about mount options, available from the following URL:
<p><code dir="ltr"><a href="https://support.oracle.com">https://support.oracle.com</a></code></p>
</div>
<div class="infobox-note">
<p class="notep1">Note:</p>
Refer to your storage vendor documentation for additional information about mount options.</div>
</div>
<!-- class="sect2" -->
<a id="CDEFJEJA"></a>
<div id="CWLIN278" class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2"><span class="secnum">3.2.7</span> Checking <a id="sthref530"></a>NFS Mount and Buffer Size Parameters for Oracle RAC</h3>
<p>If you use NFS mounts, then you must mount NFS volumes used for storing database files with special mount options on each node that has an Oracle RAC instance. When mounting an NFS file system, Oracle recommends that you use the same mount point options that your NAS vendor used when certifying the device. Refer to your device documentation or contact your vendor for information about recommended mount-point options.</p>
<p>Update the <code dir="ltr">/etc/fstab</code> file on each node with an entry similar to the following:</p>
<pre dir="ltr">
<span class="italic">nfs_server</span>:/vol/DATA/oradata  /u02/oradata     nfs\   
rw,bg,hard,nointr,tcp,vers=3,timeo=600,actimeo=0,rsize=32768,wsize=32768 0 0
</pre>
<p>The mandatory mount options comprise the minimum set of mount options that you must use while mounting the NFS volumes. These mount options are essential to protect the integrity of the data and to prevent any database corruption. Failure to use these mount options may result in the generation of file access errors. Refer to your operating system or NAS device documentation for more information about the specific options supported on your platform.</p>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
My Oracle Support note 359515.1 for updated NAS mount option information, available at the following URL:
<pre dir="ltr">
<a href="https://support.oracle.com">https://support.oracle.com</a>
</pre></div>
</div>
<!-- class="sect2" -->
<a id="CDEFBADH"></a>
<div id="CWLIN279" class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2"><span class="secnum">3.2.8</span> Enabling <a id="sthref531"></a><a id="sthref532"></a>Direct NFS Client Oracle Disk Manager Control of NFS</h3>
<p>Complete the following procedure to enable Direct NFS Client:</p>
<ol>
<li>
<p>Create an <code dir="ltr">oranfstab</code> file with the following attributes for each NFS server to be accessed using Direct NFS Client:</p>
<ul>
<li>
<p><span class="bold">Server</span>: The NFS server name.</p>
</li>
<li>
<p><span class="bold">Local</span>: Up to four paths on the database host, specified by IP address or by name, as displayed using the <code dir="ltr">ifconfig</code> command run on the database host.</p>
</li>
<li>
<p><span class="bold">Path</span>: Up to four network paths to the NFS server, specified either by IP address, or by name, as displayed using the <code dir="ltr">ifconfig</code> command on the NFS server.</p>
</li>
<li>
<p><span class="bold">Export</span>: The exported path from the NFS server.</p>
</li>
<li>
<p><span class="bold">Mount</span>: The corresponding local mount point for the exported volume.</p>
</li>
<li>
<p><span class="bold">Mnt_timeout</span>: Specifies (in seconds) the time Direct NFS Client should wait for a successful mount before timing out. This parameter is optional. The default timeout is 10 minutes (<code dir="ltr">600</code>).</p>
</li>
<li>
<p><span class="bold">Dontroute</span>: Specifies that outgoing messages should not be routed by the operating system, but instead sent using the IP address to which they are bound. Note that this POSIX option sometimes does not work on Linux systems with multiple paths in the same subnet.</p>
</li>
<li>
<p><span class="bold">management:</span> Enables Direct NFS Client to use the management interface for SNMP queries. You can use this parameter if SNMP is running on separate management interfaces on the NFS server. The default value is the server parameter value.</p>
</li>
<li>
<p><span class="bold">community:</span> Specifies the community string for use in SNMP queries. Default value is public.</p>
</li>
</ul>
<p>The examples that follow show three possible NFS server entries in <code dir="ltr">oranfstab</code>. A single <code dir="ltr">oranfstab</code> can have multiple NFS server entries.</p>
<div id="CWLIN280" class="example">
<p class="titleinexample"><a id="sthref533"></a>Example 3-1 Using Local and Path NFS Server Entries</p>
<p>The following example uses both local and path. Since they are in different subnets, we do not have to specify <code dir="ltr">dontroute</code>.</p>
<pre dir="ltr">
server: MyDataServer1
local: 192.0.2.0
path: 192.0.2.1
local: 192.0.100.0
path: 192.0.100.1
export: /vol/oradata1 mount: /mnt/oradata1
community: private
</pre></div>
<!-- class="example" -->
<div id="CWLIN281" class="example">
<p class="titleinexample"><a id="sthref534"></a>Example 3-2 Using Local and Path in the Same Subnet, with dontroute</p>
<p>The following example shows local and path in the same subnet. <code dir="ltr">dontroute</code> is specified in this case:</p>
<pre dir="ltr">
server: MyDataServer2
local: 192.0.2.0
path: 192.0.2.128
local: 192.0.2.1
path: 192.0.2.129
dontroute
export: /vol/oradata2 mount: /mnt/oradata2
management: 192.0.10.128
</pre></div>
<!-- class="example" -->
<div id="CWLIN282" class="example">
<p class="titleinexample"><a id="sthref535"></a>Example 3-3 Using Names in Place of IP Addresses, with Multiple Exports</p>
<pre dir="ltr">
server: MyDataServer3
local: LocalPath1
path: NfsPath1
local: LocalPath2
path: NfsPath2
local: LocalPath3
path: NfsPath3
local: LocalPath4
path: NfsPath4
dontroute
export: /vol/oradata3 mount: /mnt/oradata3
export: /vol/oradata4 mount: /mnt/oradata4
export: /vol/oradata5 mount: /mnt/oradata5
export: /vol/oradata6 mount: /mnt/oradata6
</pre></div>
<!-- class="example" --></li>
<li>
<p><a id="sthref536"></a>By default, Direct NFS Client is installed in a disabled state. To enable Direct NFS Client, complete the following steps on each node. If you use a shared Grid home for the cluster, then complete the following steps in the shared Grid home:</p>
<ol>
<li>
<p>Log in as the Oracle Grid Infrastructure installation owner.</p>
</li>
<li>
<p>Change directory to <code dir="ltr"><span class="codeinlineitalic">Grid_home</span></code><code dir="ltr">/rdbms/lib</code>.</p>
</li>
<li>
<p>Enter the following commands:</p>
<pre dir="ltr">
$ make -f ins_rdbms.mk dnfs_on
</pre></li>
</ol>
</li>
</ol>
</div>
<!-- class="sect2" -->
<a id="CHDIECFC"></a>
<div class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2"><span class="secnum">3.2.9</span> Enabling Hybrid Columnar Compression on Direct NFS Client</h3>
<p>To enable Hybrid Columnar Compression (HCC) on Direct NFS Client, perform the following steps:</p>
<ol>
<li>
<p>Ensure that SNMP is enabled on the ZFS Storage Server. For example:</p>
<pre dir="ltr">
$ snmpget -v1 -c public server_name .1.3.6.1.4.1.42.2.225.1.4.2.0
SNMPv2-SMI::enterprises.42.2.225.1.4.2.0 = STRING: "Sun Storage 7410"
</pre></li>
<li>
<p>If SNMP is enabled on an interface other than the NFS server, then configure <code dir="ltr">oranfstab</code> using the <code dir="ltr">management</code> parameter.</p>
</li>
<li>
<p>If SNMP is configured using a community string other than public, then configure <code dir="ltr">oranfstab</code> file using the community parameter.</p>
</li>
<li>
<p>Ensure that <code dir="ltr">libnetsnmp.so</code> is installed by checking if <code dir="ltr">snmpget</code> is available.</p>
</li>
</ol>
</div>
<!-- class="sect2" -->
<a id="CDEEBADI"></a>
<div id="CWLIN283" class="sect2">
<h3 class="sect2"><span class="secnum">3.2.10</span> Creating Directories for Oracle Clusterware Files on Shared File Systems<a id="sthref537"></a><a id="sthref538"></a><a id="sthref539"></a></h3>
<p>Use the following instructions to create directories for Oracle Clusterware files. You can also configure shared file systems for the Oracle Database and recovery files.</p>
<div class="infobox-note">
<p class="notep1">Note:</p>
For both NFS and OCFS2 storage, you must complete this procedure only if you want to place the Oracle Clusterware files on a separate file system from the Oracle base directory.</div>
<p>To create directories for the Oracle Clusterware files on separate file systems from the Oracle base directory, follow these steps:</p>
<ol>
<li>
<p>If necessary, configure the shared file systems to use and mount them on each node.</p>
<div class="infobox-note">
<p class="notep1">Note:</p>
The mount point that you use for the file system must be identical on each node. Ensure that the file systems are configured to mount automatically when a node restarts.</div>
</li>
<li>
<p>Use the <code dir="ltr">df</code> command to determine the free disk space on each mounted file system.</p>
</li>
<li>
<p>From the display, identify the file systems to use. Choose a file system with a minimum of 600 MB of free disk space (one OCR and one voting disk, with external redundancy).</p>
<p>If you are using the same file system for multiple file types, then add the disk space requirements for each type to determine the total disk space requirement.</p>
</li>
<li>
<p>Note the names of the mount point directories for the file systems that you identified.</p>
</li>
<li>
<p>If the user performing installation (typically, <code dir="ltr">grid</code> or <code dir="ltr">oracle</code>) has permissions to create directories on the storage location where you plan to install Oracle Clusterware files, then OUI creates the Oracle Clusterware file directory.</p>
<p>If the user performing installation does not have write access, then you must create these directories manually using commands similar to the following to create the recommended subdirectories in each of the mount point directories and set the appropriate owner, group, and permissions on the directory. For example, where the user is <code dir="ltr">oracle</code>, and the Oracle Clusterware file storage area is <code dir="ltr">cluster</code>:</p>
<pre dir="ltr">
# mkdir /<span class="italic">mount_point</span>/cluster
# chown oracle:oinstall /<span class="italic">mount_point</span>/cluster
# chmod 775 /<span class="italic">mount_point</span>/cluster
</pre>
<div class="infobox-note">
<p class="notep1">Note:</p>
After installation, directories in the installation path for the OCR files should be owned by <code dir="ltr">root</code>, and not writable by any account other than <code dir="ltr">root</code>.</div>
</li>
</ol>
<p>When you have completed creating a subdirectory in the mount point directory, and set the appropriate owner, group, and permissions, you have completed OCFS2 or NFS configuration for Oracle Grid Infrastructure.</p>
</div>
<!-- class="sect2" -->
<a id="CDEHCJID"></a>
<div id="CWLIN284" class="sect2">
<h3 class="sect2"><span class="secnum">3.2.11</span> Creating Directories for Oracle Database Files on Shared File Systems<a id="sthref540"></a><a id="sthref541"></a><a id="sthref542"></a></h3>
<p>Use the following instructions to create directories for shared file systems for Oracle Database and recovery files (for example, for an Oracle RAC database).</p>
<ol>
<li>
<p>If necessary, configure the shared file systems and mount them on each node.</p>
<div class="infobox-note">
<p class="notep1">Note:</p>
The mount point that you use for the file system must be identical on each node. Ensure that the file systems are configured to mount automatically when a node restarts.</div>
</li>
<li>
<p>Use the <code dir="ltr">df -h</code> command to determine the free disk space on each mounted file system.</p>
</li>
<li>
<p>From the display, identify the file systems:</p>
<div class="inftblhruleinformal">
<table class="cellalignment2509" title="File System Requirements for Datafiles and Recovery Files" summary="This table describes the file system requirements for Oracle database and recovery file storage" dir="ltr">
<thead>
<tr class="cellalignment2496">
<th class="cellalignment2508" id="r1c1-t33">File Type</th>
<th class="cellalignment2508" id="r1c2-t33">File System Requirements</th>
</tr>
</thead>
<tbody>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r2c1-t33" headers="r1c1-t33">Database files</td>
<td class="cellalignment2502" headers="r2c1-t33 r1c2-t33">Choose either:
<ul>
<li>
<p>A single file system with at least 1.5 GB of free disk space.</p>
</li>
<li>
<p>Two or more file systems with at least 1.5 GB of free disk space in total.</p>
</li>
</ul>
</td>
</tr>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r3c1-t33" headers="r1c1-t33">Recovery files</td>
<td class="cellalignment2502" headers="r3c1-t33 r1c2-t33">Choose a file system with at least 2 GB of free disk space.</td>
</tr>
</tbody>
</table>
<br /></div>
<!-- class="inftblhruleinformal" -->
<p>If you are using the same file system for multiple file types, then add the disk space requirements for each type to determine the total disk space requirement.</p>
</li>
<li>
<p>Note the names of the mount point directories for the file systems that you identified.</p>
</li>
<li>
<p>If the user performing installation (typically, <code dir="ltr">oracle</code>) has permissions to create directories on the disks where you plan to install Oracle Database, then DBCA creates the Oracle Database file directory, and the Recovery file directory.</p>
<p>If the user performing installation does not have write access, then you must create these directories manually using commands similar to the following to create the recommended subdirectories in each of the mount point directories and set the appropriate owner, group, and permissions on them:<a id="sthref543"></a><a id="sthref544"></a><a id="sthref545"></a><a id="sthref546"></a><a id="sthref547"></a><a id="sthref548"></a><a id="sthref549"></a><a id="sthref550"></a><a id="sthref551"></a></p>
<ul>
<li>
<p>Database file directory:</p>
<pre dir="ltr">
# mkdir /<span class="italic">mount_point</span>/oradata
# chown oracle:oinstall /<span class="italic">mount_point</span>/oradata
# chmod 775 /<span class="italic">mount_point</span>/oradata
</pre></li>
</ul>
<ul>
<li>
<p>Recovery file directory (Fast Recovery Area):</p>
<pre dir="ltr">
# mkdir /<span class="italic">mount_point</span>/recovery_area
# chown oracle:oinstall /<span class="italic">mount_point</span>/recovery_area
# chmod 775 /<span class="italic">mount_point</span>/recovery_area
</pre></li>
</ul>
</li>
</ol>
<p>By making members of the <code dir="ltr">oinstall</code> group owners of these directories, this permits them to be read by <a id="sthref552"></a><a id="sthref553"></a>multiple Oracle homes, including those with different OSDBA groups.</p>
<p>When you have completed creating subdirectories in each of the mount point directories, and set the appropriate owner, group, and permissions, you have completed OCFS2 or NFS configuration for Oracle Database shared storage.</p>
</div>
<!-- class="sect2" -->
<a id="CDECHIJI"></a>
<div id="CWLIN285" class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2"><span class="secnum">3.2.12</span> Disabling <a id="sthref554"></a>Direct NFS Client Oracle Disk Management Control of NFS</h3>
<p><a id="sthref555"></a>Complete the following steps to disable the Direct NFS Client:</p>
<ol>
<li>
<p>Log in as the Oracle Grid Infrastructure installation owner, and disable the Direct NFS Client using the following commands, where <code dir="ltr"><span class="codeinlineitalic">Grid_home</span></code> is the path to the Oracle Grid Infrastructure home:</p>
<pre dir="ltr">
$ cd <span class="italic">Grid_home</span>/rdbms/lib
$ make -f ins_rdbms.mk dnfs_off
</pre>
<p>Enter these commands on each node in the cluster, or on the shared Grid home if you are using a shared home for the Oracle Grid Infrastructure installation.</p>
</li>
<li>
<p>Remove the <code dir="ltr">oranfstab</code> file.</p>
</li>
</ol>
<div class="infobox-note">
<p class="notep1">Note:</p>
If you remove an NFS path that Oracle Database is using, then you must restart the database for the change to be effective.</div>
</div>
<!-- class="sect2" --></div>
<!-- class="sect1" -->
<a id="CDEEJBFE"></a>
<div id="CWLIN286" class="sect1">
<h2 class="sect1"><span class="secnum">3.3</span> Oracle Automatic Storage Management Storage Configuration</h2>
<p>Review the following sections to configure storage for Oracle Automatic Storage Management:</p>
<ul>
<li>
<p><a href="#BABBJIBF">Configuring Storage for Oracle Automatic Storage Management</a></p>
</li>
<li>
<p><a href="#CDEDGAFJ">Using Disk Groups with Oracle Database Files on Oracle ASM</a></p>
</li>
<li>
<p><a href="#CFAFBFJA">Configuring Oracle Automatic Storage Management Cluster File System</a></p>
</li>
<li>
<p><a href="#CFAGEIFE">Upgrading Existing Oracle ASM Instances</a></p>
</li>
</ul>
<a id="BABBJIBF"></a>
<div id="CWLIN287" class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2"><span class="secnum">3.3.1</span> Configuring Storage for Oracle Automatic Storage Management</h3>
<p>This section describes how to configure storage for use with Oracle Automatic Storage Management.</p>
<ul>
<li>
<p><a href="#CCHBHHCC">Identifying Storage Requirements for Oracle Automatic Storage Management</a></p>
</li>
<li>
<p><a href="#CFACJAGB">Creating Files on a NAS Device for Use with Oracle ASM</a></p>
</li>
<li>
<p><a href="#CCHBHDEG">Using an Existing Oracle ASM Disk Group</a></p>
</li>
<li>
<p><a href="#BABIFHAB">Configuring Disks for Oracle ASM with ASMLIB</a></p>
</li>
<li>
<p><a href="#CDEFFBDJ">Configuring ASMLIB for Multipath Disks</a></p>
</li>
<li>
<p><a href="#CDEBFDEH">Configuring Disk Devices Manually for Oracle ASM</a></p>
</li>
</ul>
<a id="CCHBHHCC"></a>
<div id="CWLIN288" class="sect3"><!-- infolevel="all" infotype="General" -->
<h4 class="sect3"><span class="secnum">3.3.1.1</span> Identifying Storage Requirements for Oracle Automatic Storage Management</h4>
<p>To identify the storage requirements for using Oracle ASM, you must determine how many devices and the amount of free disk space that you require. To complete this task, follow these steps:</p>
<ol>
<li>
<p>Determine whether you want to use Oracle ASM for Oracle Clusterware files (OCR and voting disks), Oracle Database files, recovery files, or all files except for Oracle Clusterware or Oracle Database binaries. Oracle Database files include data files, control files, redo log files, the server parameter file, and the password file.</p>
<div class="infobox-note">
<p class="notep1">Note:</p>
You do not have to use the same storage mechanism for Oracle Clusterware, Oracle Database files and recovery files. You can use a shared file system for one file type and Oracle ASM for the other.
<p>If you choose to enable automated backups and you do not have a shared file system available, then you must choose Oracle ASM for recovery file storage.</p>
</div>
<p>If you enable automated backups during the installation, then you can select Oracle ASM as the storage mechanism for recovery files by specifying an Oracle Automatic Storage Management disk group for the Fast Recovery Area. If you select a noninteractive installation mode, then by default it creates one disk group and stores the OCR and voting disk files there. If you want to have any other disk groups for use in a subsequent database install, then you can choose interactive mode, or run ASMCA (or a command line tool) to create the appropriate disk groups before starting the database install.</p>
</li>
<li>
<p>Choose the Oracle ASM redundancy level to use for the Oracle ASM disk group.<a id="sthref556"></a><a id="sthref557"></a><a id="sthref558"></a><a id="sthref559"></a><a id="sthref560"></a><a id="sthref561"></a><a id="sthref562"></a><a id="sthref563"></a><a id="sthref564"></a></p>
<p>The redundancy level that you choose for the Oracle ASM disk group determines how Oracle ASM mirrors files in the disk group and determines the number of disks and amount of free disk space that you require, as follows:</p>
<ul>
<li>
<p>External redundancy</p>
<p>An external redundancy disk group requires a minimum of one disk device. The effective disk space in an external redundancy disk group is the sum of the disk space in all of its devices.</p>
<p>For Oracle Clusterware files, External redundancy disk groups provide 1 voting disk file, and 1 OCR, with no copies. You must use an external technology to provide mirroring for high availability.</p>
<p><a id="sthref565"></a>Because Oracle ASM does not mirror data in an external redundancy disk group, Oracle recommends that you use external redundancy with storage devices such as RAID, or other similar devices that provide their own data protection mechanisms.</p>
</li>
<li>
<p>Normal redundancy</p>
<p>In a normal redundancy disk group, to increase performance and reliability, Oracle ASM by default uses two-way mirroring. A normal redundancy disk group requires a minimum of two disk devices (or two failure groups). The effective disk space in a normal redundancy disk group is half the sum of the disk space in all of its devices.</p>
<p>For Oracle Clusterware files, Normal redundancy disk groups provide 3 voting disk files, 1 OCR and 2 copies (one primary and one secondary mirror). With normal redundancy, the cluster can survive the loss of one failure group.</p>
<p>For most installations, Oracle recommends that you select normal redundancy.</p>
</li>
<li>
<p>High redundancy</p>
<p>In a high redundancy disk group, Oracle ASM uses three-way mirroring to increase performance and provide the highest level of reliability. A high redundancy disk group requires a minimum of three disk devices (or three failure groups). The effective disk space in a high redundancy disk group is one-third the sum of the disk space in all of its devices.</p>
<p>For Oracle Clusterware files, High redundancy disk groups provide 5 voting disk files, 1 OCR and 3 copies (one primary and two secondary mirrors). With high redundancy, the cluster can survive the loss of two failure groups.</p>
<p>While high redundancy disk groups do provide a high level of data protection, you should consider the greater cost of additional storage devices before deciding to select high redundancy disk groups.</p>
</li>
</ul>
</li>
<li>
<p>Determine the total amount of disk space that you require for Oracle Clusterware files, and for the database files and recovery files.<a id="sthref566"></a><a id="sthref567"></a><a id="sthref568"></a><a id="sthref569"></a><a id="sthref570"></a><a id="sthref571"></a></p>
<p><a id="sthref572"></a><a id="sthref573"></a>Use <a href="#CDEDEEAH">Table 3-5</a> and <a href="#CDECHBDF">Table 3-6</a> to determine the minimum number of disks and the minimum disk space requirements for installing Oracle Clusterware files, and installing the starter database, where you have voting disks in a separate disk group:<a id="sthref574"></a><a id="sthref575"></a><a id="sthref576"></a><a id="sthref577"></a></p>
<div id="CWLIN289" class="tblformal">
<p class="titleintable"><a id="sthref578"></a><a id="CDEDEEAH"></a>Table 3-5 Total Oracle Clusterware Storage Space Required by Redundancy Type</p>
<table class="cellalignment2507" title="Total Oracle Clusterware Storage Space Required by Redundancy Type" summary="disk space requirements for external, normal and high redundancy" dir="ltr">
<thead>
<tr class="cellalignment2496">
<th class="cellalignment2508" id="r1c1-t36">Redundancy Level</th>
<th class="cellalignment2508" id="r1c2-t36">Minimum Number of Disks</th>
<th class="cellalignment2508" id="r1c3-t36">Oracle Cluster Registry (OCR) Files</th>
<th class="cellalignment2508" id="r1c4-t36">Voting Disk Files</th>
<th class="cellalignment2508" id="r1c5-t36">Both File Types</th>
</tr>
</thead>
<tbody>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r2c1-t36" headers="r1c1-t36">
<p>External</p>
</td>
<td class="cellalignment2502" headers="r2c1-t36 r1c2-t36">
<p>1</p>
</td>
<td class="cellalignment2502" headers="r2c1-t36 r1c3-t36">
<p>300 MB</p>
</td>
<td class="cellalignment2502" headers="r2c1-t36 r1c4-t36">
<p>300 MB</p>
</td>
<td class="cellalignment2502" headers="r2c1-t36 r1c5-t36">
<p>600 MB</p>
</td>
</tr>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r3c1-t36" headers="r1c1-t36">
<p>Normal</p>
</td>
<td class="cellalignment2502" headers="r3c1-t36 r1c2-t36">
<p>3</p>
</td>
<td class="cellalignment2502" headers="r3c1-t36 r1c3-t36">
<p>600 MB</p>
</td>
<td class="cellalignment2502" headers="r3c1-t36 r1c4-t36">
<p>900 MB</p>
</td>
<td class="cellalignment2502" headers="r3c1-t36 r1c5-t36">
<p>1.5 GB<a id="sthref579" href="#sthref579" onclick='footdisplay(1,"If you create a disk group during installation, then it must be at least 2 GB.")'><sup class="tablefootnote">Foot&nbsp;1&nbsp;</sup></a></p>
</td>
</tr>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r4c1-t36" headers="r1c1-t36">
<p>High</p>
</td>
<td class="cellalignment2502" headers="r4c1-t36 r1c2-t36">
<p>5</p>
</td>
<td class="cellalignment2502" headers="r4c1-t36 r1c3-t36">
<p>900 MB</p>
</td>
<td class="cellalignment2502" headers="r4c1-t36 r1c4-t36">
<p>1.5 GB</p>
</td>
<td class="cellalignment2502" headers="r4c1-t36 r1c5-t36">
<p>2.4 GB</p>
</td>
</tr>
</tbody>
</table>
<br /></div>
<!-- class="tblformal" -->
<p class="tablefootnote"><sup class="tablefootnote">Footnote&nbsp;1&nbsp;</sup>If you create a disk group during installation, then it must be at least 2 GB.</p>
<div class="infobox-note">
<p class="notep1">Note:</p>
If the voting disk files are in a disk group, be aware that disk groups with Oracle Clusterware files (OCR and voting disk files) have a higher minimum number of failure groups than other disk groups.
<p>If you create a disk group as part of the installation in order to install the OCR and voting disk files, then the installer requires that you create these files on a disk group with at least 2 GB of available space.</p>
<p>A quorum failure group is a special type of failure group and disks in these failure groups do not contain user data. A quorum failure group is not considered when determining redundancy requirements in respect to storing user data. However, a quorum failure group counts when mounting a disk group.</p>
</div>
<div id="CWLIN290" class="tblformal">
<p class="titleintable"><a id="sthref580"></a><a id="CDECHBDF"></a>Table 3-6 Total Oracle Database Storage Space Required by Redundancy Type</p>
<table class="cellalignment2507" title="Total Oracle Database Storage Space Required by Redundancy Type" summary="database disk space requirements" dir="ltr">
<thead>
<tr class="cellalignment2496">
<th class="cellalignment2508" id="r1c1-t38">Redundancy Level</th>
<th class="cellalignment2508" id="r1c2-t38">Minimum Number of Disks</th>
<th class="cellalignment2508" id="r1c3-t38">Database Files</th>
<th class="cellalignment2508" id="r1c4-t38">Recovery Files</th>
<th class="cellalignment2508" id="r1c5-t38">Both File Types</th>
</tr>
</thead>
<tbody>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r2c1-t38" headers="r1c1-t38">
<p>External</p>
</td>
<td class="cellalignment2502" headers="r2c1-t38 r1c2-t38">
<p>1</p>
</td>
<td class="cellalignment2502" headers="r2c1-t38 r1c3-t38">
<p>1.5 GB</p>
</td>
<td class="cellalignment2502" headers="r2c1-t38 r1c4-t38">
<p>3 GB</p>
</td>
<td class="cellalignment2502" headers="r2c1-t38 r1c5-t38">
<p>4.5 GB</p>
</td>
</tr>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r3c1-t38" headers="r1c1-t38">
<p>Normal</p>
</td>
<td class="cellalignment2502" headers="r3c1-t38 r1c2-t38">
<p>2</p>
</td>
<td class="cellalignment2502" headers="r3c1-t38 r1c3-t38">
<p>3 GB</p>
</td>
<td class="cellalignment2502" headers="r3c1-t38 r1c4-t38">
<p>6 GB</p>
</td>
<td class="cellalignment2502" headers="r3c1-t38 r1c5-t38">
<p>9 GB</p>
</td>
</tr>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r4c1-t38" headers="r1c1-t38">
<p>High</p>
</td>
<td class="cellalignment2502" headers="r4c1-t38 r1c2-t38">
<p>3</p>
</td>
<td class="cellalignment2502" headers="r4c1-t38 r1c3-t38">
<p>4.5 GB</p>
</td>
<td class="cellalignment2502" headers="r4c1-t38 r1c4-t38">
<p>9 GB</p>
</td>
<td class="cellalignment2502" headers="r4c1-t38 r1c5-t38">
<p>13.5 GB</p>
</td>
</tr>
</tbody>
</table>
<br /></div>
<!-- class="tblformal" --></li>
<li>
<p>Determine an allocation unit size. Every Oracle ASM disk is divided into allocation units (AU). An allocation unit is the fundamental unit of allocation within a disk group. You can select the AU Size value from 1, 2, 4, 8, 16, 32 or 64 MB, depending on the specific disk group compatibility level. The default value is set to 1 MB.</p>
</li>
<li>
<p>For Oracle Clusterware installations, you must also add additional disk space for the Oracle ASM metadata. You can use the following formula to calculate the disk space requirements (in MB) for OCR and voting disk files, and the Oracle ASM metadata:</p>
<p>total = [2 * ausize * disks] + [redundancy * (ausize * (nodes * (clients + 1) + 30) + (64 * nodes) + 533)]</p>
<p>Where:</p>
<ul>
<li>
<p>redundancy = Number of mirrors: external = 1, normal = 2, high = 3.</p>
</li>
<li>
<p>ausize = Metadata AU size in megabytes (default is 1 MB)</p>
</li>
<li>
<p>nodes = Number of nodes in cluster.</p>
</li>
<li>
<p>clients - Number of database instances for each node.</p>
</li>
<li>
<p>disks - Number of disks in disk group.</p>
</li>
</ul>
<p>For example, for a four-node Oracle RAC installation, using three disks in a normal redundancy disk group, you require an additional 1684 MB of space:</p>
<p>[2 * 1 * 3] + [2 * (1 * (4 * (4 + 1)+ 30)+ (64 * 4)+ 533)] = 1684 MB</p>
<p>To ensure high availability of Oracle Clusterware files on Oracle ASM, for a normal redundancy disk group, as a general rule for most installations, you must have at least 2 GB of disk space for Oracle Clusterware files in three separate failure groups, with at least three physical disks. To ensure that the effective disk space to create Oracle Clusterware files is 2 GB, best practice suggests that you ensure at least 2.1 GB of capacity for each disk, with a total capacity of at least 6.3 GB for three disks.</p>
</li>
<li>
<p>Optionally, identify failure groups for the Oracle ASM disk group devices.<a id="sthref581"></a><a id="sthref582"></a><a id="sthref583"></a></p>
<p><a id="sthref584"></a><a id="sthref585"></a><a id="sthref586"></a><a id="sthref587"></a><a id="sthref588"></a>If you intend to use a normal or high redundancy disk group, then you can further protect your database against hardware failure by associating a set of disk devices in a custom failure group. By default, each device comprises its own failure group. However, if two disk devices in a normal redundancy disk group are attached to the same SCSI controller, then the disk group becomes unavailable if the controller fails. The controller in this example is a single point of failure.</p>
<p>To protect against failures of this type, you could use two SCSI controllers, each with two disks, and define a failure group for the disks attached to each controller. This configuration would enable the disk group to tolerate the failure of one SCSI controller.</p>
<div class="infobox-note">
<p class="notep1">Note:</p>
Define custom failure groups after installation, using the GUI tool ASMCA, the command line tool <code dir="ltr">asmcmd</code>, or SQL commands.
<p>If you define custom failure groups, then for failure groups containing database files only, you must specify a minimum of two failure groups for normal redundancy disk groups and three failure groups for high redundancy disk groups.</p>
<p>For failure groups containing database files and clusterware files, including voting disks, you must specify a minimum of three failure groups for normal redundancy disk groups, and five failure groups for high redundancy disk groups.</p>
<p>Disk groups containing voting files must have at least 3 failure groups for normal redundancy or at least 5 failure groups for high redundancy. Otherwise, the minimum is 2 and 3 respectively. The minimum number of failure groups applies whether or not they are custom failure groups.</p>
</div>
</li>
<li>
<p>If you are sure that a suitable disk group does not exist on the system, then install or identify appropriate disk devices to add to a new disk group. Use the following guidelines when identifying appropriate disk devices:</p>
<ul>
<li>
<p>All of the devices in an Oracle ASM disk group should be the same size and have the same performance characteristics.</p>
</li>
<li>
<p>Do not specify multiple partitions on a single physical disk as a disk group device. Each disk group device should be on a separate physical disk.</p>
</li>
<li>
<p>Although you can specify a logical volume as a device in an Oracle ASM disk group, Oracle does not recommend their use because it adds a layer of complexity that is unnecessary with Oracle ASM. In addition, Oracle RAC requires a cluster logical volume manager in case you decide to use a logical volume with Oracle ASM and Oracle RAC.</p>
<p>Oracle recommends that if you choose to use a logical volume manager, then use the logical volume manager to represent a single LUN without striping or mirroring, so that you can minimize the impact of the additional storage layer.</p>
</li>
</ul>
</li>
</ol>
</div>
<!-- class="sect3" -->
<a id="CFACJAGB"></a>
<div id="CWLIN291" class="sect3"><!-- infolevel="all" infotype="General" -->
<h4 class="sect3"><span class="secnum">3.3.1.2</span> Creating Files on a NAS Device for Use with Oracle ASM</h4>
<p>If you have a certified NAS storage device, then you can create zero-padded files in an NFS mounted directory and use those files as disk devices in an Oracle ASM disk group.</p>
<p>To create these files, follow these steps:</p>
<ol>
<li>
<p>If necessary, create an exported directory for the disk group files on the NAS device.</p>
<p>Refer to the NAS device documentation for more information about completing this step.</p>
</li>
<li>
<p>Switch user to <code dir="ltr">root</code>.</p>
</li>
<li>
<p>Create a mount point directory on the local system. For example:</p>
<pre dir="ltr">
# mkdir -p /mnt/oracleasm
</pre></li>
<li>
<p>To ensure that the NFS file system is mounted when the system restarts, add an entry for the file system in the mount file <code dir="ltr">/etc/fstab</code>.</p>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
My Oracle Support note 359515.1 for updated NAS mount option information, available at the following URL:
<pre dir="ltr">
<a href="https://support.oracle.com">https://support.oracle.com</a>
</pre></div>
<p>For more information about editing the mount file for the operating system, refer to the <code dir="ltr">man</code> pages. For more information about recommended mount options, refer to the section <a href="#CDEFJEJA">"Checking NFS Mount and Buffer Size Parameters for Oracle RAC"</a>.</p>
</li>
<li>
<p>Enter a command similar to the following to mount the NFS file system on the local system:</p>
<pre dir="ltr">
# mount /mnt/oracleasm
</pre></li>
<li>
<p>Choose a name for the disk group to create. For example: <code dir="ltr">sales1</code>.</p>
</li>
<li>
<p>Create a directory for the files on the NFS file system, using the disk group name as the directory name. For example:</p>
<pre dir="ltr">
# mkdir /mnt/oracleasm/nfsdg
</pre></li>
<li>
<p>Use commands similar to the following to create the required number of zero-padded files in this directory:</p>
<pre dir="ltr">
# dd if=/dev/zero
of=/mnt/oracleasm/nfsdg/disk1 bs=1024k 
count=1000 oflag=direct
</pre>
<p>This example creates 1 GB files on the NFS file system. You must create one, two, or three files respectively to create an external, normal, or high redundancy disk group.</p>
</li>
<li>
<p>Enter commands similar to the following to change the owner, group, and permissions on the directory and files that you created, where the installation owner is <code dir="ltr">grid</code>, and the OSASM group is <code dir="ltr">asmadmin</code>:</p>
<pre dir="ltr">
# chown -R grid:asmadmin /mnt/oracleasm
# chmod -R 660 /mnt/oracleasm
</pre></li>
<li>
<p>If you plan to install Oracle RAC or a standalone Oracle Database, then during installation, edit the Oracle ASM disk discovery string to specify a regular expression that matches the file names you created. For example:</p>
<pre dir="ltr">
/mnt/oracleasm/sales1/
</pre>
<div class="infobox-note">
<p class="notep1">Note:</p>
During installation, disk paths mounted on Oracle ASM and registered on ASMLIB with the string ORCL:* are listed as default database storage candidate disks.</div>
</li>
</ol>
</div>
<!-- class="sect3" -->
<a id="CCHBHDEG"></a>
<div id="CWLIN292" class="sect3"><!-- infolevel="all" infotype="General" -->
<h4 class="sect3"><span class="secnum">3.3.1.3</span> Using an Existing Oracle ASM Disk Group</h4>
<p>Select from the following choices to store either database or recovery files in an existing Oracle ASM disk group, depending on installation method:</p>
<ul>
<li>
<p>If you select an installation method that runs Database Configuration Assistant in interactive mode, then you can decide whether you want to create a disk group, or to use an existing one.</p>
<p>The same choice is available to you if you use Database Configuration Assistant after the installation to create a database.</p>
</li>
<li>
<p>If you select an installation method that runs Database Configuration Assistant in noninteractive mode, then you must choose an existing disk group for the new database; you cannot create a disk group. However, you can add disk devices to an existing disk group if it has insufficient free space for your requirements.</p>
</li>
</ul>
<div class="infobox-note">
<p class="notep1">Note:</p>
The Oracle Automatic Storage Management instance that manages the existing disk group can be running in a different Oracle home directory.</div>
<p>To determine if an existing Oracle Automatic Storage Management disk group exists, or to determine if there is sufficient disk space in a disk group, you can use the Oracle ASM command line tool (<code dir="ltr">asmcmd</code>), Oracle Enterprise Manager Grid Control or Database Control. Alternatively, you can use the following procedure:</p>
<ol>
<li>
<p>View the contents of the <code dir="ltr">oratab</code> file to determine if an Oracle Automatic Storage Management instance is configured on the system:</p>
<pre dir="ltr">
$ more /etc/oratab
</pre>
<p>If an Oracle Automatic Storage Management instance is configured on the system, then the <code dir="ltr">oratab</code> file should contain a line similar to the following:</p>
<pre dir="ltr">
+ASM2:<span class="italic">oracle_home_path</span>
</pre>
<p>In this example, <code dir="ltr">+ASM2</code> is the system identifier (SID) of the Oracle Automatic Storage Management instance, with the node number appended, and <code dir="ltr"><span class="codeinlineitalic">oracle_home_path</span></code> is the Oracle home directory where it is installed. By convention, the SID for an Oracle Automatic Storage Management instance begins with a plus sign.</p>
</li>
<li>
<p>Set the <code dir="ltr">ORACLE_SID</code> and <code dir="ltr">ORACLE_HOME</code> environment variables to specify the appropriate values for the Oracle Automatic Storage Management instance.</p>
</li>
<li>
<p>Connect to the Oracle Automatic Storage Management instance and start the instance if necessary:</p>
<pre dir="ltr">
$ $ORACLE_HOME/bin/asmcmd
ASMCMD&gt; startup
</pre></li>
<li>
<p>Enter one of the following commands to view the existing disk groups, their redundancy level, and the amount of free disk space in each one:</p>
<pre dir="ltr">
ASMCMD&gt; lsdg
</pre>
<p>or:</p>
<pre dir="ltr">
$ORACLE_HOME/bin/asmcmd -p lsdg
</pre></li>
<li>
<p>From the output, identify a disk group with the appropriate redundancy level and note the free space that it contains.</p>
</li>
<li>
<p>If necessary, install or identify the additional disk devices required to meet the storage requirements listed in the previous section.</p>
<div class="infobox-note">
<p class="notep1">Note:</p>
If you are adding devices to an existing disk group, then Oracle recommends that you use devices that have the same size and performance characteristics as the existing devices in that disk group.</div>
</li>
</ol>
</div>
<!-- class="sect3" -->
<a id="BABIFHAB"></a>
<div id="CWLIN293" class="sect3"><!-- infolevel="all" infotype="General" -->
<h4 class="sect3"><span class="secnum">3.3.1.4</span> <a id="sthref589"></a><a id="sthref590"></a>Configuring Disks for Oracle ASM with ASMLIB<a id="sthref591"></a></h4>
<p>The Oracle Automatic Storage Management (Oracle ASM) library driver (ASMLIB) simplifies the configuration and management of the disk devices by eliminating the need to rebind disk devices used with Oracle ASM each time the system is restarted.</p>
<p>Without ASMLIB Linux 2.6 kernel and later, block device paths do not maintain permissions and path persistence unless you create a <code dir="ltr">permissions</code> or <code dir="ltr">rules</code> file on each cluster member node; block device paths that were <code dir="ltr">/dev/sda</code> can appear as <code dir="ltr">/dev/sdb</code> after a system restart. Adding new disks requires you to modify the <code dir="ltr">udev</code> file to provide permissions and path persistence for the new disk.</p>
<p>With ASMLIB, you define the range of disks you want to have made available as Oracle ASM disks. ASMLIB maintains permissions and disk labels that are persistent on the storage device, so that label is available even after an operating system upgrade. You can update storage paths on all cluster member nodes by running one <code dir="ltr">oracleasm</code> command on each node.</p>
<p>If you intend to use Oracle ASM on block devices for database storage for Linux, then Oracle recommends that you install the ASMLIB driver and associated utilities, and use them to configure the disks for Oracle ASM.</p>
<div class="infobox-note">
<p class="notep1">Caution:</p>
On IBM: Linux on System z servers, due to a block size compatibility issue, you cannot use ASMLIB with SCSI storage devices and Fibre Channel Protocol (FCP) for Oracle Grid Infrastructure release 11.2.0.1 and later.
<p><span class="bold">Workaround:</span> use block device directly (for example, using paths similar to <code dir="ltr">/dev/mapper/mpatha_part1</code>), or use DASD disks.</p>
</div>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
My Oracle Support notes How to Manually Configure Disk Storage devices for use with Oracle ASM 11.2 on IBM: Linux on System z under SLES (Doc ID 1350008.1) and How to Manually Configure Disk Storage devices for use with Oracle ASM 11.2 on IBM: Linux on System z under Red Hat 5 (Doc ID 1351746.1), available at the following URL:
<p><code dir="ltr"><a href="https://support.oracle.com">https://support.oracle.com</a></code></p>
</div>
<p>To use the Oracle Automatic Storage Management library driver (ASMLIB) to configure Oracle ASM devices, complete the following tasks.</p>
<ul>
<li>
<p><a href="#CHDFAGJD">Installing and Configuring the Oracle ASM Library Driver Software</a></p>
</li>
<li>
<p><a href="#BABJBJAA">Configuring Disk Devices to Use Oracle ASM Library Driver on x86 Systems</a></p>
</li>
<li>
<p><a href="#BABJAHHE">Configuring Disk Devices to Use ASM Library Driver on IBM: Linux on System z</a></p>
</li>
<li>
<p><a href="#BABIFHCB">Administering the Oracle ASM Library Driver and Disks</a></p>
</li>
</ul>
<div class="infobox-note">
<p class="notep1">Note:</p>
To create a database during the installation using the Oracle ASM library driver, you must choose an installation method that runs ASMCA in interactive mode. You must also change the default disk discovery string to <code dir="ltr">ORCL:*.</code></div>
<a id="CHDFAGJD"></a>
<div id="CWLIN2949" class="sect4">
<h5 class="sect4"><span class="secnum">3.3.1.4.1</span> Installing and Configuring the Oracle ASM Library Driver Software<a id="sthref592"></a><a id="sthref593"></a></h5>
<p>ASMLIB is already included with Unbreakable Enterprise Kernel packages, and with SUSE 11. If you are a member of the Unbreakable Linux Network, then you can install the ASMLIB rpms by subscribing to the Oracle Software for Enterprise Linux channel, and using <code dir="ltr">up2date</code> to retrieve the most current package for your system and kernel. For additional information, refer to the following URL:</p>
<pre dir="ltr">
<a href="http://www.oracle.com/technetwork/topics/linux/asmlib/index-101839.html">http://www.oracle.com/technetwork/topics/linux/asmlib/index-101839.html</a>
</pre>
<p>To install and configure the ASMLIB driver software manually, follow these steps:</p>
<ol>
<li>
<p>Enter the following command to determine the kernel version and architecture of the system:<a id="sthref594"></a></p>
<pre dir="ltr">
# uname -rm
</pre></li>
<li>
<p>Download the required ASMLIB packages from the Oracle Technology Network (OTN) Web site:</p>
<pre dir="ltr">
<a href="http://www.oracle.com/technetwork/server-storage/linux/downloads/index-088143.html">http://www.oracle.com/technetwork/server-storage/linux/downloads/index-088143.html</a>
</pre>
<div class="infobox-note">
<p class="notep1">Note:</p>
You must install <code dir="ltr">oracleasm-support</code> package version 2.0.1 or later to use ASMLIB on Red Hat Enterprise Linux 5 Advanced Server. ASMLIB is already included with SUSE distributions.</div>
<div class="infoboxnotealso">
<p class="notep1">Tip:</p>
My Oracle Support note 1089399.1 for information about ASMLIB support with Red Hat distributions:
<p><code dir="ltr"><a href="https://support.oracle.com/CSP/main/article?cmd=show&amp;type=NOT&amp;id=1089399.1">https://support.oracle.com/CSP/main/article?cmd=show&amp;type=NOT&amp;id=1089399.1</a></code></p>
</div>
<p>You must install the following packages, where <code dir="ltr"><span class="codeinlineitalic">version</span></code> is the version of the ASMLIB driver, <code dir="ltr"><span class="codeinlineitalic">arch</span></code> is the system architecture, and <code dir="ltr"><span class="codeinlineitalic">kernel</span></code> is the version of the kernel that you are using:</p>
<pre dir="ltr">
oracleasm-support-<span class="italic">version</span>.<span class="italic">arch</span>.rpm
oracleasm-<span class="italic">kernel</span>-<span class="italic">version</span>.<span class="italic">arch</span>.rpm
oracleasmlib-<span class="italic">version</span>.<span class="italic">arch</span>.rpm
</pre></li>
<li>
<p>Switch user to the <code dir="ltr">root</code> user:</p>
<pre dir="ltr">
$ su -
</pre></li>
<li>
<p>Enter a command similar to the following to install the packages:</p>
<pre dir="ltr">
# rpm -ivh oracleasm-support-<span class="italic">version</span>.<span class="italic">arch</span>.rpm \
           oracleasm-<span class="italic">kernel</span>-<span class="italic">version</span>.<span class="italic">arch</span>.rpm \
           oracleasmlib-<span class="italic">version</span>.<span class="italic">arch</span>.rpm
</pre>
<p>For example, if you are using the Red Hat Enterprise Linux 5 AS kernel on an AMD64 system, then enter a command similar to the following:</p>
<pre dir="ltr">
# rpm -ivh oracleasm-support-2.1.3-1.el5.x86_64.rpm \
     oracleasm-2.6.18-194.26.1.el5xen-2.0.5-1.el5.x86_64.rpm \
     oracleasmlib-2.0.4-1.el5.x86_64.rpm
</pre></li>
<li>
<p><a id="sthref595"></a><a id="sthref596"></a><a id="sthref597"></a>Enter the following command to run the <code dir="ltr">oracleasm</code> initialization script with the <code dir="ltr">configure</code> option:</p>
<pre dir="ltr">
# /usr/sbin/oracleasm configure -i
</pre>
<div class="infobox-note">
<p class="notep1">Note:</p>
The <code dir="ltr">oracleasm</code> command in <code dir="ltr">/usr/sbin</code> is the command you should use. The <code dir="ltr">/etc/init.d</code> path is not deprecated, but the <code dir="ltr">oracleasm</code> binary in that path is now used typically for internal commands.</div>
</li>
<li>
<p>Enter the following information in response to the prompts that the script displays:</p>
<div class="inftblinformal">
<table class="cellalignment2509" title="Initialization Script Prompts" summary="This table lists the inititialization script prompts and the suggested responses." dir="ltr">
<thead>
<tr class="cellalignment2496">
<th class="cellalignment2508" id="r1c1-t50">Prompt</th>
<th class="cellalignment2508" id="r1c2-t50">Suggested Response</th>
</tr>
</thead>
<tbody>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r2c1-t50" headers="r1c1-t50">Default user to own the driver interface:</td>
<td class="cellalignment2502" headers="r2c1-t50 r1c2-t50"><span class="bold">Standard groups and users configuration</span>: Specify the Oracle software owner user (for example, <code dir="ltr">oracle</code>)
<p><span class="bold">Job role separation groups and users configuration:</span> Specify the Grid Infrastructure software owner (for example, <code dir="ltr">grid</code>)</p>
</td>
</tr>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r3c1-t50" headers="r1c1-t50">Default group to own the driver interface:</td>
<td class="cellalignment2502" headers="r3c1-t50 r1c2-t50"><span class="bold">Standard groups and users configuration</span>: Specify the OSDBA group for the database (for example, <code dir="ltr">dba</code>).
<p><span class="bold">Job role separation groups and users configuration:</span> Specify the OSASM group for storage administration (for example, <code dir="ltr">asmadmin</code>).</p>
</td>
</tr>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r4c1-t50" headers="r1c1-t50">Start Oracle ASM Library driver on boot (y/n):</td>
<td class="cellalignment2502" headers="r4c1-t50 r1c2-t50">Enter <code dir="ltr">y</code> to start the Oracle Automatic Storage Management library driver when the system starts.</td>
</tr>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r5c1-t50" headers="r1c1-t50">Scan for Oracle ASM disks on boot (y/n)</td>
<td class="cellalignment2502" headers="r5c1-t50 r1c2-t50">Enter <code dir="ltr">y</code> to scan for Oracle ASM disks when the system starts.</td>
</tr>
</tbody>
</table>
<br /></div>
<!-- class="inftblinformal" -->
<p>The script completes the following tasks:</p>
<ul>
<li>
<p>Creates the <code dir="ltr">/etc/sysconfig/oracleasm</code> configuration file</p>
</li>
<li>
<p>Creates the <code dir="ltr">/dev/oracleasm</code> mount point</p>
</li>
<li>
<p>Mounts the ASMLIB driver file system</p>
<div class="infobox-note">
<p class="notep1">Note:</p>
The ASMLIB driver file system is not a regular file system. It is used only by the Oracle ASM library to communicate with the Oracle ASM driver.</div>
</li>
</ul>
</li>
<li>
<p>Enter the following command to load the <code dir="ltr">oracleasm</code> kernel module:</p>
<pre dir="ltr">
# /usr/sbin/oracleasm init
</pre></li>
<li>
<p>Repeat this procedure on all nodes in the cluster where you want to install Oracle RAC.</p>
</li>
</ol>
</div>
<!-- class="sect4" -->
<a id="BABJBJAA"></a>
<div id="CWLIN295" class="sect4"><a id="CIBEJBDC"></a>
<h5 class="sect4"><span class="secnum">3.3.1.4.2</span> Configuring Disk Devices to Use Oracle ASM Library Driver on x86 Systems</h5>
<p>To configure the disk devices to use in an Oracle ASM disk group, follow these steps:</p>
<ol>
<li>
<p>If you intend to use IDE, SCSI, or RAID devices in the Oracle ASM disk group, then follow these steps:</p>
<ol>
<li>
<p>If necessary, install or configure the shared disk devices that you intend to use for the disk group and restart the system.<a id="sthref598"></a></p>
</li>
<li>
<p>To identify the device name for the disks to use, enter the following command:<a id="sthref599"></a><a id="sthref600"></a><a id="sthref601"></a><a id="sthref602"></a><a id="sthref603"></a><a id="sthref604"></a><a id="sthref605"></a><a id="sthref606"></a></p>
<pre dir="ltr">
# /sbin/fdisk -l
</pre>
<p>Depending on the type of disk, the device name can vary:<a id="sthref607"></a></p>
<div class="inftblhruleinformal">
<table class="cellalignment2509" title="Disk Device Name Formats on Linux" summary="This table shows the format of Linux disk device names" dir="ltr">
<thead>
<tr class="cellalignment2496">
<th class="cellalignment2508" id="r1c1-t52">Disk Type</th>
<th class="cellalignment2508" id="r1c2-t52">Device Name Format</th>
<th class="cellalignment2508" id="r1c3-t52">Description</th>
</tr>
</thead>
<tbody>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r2c1-t52" headers="r1c1-t52"><a id="sthref608"></a><a id="sthref609"></a>IDE disk</td>
<td class="cellalignment2502" headers="r2c1-t52 r1c2-t52">
<pre dir="ltr">
/dev/hd<span class="italic">xn</span>
</pre></td>
<td class="cellalignment2502" headers="r2c1-t52 r1c3-t52">In this example, <code dir="ltr"><span class="codeinlineitalic">x</span></code> is a letter that identifies the IDE disk and <code dir="ltr"><span class="codeinlineitalic">n</span></code> is the partition number. For example, <code dir="ltr">/dev/hda</code> is the first disk on the first IDE bus.</td>
</tr>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r3c1-t52" headers="r1c1-t52"><a id="sthref610"></a><a id="sthref611"></a>SCSI disk</td>
<td class="cellalignment2502" headers="r3c1-t52 r1c2-t52">
<pre dir="ltr">
/dev/sd<span class="italic">xn</span>
</pre></td>
<td class="cellalignment2502" headers="r3c1-t52 r1c3-t52">In this example, <code dir="ltr"><span class="codeinlineitalic">x</span></code> is a letter that identifies the SCSI disk and <code dir="ltr"><span class="codeinlineitalic">n</span></code> is the partition number. For example, <code dir="ltr">/dev/sda</code> is the first disk on the first SCSI bus.</td>
</tr>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r4c1-t52" headers="r1c1-t52"><a id="sthref612"></a><a id="sthref613"></a>RAID disk</td>
<td class="cellalignment2502" headers="r4c1-t52 r1c2-t52">
<pre dir="ltr">
/dev/rd/c<span class="italic">x</span>d<span class="italic">y</span>p<span class="italic">z</span>
/dev/ida/c<span class="italic">x</span>d<span class="italic">y</span>p<span class="italic">z</span>
</pre></td>
<td class="cellalignment2502" headers="r4c1-t52 r1c3-t52">Depending on the RAID controller, RAID devices can have different device names. In the examples shown, <code dir="ltr"><span class="codeinlineitalic">x</span></code> is a number that identifies the controller, <code dir="ltr"><span class="codeinlineitalic">y</span></code> is a number that identifies the disk, and <code dir="ltr"><span class="codeinlineitalic">z</span></code> is a number that identifies the partition. For example, <code dir="ltr">/dev/ida/c0d1</code> is the second logical drive on the first controller.</td>
</tr>
</tbody>
</table>
<br /></div>
<!-- class="inftblhruleinformal" -->
<p><a id="sthref614"></a><a id="sthref615"></a>To include devices in a disk group, you can specify either whole-drive device names or partition device names.</p>
<div class="infobox-note">
<p class="notep1">Note:</p>
Oracle recommends that you create a single whole-disk partition on each disk.</div>
</li>
<li>
<p>Use either <code dir="ltr">fdisk</code> or <code dir="ltr">parted</code> to create a single whole-disk partition on the disk devices.</p>
</li>
</ol>
</li>
<li>
<p>Enter a command similar to the following to mark a disk as an Oracle ASM disk:</p>
<pre dir="ltr">
# /usr/sbin/oracleasm createdisk DISK1 /dev/sdb1
</pre>
<p>In this example, <code dir="ltr">DISK1</code> is the name you assign to the disk.</p>
<div class="infobox-note">
<p class="notep1">Note:</p>
The disk names that you specify can contain uppercase letters, numbers, and the underscore character. They must start with an uppercase letter.
<p>If you are using a multi-pathing disk driver with Oracle ASM, then make sure that you specify the correct logical device name for the disk.</p>
</div>
</li>
<li>
<p>To make the disk available on the other nodes in the cluster, enter the following command as <code dir="ltr">root</code> on each node:</p>
<pre dir="ltr">
# /usr/sbin/oracleasm scandisks
</pre>
<p>This command identifies shared disks attached to the node that are marked as Oracle ASM disks.</p>
</li>
</ol>
</div>
<!-- class="sect4" -->
<a id="BABJAHHE"></a>
<div id="CWLIN296" class="sect4"><a id="CDEGCBBF"></a>
<h5 class="sect4"><span class="secnum">3.3.1.4.3</span> Configuring Disk Devices to Use ASM Library Driver on IBM: Linux on System z</h5>
<ol>
<li>
<p>If you formatted the DASD with the compatible disk layout, then enter a command similar to the following to create a single whole-disk partition on the device:</p>
<pre dir="ltr">
# /sbin/fdasd -a /dev/dasdxxxx
</pre></li>
<li>
<p>Enter a command similar to the following to mark a disk as an ASM disk:</p>
<pre dir="ltr">
# /etc/init.d/oracleasm createdisk DISK1 /dev/dasdxxxx
</pre>
<p>In this example, <code dir="ltr">DISK1</code> is a name that you want to assign to the disk.</p>
<div class="infobox-note">
<p class="notep1">Note:</p>
The disk names that you specify can contain uppercase letters, numbers, and the underscore character. They must start with an uppercase letter.
<p>If you are using a multi-pathing disk driver with ASM, then make sure that you specify the correct logical device name for the disk.</p>
</div>
</li>
<li>
<p>To make the disk available on the other cluster nodes, enter the following command as root on each node:</p>
<pre dir="ltr">
# /etc/init.d/oracleasm scandisks
</pre>
<p>This command identifies shared disks attached to the node that are marked as ASM disks.</p>
</li>
</ol>
</div>
<!-- class="sect4" -->
<a id="BABIFHCB"></a>
<div id="CWLIN297" class="sect4"><a id="CIBBJJAC"></a>
<h5 class="sect4"><span class="secnum">3.3.1.4.4</span> Administering the Oracle ASM Library Driver and Disks</h5>
<p>To administer the Oracle Automatic Storage Management library driver (ASMLIB) and disks, use the <code dir="ltr">oracleasm</code> initialization script with different options, as described in <a href="#CDEBEBCG">Table 3-7</a>.</p>
<div id="CWLIN298" class="tblformal">
<p class="titleintable"><a id="sthref616"></a><a id="CDEBEBCG"></a>Table 3-7 ORACLEASM Script Options</p>
<table class="cellalignment2507" title="ORACLEASM Script Options" summary="This table lists the options available with the oracleasm script" dir="ltr">
<thead>
<tr class="cellalignment2496">
<th class="cellalignment2508" id="r1c1-t56">Option</th>
<th class="cellalignment2508" id="r1c2-t56">Description</th>
</tr>
</thead>
<tbody>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r2c1-t56" headers="r1c1-t56">
<pre dir="ltr">
configure
</pre></td>
<td class="cellalignment2502" headers="r2c1-t56 r1c2-t56">
<p>Use the <code dir="ltr">configure</code> option to reconfigure the Oracle Automatic Storage Management library driver, if necessary:</p>
<pre dir="ltr">
# /usr/sbin/oracleasm configure -i
</pre>
<p>To see command options, enter <code dir="ltr">oracleasm configure</code> without the <code dir="ltr">-i</code> flag.</p>
</td>
</tr>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r3c1-t56" headers="r1c1-t56">
<pre dir="ltr">
enable
disable
</pre></td>
<td class="cellalignment2502" headers="r3c1-t56 r1c2-t56">
<p>Use the <code dir="ltr">disable</code> and <code dir="ltr">enable</code> options to change the actions of the Oracle Automatic Storage Management library driver when the system starts. The <code dir="ltr">enable</code> option causes the Oracle Automatic Storage Management library driver to load when the system starts:</p>
<pre dir="ltr">
# /usr/sbin/oracleasm enable
</pre></td>
</tr>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r4c1-t56" headers="r1c1-t56">
<pre dir="ltr">
start
stop
restart
</pre></td>
<td class="cellalignment2502" headers="r4c1-t56 r1c2-t56">
<p>Use the <code dir="ltr">start</code>, <code dir="ltr">stop</code>, and <code dir="ltr">restart</code> options to load or unload the Oracle Automatic Storage Management library driver without restarting the system:</p>
<pre dir="ltr">
# /usr/sbin/oracleasm restart
</pre></td>
</tr>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r5c1-t56" headers="r1c1-t56">
<pre dir="ltr">
createdisk
</pre></td>
<td class="cellalignment2502" headers="r5c1-t56 r1c2-t56">
<p>Use the <code dir="ltr">createdisk</code> option to mark a disk device for use with the Oracle Automatic Storage Management library driver and give it a name:</p>
<pre dir="ltr">
# /usr/sbin/oracleasm createdisk <span class="italic">DISKNAME</span> <span class="italic">devicename</span>
</pre></td>
</tr>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r6c1-t56" headers="r1c1-t56">
<pre dir="ltr">
deletedisk
</pre></td>
<td class="cellalignment2502" headers="r6c1-t56 r1c2-t56">
<p>Use the <code dir="ltr">deletedisk</code> option to unmark a named disk device:</p>
<pre dir="ltr">
# /usr/sbin/oracleasm deletedisk <span class="italic">DISKNAME</span>
</pre>
<p><span class="bold">Caution:</span> Do not use this command to unmark disks that are being used by an Oracle Automatic Storage Management disk group. You must delete the disk from the Oracle Automatic Storage Management disk group before you unmark it.</p>
</td>
</tr>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r7c1-t56" headers="r1c1-t56">
<pre dir="ltr">
querydisk
</pre></td>
<td class="cellalignment2502" headers="r7c1-t56 r1c2-t56">
<p>Use the <code dir="ltr">querydisk</code> option to determine if a disk device or disk name is being used by the Oracle Automatic Storage Management library driver:</p>
<pre dir="ltr">
# /usr/sbin/oracleasm querydisk {<span class="italic">DISKNAME </span>| <span class="italic">devicename</span>}
</pre></td>
</tr>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r8c1-t56" headers="r1c1-t56">
<pre dir="ltr">
listdisks
</pre></td>
<td class="cellalignment2502" headers="r8c1-t56 r1c2-t56">
<p>Use the <code dir="ltr">listdisks</code> option to list the disk names of marked Oracle Automatic Storage Management library driver disks:</p>
<pre dir="ltr">
# /usr/sbin/oracleasm listdisks
</pre></td>
</tr>
<tr class="cellalignment2496">
<td class="cellalignment2502" id="r9c1-t56" headers="r1c1-t56">
<pre dir="ltr">
scandisks
</pre></td>
<td class="cellalignment2502" headers="r9c1-t56 r1c2-t56">
<p>Use the <code dir="ltr">scandisks</code> option to enable cluster nodes to identify which shared disks have been marked as Oracle Automatic Storage Management library driver disks on another node:</p>
<pre dir="ltr">
# /usr/sbin/oracleasm scandisks
</pre></td>
</tr>
</tbody>
</table>
<br /></div>
<!-- class="tblformal" --></div>
<!-- class="sect4" --></div>
<!-- class="sect3" -->
<a id="CDEFFBDJ"></a>
<div id="CWLIN299" class="sect3">
<h4 class="sect3"><span class="secnum">3.3.1.5</span> Configuring ASMLIB for Multipath Disks</h4>
<p>Additional configuration is required to use the Oracle Automatic Storage Management library Driver (ASMLIB) with third party vendor multipath disks.</p>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
My Oracle Support site for updates to supported storage options:
<pre dir="ltr">
<a href="https://support.oracle.com">https://support.oracle.com</a>
</pre></div>
<div id="CWLIN300" class="sect4"><a id="sthref617"></a>
<h5 class="sect4"><span class="secnum">3.3.1.5.1</span> About Using Oracle ASM with Multipath Disks</h5>
<p>Oracle ASM requires that each disk is uniquely identified. If the same disk appears under multiple paths, then it causes errors. In a multipath disk configuration, the same disk can appear three times:</p>
<ol>
<li>
<p>The initial path to the disk</p>
</li>
<li>
<p>The second path to the disk</p>
</li>
<li>
<p>The multipath disk access point.</p>
</li>
</ol>
<p>For example: If you have one local disk, <code dir="ltr">/dev/sda</code>, and one disk attached with external storage, then your server shows two connections, or paths, to that external storage. The Linux SCSI driver shows both paths. They appear as <code dir="ltr">/dev/sdb</code> and <code dir="ltr">/dev/sdc</code>. The system may access either <code dir="ltr">/dev/sdb</code> or <code dir="ltr">/dev/sdc</code>, but the access is to the same disk.</p>
<p>If you enable multipathing, then you have a multipath disk (for example, <code dir="ltr">/dev/multipatha</code>), which can access both <code dir="ltr">/dev/sdb</code> and <code dir="ltr">/dev sdc</code>; any I/O to <code dir="ltr">multipatha</code> can use either the <code dir="ltr">sdb</code> or <code dir="ltr">sdc</code> path. If a system is using the <code dir="ltr">/dev/sdb</code> path, and that cable is unplugged, then the system shows an error. But the multipath disk will switch from the <code dir="ltr">/dev/sdb</code> path to the <code dir="ltr">/dev/sdc</code> path.</p>
<p>Most system software is unaware of multipath configurations. They can use any paths (<code dir="ltr">sdb</code>, <code dir="ltr">sdc</code> or <code dir="ltr">multipatha</code>). ASMLIB also is unaware of multipath configurations.</p>
<p>By default, ASMLIB recognizes the first disk path that Linux reports to it, but because it imprints an identity on that disk, it recognizes that disk only under one path. Depending on your storage driver, it may recognize the multipath disk, or it may recognize one of the single disk paths.</p>
<p>Instead of relying on the default, you should configure Oracle ASM to recognize the multipath disk.</p>
</div>
<!-- class="sect4" -->
<div id="CWLIN301" class="sect4"><!-- infolevel="all" infotype="General" --><a id="sthref618"></a>
<h5 class="sect4"><span class="secnum">3.3.1.5.2</span> Disk Scan Ordering</h5>
<p>The <a id="sthref619"></a>ASMLIB configuration file is located in the path <code dir="ltr">/etc/sysconfig/oracleasm</code>. It contains all the startup configuration you specified with the command <code dir="ltr">/etc/init.d/oracleasm configure</code>. That command cannot configure scan ordering.</p>
<p>The configuration file contains many configuration variables. The <code dir="ltr">ORACLEASM_SCANORDER</code> variable specifies disks to be scanned first. The <code dir="ltr">ORACLEASM_SCANEXCLUDE</code> variable specifies the disks that are to be ignored.</p>
<p>Configure values for <code dir="ltr">ORACLEASM_SCANORDER</code> using space-delimited prefix strings. A <span class="italic">prefix string</span> is the common string associated with a type of disk. For example, if you use the prefix string <code dir="ltr">sd</code>, then this string matches all SCSI devices, including <code dir="ltr">/dev/sda</code>, <code dir="ltr">/dev/sdb</code>, <code dir="ltr">/dev/sdc</code> and so on. Note that these are not globs. They do not use wild cards. They are simple prefixes. Also note that the path is not a part of the prefix. For example, the <code dir="ltr">/dev/</code> path is not part of the prefix for SCSI disks that are in the path <code dir="ltr">/dev/sd</code>*.</p>
<p>For Oracle Linux and Red Hat Enterprise Linux version 5, when scanning, the kernel sees the devices as <code dir="ltr">/dev/mapper/</code><code dir="ltr"><span class="codeinlineitalic">XXX</span></code> entries. By default, the 2.6 kernel device file naming scheme <code dir="ltr">udev</code> creates the <code dir="ltr">/dev/mapper/</code><code dir="ltr"><span class="codeinlineitalic">XXX</span></code> names for human readability. Any configuration using <code dir="ltr">ORACLEASM_SCANORDER</code> should use the <code dir="ltr">/dev/mapper/</code><code dir="ltr"><span class="codeinlineitalic">XXX</span></code> entries.</p>
</div>
<!-- class="sect4" -->
<div id="CWLIN302" class="sect4"><!-- infolevel="all" infotype="General" --><a id="sthref620"></a>
<h5 class="sect4"><span class="secnum">3.3.1.5.3</span> Configuring Disk Scan Ordering to Select Multipath Disks</h5>
<p>To configure ASMLIB to select multipath disks first, complete the following procedure:</p>
<ol>
<li>
<p>Using a text editor, open the ASMLIB configuration file <code dir="ltr">/etc/sysconfig/oracleasm</code>.</p>
</li>
<li>
<p>Edit the ORACLEASM_SCANORDER variable to provide the prefix path of the multipath disks. For example, if the multipath disks use the prefix <code dir="ltr">multipath</code> (<code dir="ltr">/dev/mapper/multipatha</code>, <code dir="ltr">/dev/mapper/multipathb</code> and so on), and the multipath disks mount SCSI disks, then provide a prefix path similar to the following:</p>
<pre dir="ltr">
ORACLEASM_SCANORDER="multipath sd"
</pre></li>
<li>
<p>Save the file.</p>
</li>
</ol>
<p>When you have completed this procedure, then when ASMLIB scans disks, it first scans all disks with the prefix string multipath, and labels these disks as Oracle ASM disks using the <code dir="ltr">/dev/mapper/multipath</code><code dir="ltr"><span class="codeinlineitalic">X</span></code> value. It then scans all disks with the prefix string <code dir="ltr">sd</code>. However, because ASMLIB recognizes that these disks have already been labeled with the <code dir="ltr">/dev/mapper/multipath</code> string values, it ignores these disks. After scanning for the prefix strings <code dir="ltr">multipath</code> and <code dir="ltr">sd</code>, Oracle ASM then scans for any other disks that do not match the scan order.</p>
<p>In the example in step 2, the key word multipath is actually the alias for multipath devices configured in <code dir="ltr">/etc/multipath.conf</code> under the <code dir="ltr">multipaths</code> section. For example:</p>
<pre dir="ltr">
multipaths {
       multipath {
               wwid                    3600508b4000156d700012000000b0000
               alias                   multipath
               ...
       }
       multipath {
               ...
               alias                   mympath
               ...
       }
       ...
}
</pre>
<p>The default device name is in the format /dev/mapper/mpath* (or a similar path).</p>
</div>
<!-- class="sect4" -->
<div id="CWLIN303" class="sect4"><!-- infolevel="all" infotype="General" --><a id="sthref621"></a>
<h5 class="sect4"><span class="secnum">3.3.1.5.4</span> Configuring Disk Order Scan to Exclude Single Path Disks</h5>
<p>To configure ASMLIB to exclude particular single path disks, complete the following procedure:</p>
<ol>
<li>
<p>Using a text editor, open the ASMLIB configuration file <code dir="ltr">/etc/sysconfig/oracleasm</code>.</p>
</li>
<li>
<p>Edit the <code dir="ltr">ORACLEASM_SCANEXCLUDE</code> variable to provide the prefix path of the single path disks. For example, if you want to exclude the single path disks <code dir="ltr">/dev sdb</code> and <code dir="ltr">/dev/sdc</code>, then provide a prefix path similar to the following:</p>
<pre dir="ltr">
ORACLEASM_SCANEXCLUDE="sdb sdc"
</pre></li>
<li>
<p>Save the file.</p>
</li>
</ol>
<p>When you have completed this procedure, then when ASMLIB scans disks, it scans all disks except for the disks with the <code dir="ltr">sdb</code> and <code dir="ltr">sdc</code> prefixes, so that it ignores <code dir="ltr">/dev/sdb</code> and <code dir="ltr">/dev/sdc</code>. It does not ignore other SCSI disks, nor multipath disks. If you have a multipath disk (for example, <code dir="ltr">/dev/multipatha</code>), which accesses both <code dir="ltr">/dev/sdb</code> and <code dir="ltr">/dev sdc</code>, but you have configured ASMLIB to ignore <code dir="ltr">sdb</code> and <code dir="ltr">sdc</code>, then ASMLIB ignores these disks and instead marks only the multipath disk as an Oracle ASM disk.</p>
</div>
<!-- class="sect4" --></div>
<!-- class="sect3" -->
<a id="CDEBFDEH"></a>
<div id="CWLIN304" class="sect3">
<h4 class="sect3"><span class="secnum">3.3.1.6</span> Configuring Disk Devices Manually for Oracle ASM<a id="sthref622"></a><a id="sthref623"></a><a id="sthref624"></a></h4>
<p>By default, the 2.6 kernel device file naming scheme <code dir="ltr">udev</code> dynamically creates device file names when the server is started, and assigns ownership of them to <code dir="ltr">root</code>. If <code dir="ltr">udev</code> applies default settings, then it changes device file names and owners for voting disks or Oracle Cluster Registry partitions, corrupting them when the server is restarted. For example, a voting disk on a device named <code dir="ltr">/dev/sdd</code> owned by the user <code dir="ltr">grid</code> may be on a device named <code dir="ltr">/dev/sdf</code> owned by <code dir="ltr">root</code> after restarting the server.If you use ASMLIB, then you do not need to ensure permissions and device path persistency in <code dir="ltr">udev</code>.</p>
<p>If you do not use ASMLIB, then you must create a custom rules file. When <code dir="ltr">udev</code> is started, it sequentially carries out rules (configuration directives) defined in rules files. These files are in the path <code dir="ltr">/etc/udev/rules.d/</code>. Rules files are read in lexical order. For example, rules in the file <code dir="ltr">10-wacom.rules</code> are parsed and carried out before rules in the rules file <code dir="ltr">90-ib.rules</code>.</p>
<p>When specifying the device information in the UDEV rules file, ensure that the OWNER, GROUP and MODE are specified before any other characteristics in the order shown. For example, if you want to include the characteristic ACTION on the UDEV line, then specify ACTION after OWNER, GROUP, and MODE.</p>
<p>Where rules files describe the same devices, on the supported Linux kernel versions, the last file read is the one that is applied.</p>
<p>To configure a permissions file for disk devices, complete the following tasks:</p>
<ol>
<li>
<p>To obtain information about existing block devices, run the command <code dir="ltr">scsi_id</code> (<code dir="ltr">/sbin/scsi_id</code>) on storage devices from one cluster node to obtain their unique device identifiers. When running the <code dir="ltr">scsi_id</code> command with the <code dir="ltr">-s</code> argument, the device path and name passed should be that relative to the <code dir="ltr">sysfs</code> directory <code dir="ltr">/sys</code> (for example, <code dir="ltr">/block/device</code>) when referring to <code dir="ltr">/sys/block/device</code>. For example:</p>
<pre dir="ltr">
# /sbin/scsi_id -g -s /block/sdb/sdb1
360a98000686f6959684a453333524174
 
# /sbin/scsi_id -g -s /block/sde/sde1
360a98000686f6959684a453333524179
</pre>
<p>Record the unique SCSI identifiers of clusterware devices, so you can provide them when required.</p>
<div class="infobox-note">
<p class="notep1">Note:</p>
The command <code dir="ltr">scsi_id</code> should return the same device identifier value for a given device, regardless of which node the command is run from.</div>
</li>
<li>
<p>Configure SCSI devices as trusted devices (white listed), by editing the <code dir="ltr">/etc/scsi_id.config</code> file and adding <code dir="ltr">options=-g</code> to the file. For example:</p>
<pre dir="ltr">
# cat &gt; /etc/scsi_id.config
vendor="ATA",options=-p 0x80
options=-g
</pre></li>
<li>
<p>Using a text editor, create a UDEV rules file for the Oracle ASM devices, setting permissions to 0660 for the installation owner and the group whose members are administrators of the Oracle Grid Infrastructure software. For example, using the installation owner <code dir="ltr">grid</code> and using a role-based group configuration, with the OSASM group <code dir="ltr">asmadmin</code>:</p>
<pre dir="ltr">
# vi /etc/udev/rules.d/99-oracle-asmdevices.rules

KERNEL=="sd?1", BUS=="scsi", PROGRAM=="/sbin/scsi_id",
RESULT=="14f70656e66696c00000000", OWNER="grid", GROUP="asmadmin", MODE="0660"
KERNEL=="sd?2", BUS=="scsi", PROGRAM=="/sbin/scsi_id",
RESULT=="14f70656e66696c00000001", OWNER="grid", GROUP="asmadmin", MODE="0660"
KERNEL=="sd?3", BUS=="scsi", PROGRAM=="/sbin/scsi_id",
RESULT=="14f70656e66696c00000002", OWNER="grid", GROUP="asmadmin", MODE="0660"
</pre></li>
<li>
<p>Copy the <code dir="ltr">rules.d</code> file to all other nodes on the cluster. For example:</p>
<pre dir="ltr">
# scp 99-oracle-asmdevices.rules root@node2:/etc/udev/rules.d/99-oracle-asmdevices.rules
</pre></li>
<li>
<p>Load updated block device partition tables on all member nodes of the cluster, using <code dir="ltr">/sbin/partprobe</code> <code dir="ltr"><span class="codeinlineitalic">devicename</span></code>.<a id="sthref625"></a> You must do this as <code dir="ltr">root</code>.</p>
</li>
<li>
<p>Run the command <code dir="ltr">udevtest</code> (<code dir="ltr">/sbin/udevtest</code>) to test the UDEV rules configuration you have created. The output should indicate that the block devices are available and the rules are applied as expected. For example:</p>
<pre dir="ltr">
# udevtest /block/sdb/sdb1
main: looking at device '/block/sdb/sdb1' from subsystem 'block'
udev_rules_get_name: add symlink
'disk/by-id/scsi-360a98000686f6959684a453333524174-part1'
udev_rules_get_name: add symlink
'disk/by-path/ip-192.168.1.1:3260-iscsi-iqn.1992-08.com.netapp:sn.887085-part1'
udev_node_mknod: preserve file '/dev/.tmp-8-17', because it has correct dev_t
run_program: '/lib/udev/vol_id --export /dev/.tmp-8-17'
run_program: '/lib/udev/vol_id' returned with status 4
run_program: '/sbin/scsi_id'
run_program: '/sbin/scsi_id' (stdout) '360a98000686f6959684a453333524174'
run_program: '/sbin/scsi_id' returned with status 0
udev_rules_get_name: rule applied, 'sdb1' becomes 'ocr1'
udev_device_event: device '/block/sdb/sdb1' validate currently present symlinks
udev_node_add: creating device node '/dev/ocr1', major = '8', minor = '17', 
mode = '0640', uid = '0', gid = '500'
udev_node_add: creating symlink
'/dev/disk/by-id/scsi-360a98000686f6959684a453333524174-part1' to '../../ocr1'
udev_node_add: creating symlink
'/dev/disk/by-path/ip-192.168.1.1:3260-iscsi-iqn.1992-08.com.netapp:sn.84187085
-part1' to '../../ocr1'
main: run: 'socket:/org/kernel/udev/monitor'
main: run: '/lib/udev/udev_run_devd'
main: run: 'socket:/org/freedesktop/hal/udev_event'
main: run: '/sbin/pam_console_apply /dev/ocr1
/dev/disk/by-id/scsi-360a98000686f6959684a453333524174-part1
/dev/disk/by-path/ip-192.168.1.1:3260-iscsi-iqn.1992-08.com.netapp:sn.84187085-
part1'
</pre>
<p>In the example output, note that applying the rules renames OCR device <code dir="ltr">/dev/sdb1</code> to <code dir="ltr">/dev/ocr1</code>.</p>
</li>
<li>
<p>Enter the command to restart the UDEV service.</p>
<p>On Asianux, Oracle Linux 5, and RHEL5, the commands are:</p>
<pre dir="ltr">
# /sbin/udevcontrol reload_rules
# /sbin/start_udev
</pre>
<p>On SUSE 10 and 11, the command is:</p>
<pre dir="ltr">
# /etc/init.d boot.udev restart
</pre></li>
</ol>
</div>
<!-- class="sect3" --></div>
<!-- class="sect2" -->
<a id="CDEDGAFJ"></a>
<div id="CWLIN306" class="sect2">
<h3 class="sect2"><span class="secnum">3.3.2</span> Using Disk Groups with Oracle Database Files on Oracle ASM</h3>
<p>Review the following sections to configure Oracle Automatic Storage Management (Oracle ASM) storage for Oracle Clusterware and Oracle Database Files:</p>
<ul>
<li>
<p><a href="#CDEDEIAD">Identifying and Using Existing Oracle Database Diskgroups on Oracle ASM</a></p>
</li>
<li>
<p><a href="#CDEBAADD">Creating Diskgroups for Oracle Database Data Files</a></p>
</li>
</ul>
<a id="CDEDEIAD"></a>
<div id="CWLIN307" class="sect3"><!-- infolevel="all" infotype="General" -->
<h4 class="sect3"><span class="secnum">3.3.2.1</span> Identifying and Using Existing Oracle Database Diskgroups on Oracle ASM</h4>
<p>The following section describes how to identify existing disk groups and determine the free disk space that they contain.</p>
<ul>
<li>
<p>Optionally, identify failure groups for the Oracle ASM disk group devices.<a id="sthref626"></a><a id="sthref627"></a><a id="sthref628"></a></p>
<p><a id="sthref629"></a><a id="sthref630"></a><a id="sthref631"></a><a id="sthref632"></a><a id="sthref633"></a>If you intend to use a normal or high redundancy disk group, then you can further protect your database against hardware failure by associating a set of disk devices in a custom failure group. By default, each device comprises its own failure group. However, if two disk devices in a normal redundancy disk group are attached to the same SCSI controller, then the disk group becomes unavailable if the controller fails. The controller in this example is a single point of failure.</p>
<p>To protect against failures of this type, you could use two SCSI controllers, each with two disks, and define a failure group for the disks attached to each controller. This configuration would enable the disk group to tolerate the failure of one SCSI controller.</p>
<div class="infobox-note">
<p class="notep1">Note:</p>
If you define custom failure groups, then you must specify a minimum of two failure groups for normal redundancy and three failure groups for high redundancy.</div>
</li>
</ul>
</div>
<!-- class="sect3" -->
<a id="CDEBAADD"></a>
<div id="CWLIN308" class="sect3">
<h4 class="sect3"><span class="secnum">3.3.2.2</span> Creating Diskgroups for Oracle Database Data Files</h4>
<p>If you are sure that a suitable disk group does not exist on the system, then install or identify appropriate disk devices to add to a new disk group. Use the following guidelines when identifying appropriate disk devices:</p>
<ul>
<li>
<p>All of the devices in an Oracle ASM disk group should be the same size and have the same performance characteristics.</p>
</li>
<li>
<p>Do not specify multiple partitions on a single physical disk as a disk group device. Oracle ASM expects each disk group device to be on a separate physical disk.</p>
</li>
<li>
<p>Although you can specify a logical volume as a device in an Oracle ASM disk group, Oracle does not recommend their use because it adds a layer of complexity that is unnecessary with Oracle ASM. In addition, Oracle RAC requires a cluster logical volume manager in case you decide to use a logical volume with Oracle ASM and Oracle RAC.</p>
</li>
</ul>
</div>
<!-- class="sect3" --></div>
<!-- class="sect2" -->
<a id="CFAFBFJA"></a>
<div id="CWLIN309" class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2"><span class="secnum">3.3.3</span> Configuring Oracle Automatic Storage Management Cluster File System</h3>
<p>Oracle ACFS is installed as part of an Oracle Grid Infrastructure installation (Oracle Clusterware and Oracle Automatic Storage Management) for 11<span class="italic">g</span> release 2 (11.2).</p>
<p>You can also create a General Purpose File System configuration of ACFS using ASMCA.</p>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<a href="#CHDDGHHD">Section 3.1.3, "General Information About Oracle ACFS"</a> for supported deployment options</div>
<p>To configure Oracle ACFS for an Oracle Database home for an Oracle RAC database:</p>
<ol>
<li>
<p>Install Oracle Grid Infrastructure for a cluster (Oracle Clusterware and Oracle Automatic Storage Management)</p>
</li>
<li>
<p>Change directory to the Oracle Grid Infrastructure home. For example:</p>
<pre dir="ltr">
$ cd /u01/app/11.2.0/grid
</pre></li>
<li>
<p>Ensure that the Oracle Grid Infrastructure installation owner has read and write permissions on the storage mountpoint you want to use. For example, if you want to use the mountpoint <code dir="ltr">/u02/acfsmounts/</code>:</p>
<pre dir="ltr">
$ ls -l /u02/acfsmounts
</pre></li>
<li>
<p><a id="sthref634"></a>Start Oracle ASM Configuration Assistant as the grid installation owner. For example:</p>
<pre dir="ltr">
./asmca
</pre></li>
<li>
<p>The Configure ASM: ASM Disk Groups page shows you the Oracle ASM disk group you created during installation. Click the <span class="bold">ASM Cluster File Systems</span> tab.</p>
</li>
<li>
<p>On the ASM Cluster File Systems page, right-click the Data disk, then select <span class="bold">Create ACFS for Database Home</span>.</p>
</li>
<li>
<p>In the Create ACFS Hosted Database Home window, enter the following information:</p>
<ul>
<li>
<p><span class="bold">Database Home ADVM Volume Device Name</span>: Enter the name of the database home. The name must be unique in your enterprise. For example: <code dir="ltr">dbase_01</code></p>
</li>
<li>
<p><span class="bold">Database Home Mountpoint</span>: Enter the directory path for the mount point. For example: <code dir="ltr">/u02/acfsmounts/dbase_01</code></p>
<p>Make a note of this mount point for future reference.</p>
</li>
<li>
<p><span class="bold">Database Home Size (GB</span>): Enter in gigabytes the size you want the database home to be.</p>
</li>
<li>
<p><span class="bold">Database Home Owner Name</span>: Enter the name of the Oracle Database installation owner you plan to use to install the database. For example: <code dir="ltr">oracle</code>1</p>
</li>
<li>
<p><span class="bold">Database Home Owner Group</span>: Enter the OSDBA group whose members you plan to provide when you install the database. Members of this group are given operating system authentication for the SYSDBA privileges on the database. For example: <code dir="ltr">dba1</code></p>
</li>
<li>
<p>Click <span class="bold">OK</span> when you have completed your entries.</p>
</li>
</ul>
</li>
<li>
<p>Run the script generated by Oracle ASM Configuration Assistant as a privileged user (<code dir="ltr">root</code>). On an Oracle Clusterware environment, the script registers the ACFS as a resource managed by Oracle Clusterware. Registering ACFS as a resource helps Oracle Clusterware to mount the ACFS automatically in proper order when ACFS is used for an Oracle RAC database Home.</p>
</li>
<li>
<p>During Oracle RAC installation, ensure that you or the DBA who installs Oracle RAC selects for the Oracle home the mount point you provided in the <span class="bold">Database Home Mountpoint</span> field (in the preceding example, <code dir="ltr">/u02/acfsmounts/dbase_01</code>).</p>
</li>
</ol>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<a class="olink OSTMG" href="../../server.112/e18951/toc.htm"><span class="italic">Oracle Automatic Storage Management Administrator's Guide</span></a> for more information about configuring and managing your storage with Oracle ACFS</div>
</div>
<!-- class="sect2" -->
<a id="CFAGEIFE"></a>
<div id="CWLIN310" class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2"><span class="secnum">3.3.4</span> Upgrading Existing Oracle ASM Instances</h3>
<p>If you have an Oracle ASM installation from a prior release installed on your server, or in an existing Oracle Clusterware installation, then you can use Oracle Automatic Storage Management Configuration Assistant (ASMCA, located in the path <code dir="ltr"><span class="codeinlineitalic">Grid_home</span></code><code dir="ltr">/bin</code>) to upgrade the existing Oracle ASM instance to 11<span class="italic">g</span> release 2 (11.2), and subsequently configure failure groups, Oracle ASM volumes and Oracle Automatic Storage Management Cluster File System (Oracle ACFS).</p>
<div class="infoboxnotealso">
<p class="notep1">Note:</p>
You must first shut down all database instances and applications on the node with the existing Oracle ASM instance before upgrading it.</div>
<p>During installation, if you are upgrading from an Oracle ASM release prior to 11.2, and you chose to use Oracle ASM and ASMCA detects that there is a prior Oracle ASM version installed in another Oracle ASM home, then after installing the Oracle ASM 11<span class="italic">g</span> release 2 (11.2) binaries, you can start ASMCA to upgrade the existing Oracle ASM instance. You can then choose to configure an Oracle ACFS deployment by creating Oracle ASM volumes and using the upgraded Oracle ASM to create the Oracle ACFS.</p>
<p>If you are upgrading from Oracle ASM 11<span class="italic">g</span> release 2 (11.2.0.1) or later, then Oracle ASM is always upgraded with Oracle Grid Infrastructure as part of the rolling upgrade, and ASMCA is started by the root scripts during upgrade. ASMCA cannot perform a separate upgrade of Oracle ASM from release 11.2.0.1 to 11.2.0.2.</p>
<p>On an existing Oracle Clusterware or Oracle RAC installation, if the prior version of Oracle ASM instances on all nodes is 11<span class="italic">g</span> release 1, then you are provided with the option to perform a rolling upgrade of Oracle ASM instances. If the prior version of Oracle ASM instances on an Oracle RAC installation are from a release prior to 11<span class="italic">g</span> release 1, then rolling upgrades cannot be performed. Oracle ASM on all nodes will be upgraded to 11<span class="italic">g</span> release 2 (11.2).</p>
</div>
<!-- class="sect2" --></div>
<!-- class="sect1" -->
<a id="CDECFFAD"></a>
<div id="CWLIN312" class="sect1">
<h2 class="sect1"><span class="secnum">3.4</span> Desupport of Block and Raw Devices<a id="sthref635"></a><a id="sthref636"></a><a id="sthref637"></a><a id="sthref638"></a><a id="sthref639"></a><a id="sthref640"></a></h2>
<p>With the release of Oracle Database and Oracle RAC 11<span class="italic">g</span> release 2 (11.2), using Database Configuration Assistant or the installer to store Oracle Clusterware or Oracle Database files on block or raw devices is not supported.</p>
<p>If you intend to upgrade an existing Oracle RAC database, or an Oracle RAC database with Oracle ASM instances, then you can use an existing raw or block device partition, and perform a rolling upgrade of your existing installation. Performing a new installation using block or raw devices is not allowed.</p>
<p>Alternatively, on IBM: Linux on System z block devices, you can use the <code dir="ltr">-d ldl</code> option to format the DASD using the Linux disk layout if you require only a single partition (for example, if you want to create a partition for ASM file management). If you use this disk layout, then the partition device name for the DASD is <code dir="ltr">/dev/dasd</code><code dir="ltr"><span class="codeinlineitalic">xxxx</span></code><code dir="ltr">1</code>.</p>
</div>
<!-- class="sect1" -->
<a id="CHDJEFAA"></a>
<div id="CWLIN313" class="sect1">
<h2 class="sect1"><span class="secnum">3.5</span> Configuring Raw Logical Volumes on IBM: Linux on System z</h2>
<p>On IBM: Linux on System z, you can use raw logical volume manager (LVM) volumes for Oracle Clusterware and Automatic Storage Management files. You can create the required raw logical volumes in a volume group on either direct access storage devices (DASDs) or on SCSI devices. To configure the required raw logical volumes, follow these steps:</p>
<div class="infobox-note">
<p class="notep1">Note:</p>
You do not have to format FBA-type DASDs in Linux. The device name for the single whole-disk partition for FBA-type DASDs is <code dir="ltr">/dev/dasd</code><code dir="ltr"><span class="codeinlineitalic">xxxx</span></code><code dir="ltr">1</code>.</div>
<ol>
<li>
<p>If necessary, install or configure the shared DASDs that you intend to use for the disk group and restart the system.</p>
</li>
<li>
<p>Enter the following command to identify the DASDs configured on the system:</p>
<pre dir="ltr">
# more /proc/dasd/devices
</pre>
<p>The output from this command contains lines similar to the following:</p>
<pre dir="ltr">
0302(ECKD) at ( 94: 48) is dasdm : active at blocksize: 4096, 540000 blocks, 2109 MB
</pre>
<p>These lines display the following information for each DASD:</p>
<ul>
<li>
<p>The device number (<code dir="ltr">0302)</code></p>
</li>
<li>
<p>The device type (<code dir="ltr">ECKD</code> or <code dir="ltr">FBA</code>)</p>
</li>
<li>
<p>The Linux device major and minor numbers (<code dir="ltr">94: 48</code>)</p>
</li>
<li>
<p>The Linux device file name (<code dir="ltr">dasdm</code>)</p>
<p>In general, DASDs have device names in the form <code dir="ltr">dasd</code><code dir="ltr"><span class="codeinlineitalic">xxxx</span></code>, where <code dir="ltr"><span class="codeinlineitalic">xxxx</span></code> is between one and four letters that identify the device.</p>
</li>
<li>
<p>The block size and size of the device</p>
</li>
</ul>
</li>
<li>
<p>From the display, identify the devices that you want to use.</p>
<p>If the devices displayed are FBA-type DASDs, then you do not have to configure them. You can proceed to bind them for Oracle Database files.</p>
<p>If you want to use ECKD-type DASDs, then enter a command similar to the following to format the DASD, if it is not already formatted:</p>
<pre dir="ltr">
# /sbin/dasdfmt -b 4096 -f /dev/dasd<span class="italic">xxxx</span>
</pre>
<div class="infobox-note">
<p class="notep1">Caution:</p>
Formatting a DASD destroys all existing data on the device. Make sure that:
<ul>
<li>
<p>You specify the correct DASD device name</p>
</li>
<li>
<p>The DASD does not contain existing data that you want to preserve</p>
</li>
</ul>
</div>
<p>This command formats the DASD with a block size of 4 KB and the compatible disk layout (default), which enables you to create up to three partitions on the DASD.</p>
</li>
<li>
<p>If you intend to create raw logical volumes on SCSI devices, then proceed to step 5.</p>
<p>If you intend to create raw logical volumes on DASDs, and you formatted the DASD with the compatible disk layout, then determine how you want to create partitions.</p>
<p><span class="bold">To create a single whole-disk partition on the device</span> (for example, if you want to create a partition on an entire raw logical volume for database files), enter a command similar to the following:</p>
<pre dir="ltr">
# /sbin/fdasd -a /dev/dasd<span class="italic">xxxx</span>
</pre>
<p>This command creates one partition across the entire disk. You are then ready to mark devices as physical volumes. Proceed to Step 6.</p>
<p><span class="bold">To create up to three partitions on the device</span> (for example, if you want to create partitions for individual tablespaces), enter a command similar to the following:</p>
<pre dir="ltr">
# /sbin/fdasd /dev/dasd<span class="italic">xxxx</span>
</pre>
<p>Use the following guidelines when creating partitions:</p>
<ul>
<li>
<p>Use the <code dir="ltr">p</code> command to list the partition table of the device.</p>
</li>
<li>
<p>Use the <code dir="ltr">n</code> command to create a new partition.</p>
</li>
<li>
<p>After you have created the required partitions on this device, use the <code dir="ltr">w</code> command to write the modified partition table to the device.</p>
</li>
<li>
<p>See the <code dir="ltr">fdasd</code> man page for more information about creating partitions.</p>
</li>
</ul>
<p>The partitions on a DASD have device names similar to the following, where <code dir="ltr"><span class="codeinlineitalic">n</span></code> is the partition number, between 1 and 3:</p>
<pre dir="ltr">
/dev/dasd<span class="italic">xxxx</span><span class="italic">n</span>
</pre>
<p>When you have completed creating partitions, you are then ready to mark devices as physical volumes. Proceed to Step 6.</p>
</li>
<li>
<p>If you intend to use SCSI devices in the volume group, then follow these steps:</p>
<ol>
<li>
<p>If necessary, install or configure the shared disk devices that you intend to use for the volume group and restart the system.<a id="sthref641"></a></p>
</li>
<li>
<p>To identify the device name for the disks that you want to use, enter the following command:<a id="sthref642"></a><a id="sthref643"></a><a id="sthref644"></a><a id="sthref645"></a><a id="sthref646"></a><a id="sthref647"></a><a id="sthref648"></a><a id="sthref649"></a><a id="sthref650"></a><a id="sthref651"></a></p>
<pre dir="ltr">
# /sbin/fdisk -l
</pre>
<p>SCSI devices have device names similar to the following:</p>
<pre dir="ltr">
/dev/sd<span class="italic">xn</span>
</pre>
<p>In this example, <code dir="ltr"><span class="codeinlineitalic">x</span></code> is a letter that identifies the SCSI disk and <code dir="ltr"><span class="codeinlineitalic">n</span></code> is the partition number. For example, <code dir="ltr">/dev/sda</code> is the first disk on the first SCSI bus.</p>
</li>
<li>
<p>If necessary, use <code dir="ltr">fdisk</code> to create partitions on the devices that you want to use.</p>
</li>
<li>
<p>Use the <code dir="ltr">t</code> command in <code dir="ltr">fdisk</code> to change the system ID for the partitions that you want to use to <code dir="ltr">0x8e</code>.</p>
</li>
</ol>
</li>
<li>
<p>Enter a command similar to the following to mark each device that you want to use in the volume group as a physical volume:</p>
<p>For SCSI devices:</p>
<pre dir="ltr">
# pvcreate /dev/sda1 /dev/sdb1
</pre>
<p>For DASD devices:</p>
<pre dir="ltr">
# pvcreate /dev/dasda1 /dev/dasdb1
</pre></li>
<li>
<p>To create a volume group named <code dir="ltr">oracle_vg</code> using the devices that you marked, enter a command similar to the following:</p>
<p>For SCSI devices:</p>
<pre dir="ltr">
# vgcreate oracle_vg /dev/sda1 /dev/sdb1
</pre>
<p>For DASD devices:</p>
<pre dir="ltr">
# vgcreate oracle_vg /dev/dasda1 /dev/dasdb1
</pre></li>
<li>
<p>To create the required logical volumes in the volume group that you created, enter commands similar to the following:</p>
<pre dir="ltr">
# lvcreate -L <span class="italic">size</span> -n <span class="italic">lv_name</span> <span class="italic">vg_name</span>
</pre>
<p>In this example:</p>
<ul>
<li>
<p><code dir="ltr"><span class="codeinlineitalic">size</span></code> is the size of the logical volume, for example <code dir="ltr">500M</code></p>
</li>
<li>
<p><code dir="ltr"><span class="codeinlineitalic">lv_name</span></code> is the name of the logical volume, for example <code dir="ltr">orcl_system_raw_500m</code></p>
</li>
<li>
<p><code dir="ltr"><span class="codeinlineitalic">vg_name</span></code> is the name of the volume group, for example <code dir="ltr">oracle_vg</code></p>
</li>
</ul>
<p>For example, to create a 500 MB logical volume for the SYSTEM tablespace for a database named <code dir="ltr">rac</code> in the <code dir="ltr">oracle_vg</code> volume group, enter the following command:</p>
<pre dir="ltr">
# lvcreate -L 500M -n rac_system_raw_500m oracle_vg
</pre>
<div class="infobox-note">
<p class="notep1">Note:</p>
These commands create a device name similar to the following for each logical volume:
<pre dir="ltr">
/dev/<span class="italic">vg_name</span>/<span class="italic">lv_name</span>
</pre></div>
</li>
<li>
<p>On the other cluster nodes, enter the following commands to scan all volume groups and make them active:</p>
<pre dir="ltr">
# vgscan
# vgchange -a y
</pre></li>
</ol>
</div>
<!-- class="sect1" --></div>
<!-- class="chapter" --></div>
<!-- class="ind" -->
<!-- Start Footer -->
</div>
<!-- add extra wrapper close div-->
<footer><!--
<hr />
<table class="cellalignment2495">
<tr>
<td class="cellalignment2502">
<table class="cellalignment2500">
<tr>
<td class="cellalignment2499"><a href="prelinux.htm"><img width="24" height="24" src="../../dcommon/gifs/leftnav.gif" alt="Go to previous page" /><br />
<span class="icon">Previous</span></a></td>
<td class="cellalignment2499"><a href="crsunix.htm"><img width="24" height="24" src="../../dcommon/gifs/rightnav.gif" alt="Go to next page" /><br />
<span class="icon">Next</span></a></td>
</tr>
</table>
</td>
<td class="cellalignment-copyrightlogo"><img width="144" height="18" src="../../dcommon/gifs/oracle.gif" alt="Oracle" /><br />
Copyright&nbsp;&copy;&nbsp;2007, 2017,&nbsp;Oracle&nbsp;and/or&nbsp;its&nbsp;affiliates.&nbsp;All&nbsp;rights&nbsp;reserved.<br />
<a href="../../dcommon/html/cpyr.htm">Legal Notices</a></td>
<td class="cellalignment2504">
<table class="cellalignment2498">
<tr>
<td class="cellalignment2499"><a href="../../index.htm"><img width="24" height="24" src="../../dcommon/gifs/doclib.gif" alt="Go to Documentation Home" /><br />
<span class="icon">Home</span></a></td>
<td class="cellalignment2499"><a href="../../nav/portal_booklist.htm"><img width="24" height="24" src="../../dcommon/gifs/booklist.gif" alt="Go to Book List" /><br />
<span class="icon">Book List</span></a></td>
<td class="cellalignment2499"><a href="toc.htm"><img width="24" height="24" src="../../dcommon/gifs/toc.gif" alt="Go to Table of Contents" /><br />
<span class="icon">Contents</span></a></td>
<td class="cellalignment2499"><a href="index.htm"><img width="24" height="24" src="../../dcommon/gifs/index.gif" alt="Go to Index" /><br />
<span class="icon">Index</span></a></td>
<td class="cellalignment2499"><a href="../../nav/mindx.htm"><img width="24" height="24" src="../../dcommon/gifs/masterix.gif" alt="Go to Master Index" /><br />
<span class="icon">Master Index</span></a></td>
<td class="cellalignment2499"><a href="../../dcommon/html/feedback.htm"><img width="24" height="24" src="../../dcommon/gifs/feedbck2.gif" alt="Go to Feedback page" /><br />
<span class="icon">Contact Us</span></a></td>
</tr>
</table>
</td>
</tr>
</table>
--></footer>
</body>
</html>
