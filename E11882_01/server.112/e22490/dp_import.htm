<!DOCTYPE html>
<html lang="en" >
<head>
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta charset="utf-8">
<title>Data Pump Import</title>
<meta name="generator" content="Oracle DARB XHTML Converter (Mode = document) - Merged Version 1093" />
<meta name="dcterms.created" content="2018-03-26T15:54:40Z" />
<meta name="robots" content="all" />
<meta name="dcterms.title" content="Database Utilities" />
<meta name="dcterms.identifier" content="E22490-08" />
<meta name="dcterms.isVersionOf" content="SUTIL" />
<meta name="dcterms.rights" content="Copyright&nbsp;&copy;&nbsp;1996, 2018,&nbsp;Oracle&nbsp;and/or&nbsp;its&nbsp;affiliates.&nbsp;All&nbsp;rights&nbsp;reserved." />
<link rel="Start" href="../../index.htm" title="Home" type="text/html" />
<link rel="Copyright" href="../../dcommon/html/cpyr.htm" title="Copyright" type="text/html" />

<script type="application/javascript"  src="../../dcommon/js/headfoot.js"></script>
<script type="application/javascript"  src="../../nav/js/doccd.js"></script>
<link rel="Contents" href="toc.htm" title="Contents" type="text/html" />
<link rel="Index" href="index.htm" title="Index" type="text/html" />
<link rel="Prev" href="dp_export.htm" title="Previous" type="text/html" />
<link rel="Next" href="dp_legacy.htm" title="Next" type="text/html" />
<link rel="alternate" href="../e22490.pdf" title="PDF version" type="application/pdf" />
<link rel="schema.dcterms" href="http://purl.org/dc/terms/" />
<link rel="stylesheet" href="../../dcommon/css/fusiondoc.css">
<link rel="stylesheet" type="text/css"  href="../../dcommon/css/header.css">
<link rel="stylesheet" type="text/css"  href="../../dcommon/css/footer.css">
<link rel="stylesheet" type="text/css"  href="../../dcommon/css/fonts.css">
<link rel="stylesheet" href="../../dcommon/css/foundation.css">
<link rel="stylesheet" href="../../dcommon/css/codemirror.css">
<link rel="stylesheet" type="text/css" title="Default" href="../../nav/css/html5.css">
<link rel="stylesheet" href="../../dcommon/css/respond-480-tablet.css">
<link rel="stylesheet" href="../../dcommon/css/respond-768-laptop.css">
<link rel="stylesheet" href="../../dcommon/css/respond-1140-deskop.css">
<script type="application/javascript" src="../../dcommon/js/modernizr.js"></script>
<script type="application/javascript" src="../../dcommon/js/codemirror.js"></script>
<script type="application/javascript" src="../../dcommon/js/jquery.js"></script>
<script type="application/javascript" src="../../dcommon/js/foundation.min.js"></script>
<script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-552992c80ef99c8d" async="async"></script>
<script type="application/javascript" src="../../dcommon/js/jqfns.js"></script>
<script type="application/javascript" src="../../dcommon/js/ohc-inline-videos.js"></script>
<!-- Add fancyBox -->
<link rel="stylesheet" href="../../dcommon/fancybox/jquery.fancybox.css?v=2.1.5" type="text/css" media="screen" />
<script type="text/javascript" src="../../dcommon/fancybox/jquery.fancybox.pack.js?v=2.1.5"></script>
<!-- Optionally add helpers - button, thumbnail and/or media -->
<link rel="stylesheet"  href="../../dcommon/fancybox/helpers/jquery.fancybox-buttons.css?v=1.0.5"  type="text/css" media="screen" />
<script type="text/javascript" src="../../dcommon/fancybox/helpers/jquery.fancybox-buttons.js?v=1.0.5"></script>
<script type="text/javascript" src="../../dcommon/fancybox/helpers/jquery.fancybox-media.js?v=1.0.6"></script>
<link rel="stylesheet"  href="../../dcommon/fancybox/helpers/jquery.fancybox-thumbs.css?v=1.0.7"  type="text/css" media="screen" />
<script type="text/javascript" src="../../dcommon/fancybox/helpers/jquery.fancybox-thumbs.js?v=1.0.7"></script>
</head>
<body>
<a href="#BEGIN" class="accessibility-top skipto" tabindex="0">Go to main content</a><header><!--
<div class="zz-skip-header"><a id="top" href="#BEGIN">Go to main content</a>--></header>
<div class="row" id="CONTENT">
<div class="IND large-9 medium-8 columns" dir="ltr">
<a id="BEGIN" name="BEGIN"></a>
<span id="PAGE" style="display:none;">11/36</span> <!-- End Header -->
<div id="SUTIL300" class="chapter"><a id="g1025464"></a> <a id="i1007653"></a>
<h1 class="chapter"><span class="secnum">3</span> Data Pump Import</h1>
<p>This chapter describes the Oracle Data Pump Import utility (impdp). The following topics are discussed:</p>
<ul>
<li>
<p><a href="#i1006529">What Is Data Pump Import?</a></p>
</li>
<li>
<p><a href="#i1012504">Invoking Data Pump Import</a></p>
</li>
<li>
<p><a href="#i1009204">Filtering During Import Operations</a></p>
</li>
<li>
<p><a href="#i1010670">Parameters Available in Import's Command-Line Mode</a></p>
</li>
<li>
<p><a href="#i1005692">Commands Available in Import's Interactive-Command Mode</a></p>
</li>
<li>
<p><a href="#i1006564">Examples of Using Data Pump Import</a></p>
</li>
<li>
<p><a href="#BEHIBGEC">Syntax Diagrams for Data Pump Import</a></p>
</li>
</ul>
<a id="i1006529"></a>
<div id="SUTIL890" class="sect1">
<h2 class="sect1">What Is Data Pump Import?</h2>
<p>Data Pump Import (hereinafter referred to as Import for ease of reading) is a utility for loading an export dump file set into a target system. The dump file set is made up of one or more disk files that contain table data, database object metadata, and control information. The files are written in a proprietary, binary format. During an import operation, the Data Pump Import utility uses these files to locate each database object in the dump file set.</p>
<p>Import can also be used to load a target database directly from a source database with no intervening dump files. This is known as a network import.</p>
<p>Data Pump Import enables you to specify whether a job should move a subset of the data and metadata from the dump file set or the source database (in the case of a network import), as determined by the import mode. This is done using data filters<a id="sthref191"></a> and metadata filters, which are implemented through Import commands. See <a href="#i1009204">"Filtering During Import Operations"</a>.</p>
<p>To see some examples of the various ways in which you can use Import, refer to <a href="#i1006564">"Examples of Using Data Pump Import"</a>.</p>
</div>
<!-- class="sect1" -->
<a id="i1012504"></a>
<div id="SUTIL891" class="sect1">
<h2 class="sect1">Invoking Data Pump Import</h2>
<p>The Data Pump Import utility is invoked using the <code dir="ltr">impdp</code> command. The characteristics of the import operation are determined by the import parameters you specify. These parameters can be specified either on the command line or in a parameter file.</p>
<div class="infobox-note">
<p class="notep1">Note:</p>
Do not invoke Import<a id="sthref192"></a> as <code dir="ltr">SYSDBA,</code> except at the request of Oracle technical support. <code dir="ltr">SYSDBA</code> is used internally and has specialized functions; its behavior is not the same as for general users.</div>
<div class="infobox-note">
<p class="notep1">Note:</p>
Be aware that if you are performing a Data Pump Import into a table or tablespace created with the <code dir="ltr">NOLOGGING</code> clause enabled, then a redo log file may still be generated. The redo that is generated in such a case is generally for maintenance of the master table or related to underlying recursive space transactions, data dictionary changes, and index maintenance for indices on the table that require logging.</div>
<p>The following sections contain more information about invoking Import:</p>
<ul>
<li>
<p><a href="#i1007316">"Data Pump Import Interfaces"</a></p>
</li>
<li>
<p><a href="#i1007324">"Data Pump Import Modes"</a></p>
</li>
<li>
<p><a href="#BEHDGDBG">"Network Considerations"</a></p>
</li>
</ul>
<a id="i1007316"></a>
<div id="SUTIL892" class="sect2">
<h3 class="sect2">Data Pump Import Interfaces</h3>
<p>You can interact<a id="sthref193"></a> with Data Pump Import by using a command line, a parameter file, or an interactive-command mode.</p>
<ul>
<li>
<p>Command-Line Interface: Enables you to specify the Import parameters directly on the command line. For a complete description of the parameters available in the command-line interface, see <a href="#i1010670">"Parameters Available in Import's Command-Line Mode"</a>.</p>
</li>
<li>
<p>Parameter File Interface: Enables you to specify command-line parameters in a parameter file. The only exception is the <code dir="ltr">PARFILE</code> parameter because parameter files cannot be nested. The use of parameter files is recommended if you are using parameters whose values require quotation marks. See <a href="#BEHECGCA">"Use of Quotation Marks On the Data Pump Command Line"</a>.</p>
</li>
<li>
<p>Interactive-Command Interface: Stops logging to the terminal and displays the Import prompt, from which you can enter various commands, some of which are specific to interactive-command mode. This mode is enabled by pressing Ctrl+C during an import operation started with the command-line interface or the parameter file interface. Interactive-command mode is also enabled when you attach to an executing or stopped job.</p>
<p>For a complete description of the commands available in interactive-command mode, see <a href="#i1005692">"Commands Available in Import's Interactive-Command Mode"</a>.</p>
</li>
</ul>
</div>
<!-- class="sect2" -->
<a id="i1007324"></a>
<div id="SUTIL893" class="sect2">
<h3 class="sect2">Data Pump Import Modes</h3>
<p>The import mode determines what is imported. The specified mode applies to the source of the operation, either a dump file set or another database if the <code dir="ltr">NETWORK_LINK</code> parameter is specified.</p>
<p>When the source of the import operation is a dump file set, specifying a mode is optional. If no mode is specified, then Import attempts to load the entire dump file set in the mode in which the export operation was run.</p>
<p>The mode is specified on the command line, using the appropriate parameter. The available modes are described in the following sections:</p>
<ul>
<li>
<p><a href="#i1011935">"Full Import Mode"</a></p>
</li>
<li>
<p><a href="#i1011943">"Schema Mode"</a></p>
</li>
<li>
<p><a href="#i1011951">"Table Mode"</a></p>
</li>
<li>
<p><a href="#i1011959">"Tablespace Mode"</a></p>
</li>
<li>
<p><a href="#i1011967">"Transportable Tablespace Mode"</a></p>
</li>
</ul>
<div class="infobox-note">
<p class="notep1">Note:</p>
When you import a dump file that was created by a full-mode export, the import operation attempts to copy the password for the <code dir="ltr">SYS</code> account from the source database. This sometimes fails (for example, if the password is in a shared password file). If it does fail, then after the import completes, you must set the password for the <code dir="ltr">SYS</code> account at the target database to a password of your choice.</div>
<a id="i1011935"></a>
<div id="SUTIL894" class="sect3">
<h4 class="sect3">Full Import Mode</h4>
<p>A full import<a id="sthref194"></a> is specified using the <code dir="ltr">FULL</code> parameter. In full import mode, the entire content of the source (dump file set or another database) is loaded into the target database. This is the default for file-based imports. You must have the <code dir="ltr">DATAPUMP_IMP_FULL_DATABASE</code> role if the source is another database.</p>
<p>Cross-schema references are not imported for non-privileged users. For example, a trigger defined on a table within the importing user's schema, but residing in another user's schema, is not imported.</p>
<p>The <code dir="ltr">DATAPUMP_IMP_FULL_DATABASE</code> role is required on the target database and the <code dir="ltr">DATAPUMP_EXP_FULL_DATABASE</code> role is required on the source database if the <code dir="ltr">NETWORK_LINK</code> parameter is used for a full import.</p>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<a href="#i1007012">"FULL"</a></div>
</div>
<!-- class="sect3" -->
<a id="i1011943"></a>
<div id="SUTIL895" class="sect3">
<h4 class="sect3">Schema Mode</h4>
<p>A schema import<a id="sthref195"></a> is specified using the <code dir="ltr">SCHEMAS</code> parameter. In a schema import, only objects owned by the specified schemas are loaded. The source can be a full, table, tablespace, or schema-mode export dump file set or another database. If you have the <code dir="ltr">DATAPUMP_IMP_FULL_DATABASE</code> role, then a list of schemas can be specified and the schemas themselves (including system privilege grants) are created in the database in addition to the objects contained within those schemas.</p>
<p>Cross-schema references are not imported for non-privileged users unless the other schema is remapped to the current schema. For example, a trigger defined on a table within the importing user's schema, but residing in another user's schema, is not imported.</p>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<a href="#i1007024">"SCHEMAS"</a></div>
</div>
<!-- class="sect3" -->
<a id="i1011951"></a>
<div id="SUTIL896" class="sect3">
<h4 class="sect3">Table Mode</h4>
<p>A table-mode import<a id="sthref196"></a> is specified using the <code dir="ltr">TABLES</code> parameter. In table mode, only the specified set of tables, partitions, and their dependent objects are loaded. The source can be a full, schema, tablespace, or table-mode export dump file set or another database. You must have the <code dir="ltr">DATAPUMP_IMP_FULL_DATABASE</code> role to specify tables that are not in your own schema.</p>
<p>You can use the transportable option during a table-mode import by specifying the <code dir="ltr">TRANPORTABLE=ALWAYS</code> parameter with the <code dir="ltr">TABLES</code> parameter. Note that this requires use of the <code dir="ltr">NETWORK_LINK</code> parameter, as well.</p>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<ul>
<li>
<p><a href="#i1007036">"TABLES"</a></p>
</li>
<li>
<p><a href="#BABIDIFA">"TRANSPORTABLE"</a></p>
</li>
<li>
<p><a href="dp_overview.htm#CEGFEEJE">"Using Data File Copying to Move Data"</a></p>
</li>
</ul>
</div>
</div>
<!-- class="sect3" -->
<a id="i1011959"></a>
<div id="SUTIL897" class="sect3">
<h4 class="sect3">Tablespace Mode</h4>
<p>A tablespace-mode import<a id="sthref197"></a> is specified using the <code dir="ltr">TABLESPACES</code> parameter. In tablespace mode, all objects contained within the specified set of tablespaces are loaded, along with the dependent objects. The source can be a full, schema, tablespace, or table-mode export dump file set or another database. For unprivileged users, objects not remapped to the current schema will not be processed.</p>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<a href="#i1007048">"TABLESPACES"</a></div>
</div>
<!-- class="sect3" -->
<a id="i1011967"></a>
<div id="SUTIL898" class="sect3">
<h4 class="sect3">Transportable Tablespace Mode</h4>
<p>A transportable tablespace import<a id="sthref198"></a> is specified using the <code dir="ltr">TRANSPORT_TABLESPACES</code> parameter. In transportable tablespace mode, the metadata from another database is loaded using a database link (specified with the <code dir="ltr">NETWORK_LINK</code> parameter). There are no dump files involved. The actual data files, specified by the <code dir="ltr">TRANSPORT_DATAFILES</code> parameter, must be made available from the source system for use in the target database, typically by copying them over to the target system.</p>
<p>Encrypted columns are not supported in transportable tablespace mode.</p>
<p>This mode requires the <code dir="ltr">DATAPUMP_IMP_FULL_DATABASE</code> role.</p>
<div class="infobox-note">
<p class="notep1">Note:</p>
You cannot export transportable tablespaces and then import them into a database at a lower release level. The target database must be at the same or higher release level as the source database.</div>
<p class="subhead2"><a id="BEHDHCAF"></a><a id="SUTIL3777"></a>Considerations for Time Zone File Versions in Transportable Tablespace Mode</p>
<p>Jobs performed in transportable tablespace mode have the following requirements concerning time zone file versions:<a id="sthref199"></a><a id="sthref200"></a></p>
<ul>
<li>
<p>If the source is Oracle Database 11<span class="italic">g</span> release 2 (11.2.0.2) or later and there are tables in the transportable set that use TIMESTAMP WITH TIMEZONE (TSTZ) columns, then the time zone file version on the target database must exactly match the time zone file version on the source database.</p>
</li>
<li>
<p>If the source is earlier than Oracle Database 11<span class="italic">g</span> release 2 (11.2.0.2), then the time zone file version must be the same on the source and target database for all transportable jobs regardless of whether the transportable set uses TSTZ columns.</p>
</li>
</ul>
<p>If these requirements are not met, then the import job aborts before anything is imported. This is because if the import job were allowed to import the objects, there might be inconsistent results when tables with TSTZ columns were read.</p>
<p>To identify the time zone file version of a database, you can execute the following SQL statement:</p>
<pre dir="ltr">
SQL&gt; SELECT VERSION FROM V$TIMEZONE_FILE;
</pre>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<ul>
<li>
<p><a href="#BEHFFDCD">"TRANSPORT_TABLESPACES"</a></p>
</li>
<li>
<p><a href="#i1007060">"TRANSPORT_FULL_CHECK"</a></p>
</li>
<li>
<p><a href="#BABJIDCB">"TRANSPORT_DATAFILES"</a></p>
</li>
<li>
<p><a class="olink ADMIN10140" href="../../server.112/e25494/tspaces.htm#ADMIN10140"><span class="italic">Oracle Database Administrator's Guide</span></a> for more information about transportable tablespaces</p>
</li>
<li>
<p><a class="olink NLSPG004" href="../../server.112/e10729/ch4datetime.htm#NLSPG004"><span class="italic">Oracle Database Globalization Support Guide</span></a> for more information about time zone file versions</p>
</li>
</ul>
</div>
</div>
<!-- class="sect3" --></div>
<!-- class="sect2" -->
<a id="BEHDGDBG"></a>
<div id="SUTIL899" class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2">Network Considerations</h3>
<p>You can specify a connect identifier in the connect string when you invoke the Data Pump Import utility. The connect identifier can specify a database instance that is different from the current instance identified by the current Oracle System ID (SID). The connect identifier can be an Oracle*Net connect descriptor or a net service name (usually defined in the <code dir="ltr">tnsnames.ora</code> file) that maps to a connect descriptor. Use of a connect identifier requires that you have Oracle Net Listener running (to start the default listener, enter <code dir="ltr">lsnrctl</code> <code dir="ltr">start</code>). The following is an example of this type of connection, in which <code dir="ltr">inst1</code> is the connect identifier:</p>
<pre dir="ltr">
impdp hr@inst1 DIRECTORY=dpump_dir1 DUMPFILE=hr.dmp TABLES=employees
</pre>
<p>Import then prompts you for a password:</p>
<pre dir="ltr">
Password: <span class="italic">password</span>
 
</pre>
<p>The local Import client connects to the database instance identified by the connect identifier <code dir="ltr">inst1</code> (a net service name), and imports the data from the dump file <code dir="ltr">hr.dmp</code> to <code dir="ltr">inst1</code>.</p>
<p>Specifying a connect identifier when you invoke the Import utility is different from performing an import operation using the <code dir="ltr">NETWORK_LINK</code> parameter. When you start an import operation and specify a connect identifier, the local Import client connects to the database instance identified by the connect identifier and imports the data from the dump file named on the command line to that database instance.</p>
<p>Whereas, when you perform an import using the <code dir="ltr">NETWORK_LINK</code> parameter, the import is performed using a database link, and there is no dump file involved. (A database link is a connection between two physical database servers that allows a client to access them as one logical database.)</p>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<ul>
<li>
<p><a href="#i1007380">"NETWORK_LINK"</a></p>
</li>
<li>
<p><a class="olink ADMIN12083" href="../../server.112/e25494/ds_concepts.htm#ADMIN12083"><span class="italic">Oracle Database Administrator's Guide</span></a> for more information about database links</p>
</li>
<li>
<p><a class="olink NETAG" href="../../network.112/e41945/toc.htm"><span class="italic">Oracle Database Net Services Administrator's Guide</span></a> for more information about connect identifiers and Oracle Net Listener</p>
</li>
<li>
<p><a class="olink HETER" href="../../server.112/e11050/toc.htm"><span class="italic">Oracle Database Heterogeneous Connectivity User's Guide</span></a></p>
</li>
</ul>
</div>
</div>
<!-- class="sect2" --></div>
<!-- class="sect1" -->
<a id="i1009204"></a>
<div id="SUTIL900" class="sect1">
<h2 class="sect1">Filtering During Import Operations</h2>
<p>Data Pump Import provides data and metadata filtering capability to help you limit the type of information that is imported.</p>
<div id="SUTIL901" class="sect2"><a id="sthref201"></a>
<h3 class="sect2">Data Filters</h3>
<p>Data specific filtering is implemented through the <code dir="ltr">QUERY</code> and <code dir="ltr">SAMPLE</code> parameters, which specify restrictions on the table rows that are to be imported. Data filtering can also occur indirectly because of metadata filtering, which can include or exclude table objects along with any associated row data.</p>
<p>Each data filter can only be specified once per table and once per job. If different filters using the same name are applied to both a particular table and to the whole job, then the filter parameter supplied for the specific table takes precedence.</p>
</div>
<!-- class="sect2" -->
<div id="SUTIL902" class="sect2"><a id="sthref202"></a>
<h3 class="sect2">Metadata Filters</h3>
<p>Data Pump Import provides much greater metadata filtering capability than was provided by the original Import utility. Metadata filtering is implemented through the <code dir="ltr">EXCLUDE</code> and <code dir="ltr">INCLUDE</code> parameters. The <code dir="ltr">EXCLUDE</code> and <code dir="ltr">INCLUDE</code> parameters are mutually exclusive.</p>
<p>Metadata filters identify a set of objects to be included or excluded from a Data Pump operation. For example, you could request a full import, but without Package Specifications or Package Bodies.</p>
<p>To use filters correctly and to get the results you expect, remember that <span class="italic">dependent objects of an identified object are processed along with the identified object</span>. For example, if a filter specifies that a package is to be included in an operation, then grants upon that package will also be included. Likewise, if a table is excluded by a filter, then indexes, constraints, grants, and triggers upon the table will also be excluded by the filter.</p>
<p>If multiple filters are specified for an object type, then an implicit <code dir="ltr">AND</code> operation is applied to them. That is, objects participating in the job must pass <span class="italic">all</span> of the filters applied to their object types.</p>
<p>The same filter name can be specified multiple times within a job.</p>
<p>To see a list of valid object types, query the following views: <code dir="ltr">DATABASE_EXPORT_OBJECTS</code> for full mode, <code dir="ltr">SCHEMA_EXPORT_OBJECTS</code> for schema mode, and <code dir="ltr">TABLE_EXPORT_OBJECTS</code> for table and tablespace mode. The values listed in the <code dir="ltr">OBJECT_PATH</code> column are the valid object types. Note that full object path names are determined by the export mode, not by the import mode.</p>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<ul>
<li>
<p><a href="dp_export.htm#i1012306">"Metadata Filters"</a> for an example of using filtering</p>
</li>
<li>
<p>The Import <a href="#i1007865">"EXCLUDE"</a> parameter</p>
</li>
<li>
<p>The Import <a href="#i1007761">"INCLUDE"</a> parameter</p>
</li>
</ul>
</div>
</div>
<!-- class="sect2" --></div>
<!-- class="sect1" -->
<a id="i1010670"></a>
<div id="SUTIL903" class="sect1">
<h2 class="sect1">Parameters Available in Import's Command-Line Mode</h2>
<p>This section describes the parameters available in the command-line mode<a id="sthref203"></a> of Data Pump Import. Be sure to read the following sections before using the Import parameters:</p>
<ul>
<li>
<p><a href="#CIHIGCAF">Specifying Import Parameters</a></p>
</li>
<li>
<p><a href="#BEHECGCA">Use of Quotation Marks On the Data Pump Command Line</a></p>
</li>
</ul>
<p>Many of the descriptions include an example of how to use the parameter. For background information on setting up the necessary environment to run the examples, see:</p>
<ul>
<li>
<p><a href="#BEHFGIGF">Using the Import Parameter Examples</a></p>
</li>
</ul>
<p class="subhead1"><a id="CIHIGCAF"></a><a id="SUTIL3758"></a>Specifying Import Parameters</p>
<p>For parameters that can have multiple values specified, the values can be separated by commas or by spaces. For example, you could specify <code dir="ltr">TABLES=employees,jobs</code> or <code dir="ltr">TABLES=employees jobs</code>.</p>
<p>For every parameter you enter, you must enter an equal sign (=) and a value. Data Pump has no other way of knowing that the previous parameter specification is complete and a new parameter specification is beginning. For example, in the following command line, even though <code dir="ltr">NOLOGFILE</code> is a valid parameter, it would be interpreted as another dump file name for the <code dir="ltr">DUMPFILE</code> parameter:</p>
<pre dir="ltr">
impdp DIRECTORY=dpumpdir DUMPFILE=test.dmp NOLOGFILE TABLES=employees
</pre>
<p>This would result in two dump files being created, <code dir="ltr">test.dmp</code> and <code dir="ltr">nologfile.dmp</code>.</p>
<p>To avoid this, specify either <code dir="ltr">NOLOGFILE=YES</code> or <code dir="ltr">NOLOGFILE=NO</code>.</p>
<p class="subhead2"><a id="BEHECGCA"></a><a id="SUTIL3092"></a>Use of Quotation Marks On the Data Pump Command Line<a id="sthref204"></a><a id="sthref205"></a></p>
<p>Some operating systems treat quotation marks as special characters and will therefore not pass them to an application unless they are preceded by an escape character, such as the backslash (\). This is true both on the command line and within parameter files. Some operating systems may require an additional set of single or double quotation marks on the command line around the entire parameter value containing the special characters.</p>
<p>The following examples are provided to illustrate these concepts. Be aware that they may not apply to your particular operating system and that this documentation cannot anticipate the operating environments unique to each user.</p>
<p>Suppose you specify the <code dir="ltr">TABLES</code> parameter in a parameter file, as follows:</p>
<pre dir="ltr">
TABLES = \"MixedCaseTableName\"
</pre>
<p>If you were to specify that on the command line, then some operating systems would require that it be surrounded by single quotation marks, as follows:</p>
<pre dir="ltr">
TABLES = '\"MixedCaseTableName\"'
</pre>
<p>To avoid having to supply additional quotation marks on the command line, Oracle recommends the use of parameter files. Also, note that if you use a parameter file and the parameter value being specified does not have quotation marks as the first character in the string (for example, <code dir="ltr">TABLES=scott."EmP"</code>), then the use of escape characters may not be necessary on some systems.</p>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<ul>
<li>
<p>The Import <a href="#CIHGFACC">"PARFILE"</a> parameter</p>
</li>
<li>
<p><a href="dp_overview.htm#i1009520">"Default Locations for Dump, Log, and SQL Files"</a> for information about creating default directory objects</p>
</li>
<li>
<p><a href="dp_export.htm#i1006376">"Examples of Using Data Pump Export"</a></p>
</li>
<li>
<p>Your Oracle operating system-specific documentation for information about how special and reserved characters are handled on your system</p>
</li>
</ul>
</div>
<p class="subhead1"><a id="BEHFGIGF"></a><a id="SUTIL3091"></a>Using the Import Parameter Examples</p>
<p>If you try running the examples that are provided for each parameter, then be aware of the following:</p>
<ul>
<li>
<p>After you enter the username and parameters as shown in the example, Import is started and you are prompted for a password. You must supply a password before a database connection is made.</p>
</li>
<li>
<p>Most of the examples use the sample schemas of the seed database, which is installed by default when you install Oracle Database. In particular, the human resources (<code dir="ltr">hr</code>) schema is often used.</p>
</li>
<li>
<p>Examples that specify a dump file to import assume that the dump file exists. Wherever possible, the examples use dump files that are generated when you run the Export examples in <a href="dp_export.htm#g1022624">Chapter 2</a>.</p>
</li>
<li>
<p>The examples assume that the directory objects, <code dir="ltr">dpump_dir1</code> and <code dir="ltr">dpump_dir2</code>, already exist and that <code dir="ltr">READ</code> and <code dir="ltr">WRITE</code> privileges have been granted to the <code dir="ltr">hr</code> user for these directory objects. See <a href="dp_overview.htm#i1009520">"Default Locations for Dump, Log, and SQL Files"</a> for information about creating directory objects and assigning privileges to them.</p>
</li>
<li>
<p>Some of the examples require the <code dir="ltr">DATAPUMP_EXP_FULL_DATABASE</code> and <code dir="ltr">DATAPUMP_IMP_FULL_DATABASE</code> roles. The examples assume that the <code dir="ltr">hr</code> user has been granted these roles.</p>
</li>
</ul>
<p>If necessary, ask your DBA for help in creating these directory objects and assigning the necessary privileges and roles.</p>
<p>Syntax diagrams of these parameters are provided in <a href="#BEHIBGEC">"Syntax Diagrams for Data Pump Import"</a>.</p>
<p>Unless specifically noted, these parameters can also be specified in a parameter file.</p>
<div id="SUTIL3857" class="sect2"><!-- infolevel="all" infotype="General" --><a id="sthref206"></a>
<h3 class="sect2">ABORT_STEP</h3>
<p>Default: Null</p>
<p class="subhead1"><a id="SUTIL3858"></a>Purpose</p>
<p>Used to stop the job after it is initialized. This allows the master table to be queried before any data is imported.</p>
<p class="subhead1"><a id="SUTIL3859"></a>Syntax and Description</p>
<pre dir="ltr">
ABORT_STEP=[<span class="italic">n</span> | -1]
</pre>
<p>The possible values correspond to a process order number in the master table. The result of using each number is as follows:</p>
<ul>
<li>
<p><span class="italic">n</span> -- If the value is zero or greater, then the import operation is started and the job is aborted at the object that is stored in the master table with the corresponding process order number.</p>
</li>
<li>
<p>-1 and the job is an import using a <code dir="ltr">NETWORK_LINK</code> -- Abort the job after setting it up but before importing any objects.</p>
</li>
<li>
<p>-1 and the job is an import that does <span class="italic">not</span> use <code dir="ltr">NETWORK_LINK</code> -- Abort the job after loading the master table and applying filters.</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3860"></a>Restrictions</p>
<ul>
<li>
<p>None</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3861"></a>Example</p>
<pre dir="ltr">
&gt; impdp hr SCHEMAS=hr DIRECTORY=dpump_dir1 LOGFILE=schemas.log
DUMPFILE=expdat.dmp ABORT_STEP=-1 
</pre></div>
<!-- class="sect2" -->
<div id="SUTIL3862" class="sect2"><!-- infolevel="all" infotype="General" --><a id="sthref207"></a>
<h3 class="sect2">ACCESS_METHOD</h3>
<p>Default: <code dir="ltr">AUTOMATIC</code></p>
<p class="subhead1"><a id="SUTIL3863"></a>Purpose</p>
<p>Instructs Import to use a particular method to load data.</p>
<p class="subhead1"><a id="SUTIL3864"></a>Syntax and Description</p>
<pre dir="ltr">
ACCESS_METHOD=[AUTOMATIC | DIRECT_PATH | EXTERNAL_TABLE | CONVENTIONAL]
</pre>
<p>The <code dir="ltr">ACCESS_METHOD</code> parameter is provided so that you can try an alternative method if the default method does not work for some reason. Oracle recommends that you use the default option (<code dir="ltr">AUTOMATIC</code>) whenever possible because it allows Data Pump to automatically select the most efficient method.</p>
<p class="subhead1"><a id="SUTIL3865"></a>Restrictions</p>
<ul>
<li>
<p>If the <code dir="ltr">NETWORK_LINK</code> parameter is also specified, then the <code dir="ltr">ACCESS_METHOD</code> parameter is ignored.</p>
</li>
<li>
<p>The <code dir="ltr">ACCESS_METHOD</code> parameter for Data Pump Import is not valid for transportable tablespace jobs.</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3866"></a>Example</p>
<pre dir="ltr">
&gt; impdp hr SCHEMAS=hr DIRECTORY=dpump_dir1 LOGFILE=schemas.log
DUMPFILE=expdat.dmp ACCESS_METHOD=CONVENTIONAL 
</pre></div>
<!-- class="sect2" -->
<a id="i1007379"></a>
<div id="SUTIL904" class="sect2">
<h3 class="sect2">ATTACH<a id="sthref208"></a></h3>
<p>Default: current job in user's schema, if there is only one running job.</p>
<p class="subhead1"><a id="SUTIL3093"></a>Purpose</p>
<p>Attaches<a id="sthref209"></a><a id="sthref210"></a><a id="sthref211"></a> the client session to an existing import job and automatically places you in interactive-command mode.</p>
<p class="subhead1"><a id="SUTIL3094"></a>Syntax and Description</p>
<pre dir="ltr">
ATTACH [=[<span class="italic">schema_name</span>.]<span class="italic">job_name</span>]
</pre>
<p>Specify a <code dir="ltr"><span class="codeinlineitalic">schema_name</span></code> if the schema to which you are attaching is not your own. You must have the <code dir="ltr">DATAPUMP_IMP_FULL_DATABASE</code> role to do this.</p>
<p>A <code dir="ltr"><span class="codeinlineitalic">job_name</span></code> does not have to be specified if only one running job is associated with your schema and the job is active. If the job you are attaching to is stopped, then you must supply the job name. To see a list of Data Pump job names, you can query the <code dir="ltr">DBA_DATAPUMP_JOBS</code> view or the <code dir="ltr">USER_DATAPUMP_JOBS</code> view.</p>
<p>When you are attached to the job, Import displays a description of the job and then displays the Import prompt.</p>
<p class="subhead1"><a id="SUTIL3095"></a>Restrictions</p>
<ul>
<li>
<p>When you specify the <code dir="ltr">ATTACH</code> parameter, the only other Data Pump parameter you can specify on the command line is <code dir="ltr">ENCRYPTION_PASSWORD</code>.</p>
</li>
<li>
<p>If the job you are attaching to was initially started using an encryption password, then when you attach to the job you must again enter the <code dir="ltr">ENCRYPTION_PASSWORD</code> parameter on the command line to re-specify that password. The only exception to this is if the job was initially started with the <code dir="ltr">ENCRYPTION=ENCRYPTED_COLUMNS_ONLY</code> parameter. In that case, the encryption password is not needed when attaching to the job.</p>
</li>
<li>
<p>You cannot attach to a job in another schema unless it is already running.</p>
</li>
<li>
<p>If the dump file set or master table for the job have been deleted, then the attach operation fails.</p>
</li>
<li>
<p>Altering the master table in any way can lead to unpredictable results.</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3096"></a>Example</p>
<p>The following is an example of using the <code dir="ltr">ATTACH</code> parameter.</p>
<pre dir="ltr">
&gt; impdp hr ATTACH=import_job
</pre>
<p>This example assumes that a job named <code dir="ltr">import_job</code> exists in the <code dir="ltr">hr</code> schema.</p>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<a href="#i1005692">"Commands Available in Import's Interactive-Command Mode"</a></div>
</div>
<!-- class="sect2" -->
<a id="CIHHJIBE"></a>
<div id="SUTIL3097" class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2">CLUSTER<a id="sthref212"></a><a id="sthref213"></a></h3>
<p>Default: <code dir="ltr">Y</code>ES</p>
<p class="subhead1"><a id="SUTIL3098"></a>Purpose</p>
<p>Determines whether Data Pump can use Oracle Real Application Clusters (Oracle RAC) resources and start workers on other Oracle RAC instances.</p>
<p class="subhead1"><a id="SUTIL3099"></a>Syntax and Description</p>
<pre dir="ltr">
CLUSTER=[YES | NO]
</pre>
<p>To force Data Pump Import to use only the instance where the job is started and to replicate pre-Oracle Database 11<span class="italic">g</span> release 2 (11.2) behavior, specify <code dir="ltr">CLUSTER=NO</code>.</p>
<p>To specify a specific, existing service and constrain worker processes to run only on instances defined for that service, use the <code dir="ltr">SERVICE_NAME</code> parameter with the <code dir="ltr">CLUSTER=YES</code> parameter.</p>
<p>Use of the <code dir="ltr">CLUSTER</code> parameter may affect performance because there is some additional overhead in distributing the import job across Oracle RAC instances. For small jobs, it may be better to specify <code dir="ltr">CLUSTER=NO</code> to constrain the job to run on the instance where it is started. Jobs whose performance benefits the most from using the <code dir="ltr">CLUSTER</code> parameter are those involving large amounts of data.</p>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<ul>
<li>
<p><a href="#CIHHFIDE">"SERVICE_NAME"</a></p>
</li>
<li>
<p><a href="dp_overview.htm#CJAJGBFF">"Oracle RAC Considerations"</a></p>
</li>
</ul>
</div>
<p class="subhead1"><a id="SUTIL3100"></a>Example</p>
<pre dir="ltr">
&gt; impdp hr DIRECTORY=dpump_dir1 SCHEMAS=hr CLUSTER=NO PARALLEL=3 NETWORK_LINK=dbs1
</pre>
<p>This example performs a schema-mode import of the <code dir="ltr">hr</code> schema. Because <code dir="ltr">CLUSTER=NO</code> is used, the job uses only the instance where it is started. Up to 3 parallel processes can be used. The <code dir="ltr">NETWORK_LINK</code> value of <code dir="ltr">dbs1</code> would be replaced with the name of the source database from which you were importing data. (Note that there is no dump file generated because this is a network import.)</p>
<p>The <code dir="ltr">NETWORK_LINK</code> parameter is simply being used as part of the example. It is not required when using the <code dir="ltr">CLUSTER</code> parameter.</p>
</div>
<!-- class="sect2" -->
<a id="i1007838"></a>
<div id="SUTIL905" class="sect2">
<h3 class="sect2">CONTENT<a id="sthref214"></a></h3>
<p>Default: <code dir="ltr">ALL</code></p>
<p class="subhead1"><a id="SUTIL3101"></a>Purpose</p>
<p>Enables you to filter what is loaded during the import operation.</p>
<p class="subhead1"><a id="SUTIL3102"></a>Syntax and Description</p>
<pre dir="ltr">
CONTENT=[ALL | DATA_ONLY | METADATA_ONLY]
</pre>
<ul>
<li>
<p><code dir="ltr">ALL</code> loads any data and metadata contained in the source. This is the default.</p>
</li>
<li>
<p><code dir="ltr">DATA_ONLY l</code>oads only table row data into existing tables; no database objects are created.</p>
</li>
<li>
<p><code dir="ltr">METADATA_ONLY</code> loads only database object definitions; no table row data is loaded. Be aware that if you specify <code dir="ltr">CONTENT=METADATA_ONLY</code>, then any index or table statistics imported from the dump file are locked after the import operation is complete.</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3103"></a>Restrictions</p>
<ul>
<li>
<p>The <code dir="ltr">CONTENT=METADATA_ONLY</code> parameter and value cannot be used in conjunction with the <code dir="ltr">TRANSPORT_TABLESPACES</code> (transportable-tablespace mode) parameter or the <code dir="ltr">QUERY</code> parameter.</p>
</li>
<li>
<p>The <code dir="ltr">CONTENT=ALL</code> and <code dir="ltr">CONTENT=DATA_ONLY</code> parameter and values cannot be used in conjunction with the <code dir="ltr">SQLFILE</code> parameter.</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3104"></a>Example</p>
<p>The following is an example of using the <code dir="ltr">CONTENT</code> parameter. You can create the <code dir="ltr">expfull.dmp</code> dump file used in this example by running the example provided for the Export <code dir="ltr">FULL</code> parameter. See <a href="dp_export.htm#i1006790">"FULL"</a>.</p>
<pre dir="ltr">
&gt; impdp hr DIRECTORY=dpump_dir1 DUMPFILE=expfull.dmp CONTENT=METADATA_ONLY
</pre>
<p>This command will execute a full import that will load only the metadata in the <code dir="ltr">expfull.dmp</code> dump file. It executes a full import because that is the default for file-based imports in which no import mode is specified.</p>
</div>
<!-- class="sect2" -->
<a id="BABCIECC"></a>
<div id="SUTIL906" class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2">DATA_OPTIONS<a id="sthref215"></a><a id="sthref216"></a></h3>
<p>Default: There is no default. If this parameter is not used, then the special data handling options it provides simply do not take effect.</p>
<p class="subhead1"><a id="SUTIL3105"></a>Purpose</p>
<p>The <code dir="ltr">DATA_OPTIONS</code> parameter designates how certain types of data should be handled during import operations.</p>
<p class="subhead1"><a id="SUTIL3106"></a>Syntax and Description</p>
<pre dir="ltr">
DATA_OPTIONS = [DISABLE_APPEND_HINT | SKIP_CONSTRAINT_ERRORS]
</pre>
<ul>
<li>
<p><code dir="ltr">DISABLE_APPEND_HINT</code> - Specifies that you do not want the import operation to use the <code dir="ltr">APPEND</code> hint while loading the data object. Disabling the <code dir="ltr">APPEND</code> hint can be useful if there is a small set of data objects to load that already exist in the database and some other application may be concurrently accessing one or more of the data objects.</p>
<p>If <code dir="ltr">DISABLE_APPEND_HINT</code> is not set, then the default behavior is to use the <code dir="ltr">APPEND</code> hint for loading data objects.</p>
</li>
<li>
<p><code dir="ltr">SKIP_CONSTRAINT_ERRORS</code> - affects how <span class="italic">non-deferred</span> constraint violations are handled while a data object (table, partition, or subpartition) is being loaded. It has no effect on the load if <span class="italic">deferred</span> constraint violations are encountered. Deferred constraint violations always cause the entire load to be rolled back.</p>
<p>The <code dir="ltr">SKIP_CONSTRAINT_ERRORS</code> option specifies that you want the import operation to proceed even if non-deferred constraint violations are encountered. It logs any rows that cause non-deferred constraint violations, but does not stop the load for the data object experiencing the violation.</p>
<p>If <code dir="ltr">SKIP_CONSTRAINT_ERRORS</code> is not set, then the default behavior is to roll back the entire load of the data object on which non-deferred constraint violations are encountered.</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3107"></a>Restrictions</p>
<ul>
<li>
<p>If <code dir="ltr">DISABLE_APPEND_HINT</code> is used, then it can take longer for data objects to load.</p>
</li>
<li>
<p>If <code dir="ltr">SKIP_CONSTRAINT_ERRORS</code> is used and if a data object has unique indexes or constraints defined on it at the time of the load, then the <code dir="ltr">APPEND</code> hint will not be used for loading that data object. Therefore, loading such data objects will take longer when the <code dir="ltr">SKIP_CONSTRAINT_ERRORS</code> option is used.</p>
</li>
<li>
<p>Even if <code dir="ltr">SKIP_CONSTRAINT_ERRORS</code> is specified, then it is not used unless a data object is being loaded using the external table access method.</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3108"></a>Example</p>
<p>This example shows a data-only table mode import with <code dir="ltr">SKIP_CONSTRAINT_ERRORS</code> enabled:</p>
<pre dir="ltr">
&gt; impdp hr TABLES=employees CONTENT=DATA_ONLY 
DUMPFILE=dpump_dir1:table.dmp DATA_OPTIONS=skip_constraint_errors
</pre>
<p>If any non-deferred constraint violations are encountered during this import operation, then they will be logged and the import will continue on to completion.</p>
</div>
<!-- class="sect2" -->
<a id="i1008820"></a>
<div id="SUTIL907" class="sect2">
<h3 class="sect2">DIRECTORY<a id="sthref217"></a><a id="sthref218"></a></h3>
<p>Default: <code dir="ltr">DATA_PUMP_DIR</code></p>
<p class="subhead1"><a id="SUTIL3109"></a>Purpose</p>
<p>Specifies the default location in which the import job can find the dump file set and where it should create log and SQL files.</p>
<p class="subhead1"><a id="SUTIL3110"></a>Syntax and Description</p>
<pre dir="ltr">
DIRECTORY=<span class="italic">directory_object</span>
</pre>
<p>The <code dir="ltr"><span class="codeinlineitalic">directory_object</span></code> is the name of a database directory object (<span class="italic">not</span> <span class="italic">the file path of</span> <span class="italic">an actual directory</span>). Upon installation, privileged users have access to a default directory object named <code dir="ltr">DATA_PUMP_DIR</code>. Users with access to the default <code dir="ltr">DATA_PUMP_DIR</code> directory object do not need to use the <code dir="ltr">DIRECTORY</code> parameter at all.</p>
<p>A directory object specified on the <code dir="ltr">DUMPFILE</code>, <code dir="ltr">LOGFILE</code>, or <code dir="ltr">SQLFILE</code> parameter overrides any directory object that you specify for the <code dir="ltr">DIRECTORY</code> parameter. You must have Read access to the directory used for the dump file set and Write access to the directory used to create the log and SQL files.</p>
<p class="subhead1"><a id="SUTIL3111"></a>Example</p>
<p>The following is an example of using the <code dir="ltr">DIRECTORY</code> parameter. You can create the <code dir="ltr">expfull.dmp</code> dump file used in this example by running the example provided for the Export <code dir="ltr">FULL</code> parameter. See <a href="dp_export.htm#i1006790">"FULL"</a>.</p>
<pre dir="ltr">
&gt; impdp hr DIRECTORY=dpump_dir1 DUMPFILE=expfull.dmp 
LOGFILE=dpump_dir2:expfull.log
</pre>
<p>This command results in the import job looking for the <code dir="ltr">expfull.dmp</code> dump file in the directory pointed to by the <code dir="ltr">dpump_dir1</code> directory object. The <code dir="ltr">dpump_dir2</code> directory object specified on the <code dir="ltr">LOGFILE</code> parameter overrides the <code dir="ltr">DIRECTORY</code> parameter so that the log file is written to <code dir="ltr">dpump_dir2</code>.</p>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<ul>
<li>
<p><a href="dp_overview.htm#i1009520">"Default Locations for Dump, Log, and SQL Files"</a> for more information about default directory objects and the order of precedence Data Pump uses to determine a file's location</p>
</li>
<li>
<p><a href="dp_overview.htm#CJAJGBFF">"Oracle RAC Considerations"</a></p>
</li>
<li>
<p><a class="olink SQLRF" href="../e41084/toc.htm"><span class="italic">Oracle Database SQL Language Reference</span></a> for more information about the <code dir="ltr">CREATE</code> <code dir="ltr">DIRECTORY</code> command</p>
</li>
</ul>
</div>
</div>
<!-- class="sect2" -->
<div id="SUTIL908" class="sect2"><a id="sthref219"></a>
<h3 class="sect2">DUMPFILE<a id="sthref220"></a></h3>
<p>Default: <code dir="ltr">expdat</code>.<code dir="ltr">dmp</code></p>
<p class="subhead1"><a id="SUTIL3112"></a>Purpose</p>
<p>Specifies<a id="sthref221"></a> the names<a id="sthref222"></a> and optionally, the directory objects of the dump file set that was created by Export.</p>
<p class="subhead1"><a id="SUTIL3113"></a>Syntax and Description</p>
<pre dir="ltr">
DUMPFILE=[<span class="italic">directory_object</span>:]<span class="italic">file_name</span> [, ...]
</pre>
<p>The <code dir="ltr"><span class="codeinlineitalic">directory_object</span></code> is optional if one has already been established by the <code dir="ltr">DIRECTORY</code> parameter. If you do supply a value here, then it must be a directory object that already exists and that you have access to. A database directory object that is specified as part of the <code dir="ltr">DUMPFILE</code> parameter overrides a value specified by the <code dir="ltr">DIRECTORY</code> parameter.</p>
<p>The <code dir="ltr"><span class="codeinlineitalic">file_name</span></code> is the name of a file in the dump file set. The file names can also be templates that contain the substitution variable, <code dir="ltr">%U</code>. If <code dir="ltr">%U</code> is used, then Import examines each file that matches the template (until no match is found) to locate all files that are part of the dump file set. The <code dir="ltr">%U</code> expands to a 2-digit incrementing integer starting with 01.</p>
<p>Sufficient information is contained within the files for Import to locate the entire set, provided the file specifications in the <code dir="ltr">DUMPFILE</code> parameter encompass the entire set. The files are not required to have the same names, locations, or order that they had at export time.</p>
<p class="subhead1"><a id="SUTIL3114"></a>Example</p>
<p>The following is an example of using the Import <code dir="ltr">DUMPFILE</code> parameter. You can create the dump files used in this example by running the example provided for the Export <code dir="ltr">DUMPFILE</code> parameter. See <a href="dp_export.htm#i1006912">"DUMPFILE"</a>.</p>
<pre dir="ltr">
&gt; impdp hr DIRECTORY=dpump_dir1 DUMPFILE=dpump_dir2:exp1.dmp, exp2%U.dmp
</pre>
<p>Because a directory object (<code dir="ltr">dpump_dir2</code>) is specified for the <code dir="ltr">exp1.dmp</code> dump file, the import job will look there for the file. It will also look in <code dir="ltr">dpump_dir1</code> for dump files of the form <code dir="ltr">exp2</code><code dir="ltr"><span class="codeinlineitalic">nn</span></code><code dir="ltr">.dmp</code>. The log file will be written to <code dir="ltr">dpump_dir1</code>.</p>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<ul>
<li>
<p><a href="dp_overview.htm#i1007107">"File Allocation"</a></p>
</li>
<li>
<p><a href="#i1008875">"Performing a Data-Only Table-Mode Import"</a></p>
</li>
</ul>
</div>
</div>
<!-- class="sect2" -->
<a id="BABCDGIG"></a>
<div id="SUTIL909" class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2">ENCRYPTION_PASSWORD<a id="sthref223"></a><a id="sthref224"></a><a id="sthref225"></a><a id="sthref226"></a></h3>
<p>Default: There is no default; the value is user-supplied.</p>
<p class="subhead1"><a id="SUTIL3115"></a>Purpose</p>
<p>Specifies a password for accessing encrypted column data in the dump file set. This prevents unauthorized access to an encrypted dump file set.</p>
<p class="subhead1"><a id="SUTIL3116"></a>Syntax and Description</p>
<pre dir="ltr">
ENCRYPTION_PASSWORD = <span class="italic">password</span>
</pre>
<p>This parameter is required on an import operation if an encryption password was specified on the export operation. The password that is specified must be the same one that was specified on the export operation.</p>
<p class="subhead1"><a id="SUTIL3117"></a>Restrictions</p>
<ul>
<li>
<p>This parameter is valid only in the Enterprise Edition of Oracle Database 11<span class="italic">g</span>.</p>
</li>
<li>
<p>Data Pump encryption features require that the Oracle Advanced Security option be enabled. See <a class="olink ASOAG" href="../../network.112/e40393/toc.htm"><span class="italic">Oracle Database Advanced Security Administrator's Guide</span></a> for information about licensing requirements for the Oracle Advanced Security option.</p>
</li>
<li>
<p>The <code dir="ltr">ENCRYPTION_PASSWORD</code> parameter is not valid if the dump file set was created using the transparent mode of encryption.</p>
</li>
<li>
<p>The <code dir="ltr">ENCRYPTION_PASSWORD</code> parameter is not valid for network import jobs.</p>
</li>
<li>
<p>Encryption attributes for all columns must match between the exported table definition and the target table. For example, suppose you have a table, <code dir="ltr">EMP</code>, and one of its columns is named <code dir="ltr">EMPNO</code>. Both of the following situations would result in an error because the encryption attribute for the <code dir="ltr">EMP</code> column in the source table would not match the encryption attribute for the <code dir="ltr">EMP</code> column in the target table:</p>
<ul>
<li>
<p>The <code dir="ltr">EMP</code> table is exported with the <code dir="ltr">EMPNO</code> column being encrypted, but before importing the table you remove the encryption attribute from the <code dir="ltr">EMPNO</code> column.</p>
</li>
<li>
<p>The <code dir="ltr">EMP</code> table is exported without the <code dir="ltr">EMPNO</code> column being encrypted, but before importing the table you enable encryption on the <code dir="ltr">EMPNO</code> column.</p>
</li>
</ul>
</li>
</ul>
<p class="subhead2"><a id="SUTIL3118"></a>Example</p>
<p>In the following example, the encryption password, <code dir="ltr">123456</code>, must be specified because it was specified when the <code dir="ltr">dpcd2be1.dmp</code> dump file was created (see <a href="dp_export.htm#BABEIGFB">"ENCRYPTION_PASSWORD"</a>).</p>
<pre dir="ltr">
&gt; impdp hr TABLES=employee_s_encrypt DIRECTORY=dpump_dir
  DUMPFILE=dpcd2be1.dmp ENCRYPTION_PASSWORD=123456
</pre>
<p>During the import operation, any columns in the <code dir="ltr">employee_s_encrypt</code> table that were encrypted during the export operation are decrypted before being imported.</p>
</div>
<!-- class="sect2" -->
<div id="SUTIL910" class="sect2"><a id="sthref227"></a>
<h3 class="sect2">ESTIMATE<a id="sthref228"></a></h3>
<p>Default: <code dir="ltr">BLOCKS</code></p>
<p class="subhead1"><a id="SUTIL3119"></a>Purpose</p>
<p>Instructs the source system in a network import operation to<a id="sthref229"></a> estimate how much data will be generated.</p>
<p class="subhead1"><a id="SUTIL3120"></a>Syntax and Description</p>
<pre dir="ltr">
ESTIMATE=[BLOCKS | STATISTICS]
</pre>
<p><a id="sthref230"></a>The valid choices for the <code dir="ltr">ESTIMATE</code> parameter are as follows:</p>
<ul>
<li>
<p><code dir="ltr">BLOCKS</code> - The estimate is calculated by multiplying the number of database blocks used by the source objects times the appropriate block sizes.</p>
</li>
<li>
<p><code dir="ltr">STATISTICS</code> - The estimate is calculated using statistics for each table. For this method to be as accurate as possible, all tables should have been analyzed recently. (Table analysis can be done with either the SQL <code dir="ltr">ANALYZE</code> statement or the <code dir="ltr">DBMS_STATS</code> PL/SQL package.)</p>
</li>
</ul>
<p>The estimate that is generated can be used to determine a percentage complete throughout the execution of the import job.</p>
<p class="subhead1"><a id="SUTIL3121"></a>Restrictions</p>
<ul>
<li>
<p>The Import <code dir="ltr">ESTIMATE</code> parameter is valid only if the <code dir="ltr">NETWORK_LINK</code> parameter is also specified.</p>
</li>
<li>
<p>When the import source is a dump file set, the amount of data to be loaded is already known, so the percentage complete is automatically calculated.</p>
</li>
<li>
<p>The estimate may be inaccurate if either the <code dir="ltr">QUERY</code> or <code dir="ltr">REMAP_DATA</code> parameter is used.</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3122"></a>Example</p>
<p>In the following example, <code dir="ltr"><span class="codeinlineitalic">source_database_link</span></code> would be replaced with the name of a valid link to the source database.</p>
<pre dir="ltr">
&gt; impdp hr TABLES=job_history NETWORK_LINK=<span class="italic">source_database_link</span>
  DIRECTORY=dpump_dir1 ESTIMATE=STATISTICS 
</pre>
<p>The <code dir="ltr">job_history</code> table in the <code dir="ltr">hr</code> schema is imported from the source database. A log file is created by default and written to the directory pointed to by the <code dir="ltr">dpump_dir1</code> directory object. When the job begins, an estimate for the job is calculated based on table statistics.</p>
</div>
<!-- class="sect2" -->
<a id="i1007865"></a>
<div id="SUTIL911" class="sect2">
<h3 class="sect2">EXCLUDE<a id="sthref231"></a></h3>
<p>Default: There is no default</p>
<p class="subhead1"><a id="SUTIL3123"></a>Purpose</p>
<p><a id="sthref232"></a>Enables you to filter<a id="sthref233"></a> the metadata<a id="sthref234"></a> that is imported by specifying objects and object types to exclude from the import job.</p>
<p class="subhead1"><a id="SUTIL3124"></a>Syntax and Description</p>
<pre dir="ltr">
EXCLUDE=<span class="italic">object_type</span>[:<span class="italic">name_clause</span>] [, ...]
</pre>
<p>The <code dir="ltr"><span class="codeinlineitalic">object_type</span></code> specifies the type of object to be excluded. To see a list of valid values for <code dir="ltr"><span class="codeinlineitalic">object_type</span></code>, query the following views: <code dir="ltr">DATABASE_EXPORT_OBJECTS</code> for full mode, <code dir="ltr">SCHEMA_EXPORT_OBJECTS</code> for schema mode, and <code dir="ltr">TABLE_EXPORT_OBJECTS</code> for table and tablespace mode. The values listed in the <code dir="ltr">OBJECT_PATH</code> column are the valid object types.</p>
<p>For the given mode of import, all object types contained within the source (and their dependents) are included, <span class="italic">except</span> those specified in an <code dir="ltr">EXCLUDE</code> statement. If an object is excluded, then all of its dependent objects are also excluded. For example, excluding a table will also exclude all indexes and triggers on the table.</p>
<p>The <code dir="ltr"><span class="codeinlineitalic">name_clause</span></code> is optional. It allows fine-grained selection of specific objects within an object type. It is a SQL expression used as a filter on the object names of the type. It consists of a SQL operator and the values against which the object names of the specified type are to be compared. The <code dir="ltr"><span class="codeinlineitalic">name_clause</span></code> applies only to object types whose instances have names (for example, it is applicable to <code dir="ltr">TABLE</code> and <code dir="ltr">VIEW</code>, but not to <code dir="ltr">GRANT</code>). It must be separated from the object type with a colon and enclosed in double quotation marks, because single quotation marks are required to delimit the name strings. For example, you could set <code dir="ltr">EXCLUDE=INDEX:"LIKE</code> <code dir="ltr">'DEPT%'"</code> to exclude all indexes whose names start with <code dir="ltr">dept</code>.</p>
<p>The name that you supply for the <code dir="ltr"><span class="codeinlineitalic">name_clause</span></code> must exactly match, including upper and lower casing, an existing object in the database. For example, if the <code dir="ltr"><span class="codeinlineitalic">name_clause</span></code> you supply is for a table named <code dir="ltr">EMPLOYEES</code>, then there must be an existing table named <code dir="ltr">EMPLOYEES</code> using all upper case. If the <code dir="ltr"><span class="codeinlineitalic">name_clause</span></code> were supplied as <code dir="ltr">Employees</code> or <code dir="ltr">employees</code> or any other variation, then the table would not be found.</p>
<p>More than one <code dir="ltr">EXCLUDE</code> statement can be specified.</p>
<p>Depending on your operating system, the use of quotation marks when you specify a value for this parameter may also require that you use escape characters. Oracle recommends that you place this parameter in a parameter file, which can reduce the number of escape characters that might otherwise be needed on the command line.</p>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<a href="#BEHECGCA">"Use of Quotation Marks On the Data Pump Command Line"</a></div>
<p>As explained in the following sections, you should be aware of the effects of specifying certain objects for exclusion, in particular, <code dir="ltr">CONSTRAINT</code>, <code dir="ltr">GRANT</code>, and <code dir="ltr">USER</code>.</p>
<p class="subhead2"><a id="SUTIL3125"></a>Excluding Constraints</p>
<p>The following constraints cannot be excluded:</p>
<ul>
<li>
<p><code dir="ltr">NOT</code> <code dir="ltr">NULL</code> constraints.</p>
</li>
<li>
<p>Constraints needed for the table to be created and loaded successfully (for example, primary key constraints for index-organized tables or <code dir="ltr">REF</code> <code dir="ltr">SCOPE</code> and <code dir="ltr">WITH</code> <code dir="ltr">ROWID</code> constraints for tables with <code dir="ltr">REF</code> columns).</p>
</li>
</ul>
<p>This means that the following <code dir="ltr">EXCLUDE</code> statements will be interpreted as follows:</p>
<ul>
<li>
<p><code dir="ltr">EXCLUDE=</code><code dir="ltr">CONSTRAINT</code> will exclude all nonreferential constraints, except for <code dir="ltr">NOT</code> <code dir="ltr">NULL</code> constraints and any constraints needed for successful table creation and loading.</p>
</li>
<li>
<p><code dir="ltr">EXCLUDE=</code><code dir="ltr">REF_CONSTRAINT</code> will exclude referential integrity (foreign key) constraints.</p>
</li>
</ul>
<p class="subhead2"><a id="SUTIL3126"></a>Excluding Grants and Users</p>
<p>Specifying <code dir="ltr">EXCLUDE=</code><code dir="ltr">GRANT</code> excludes object grants on all object types and system privilege grants.</p>
<p>Specifying <code dir="ltr">EXCLUDE=</code><code dir="ltr">USER</code> excludes only the definitions of users, not the objects contained within users' schemas.</p>
<p>To exclude a specific user and all objects of that user, specify a command such as the following, where <code dir="ltr">hr</code> is the schema name of the user you want to exclude.</p>
<p><code dir="ltr">impdp FULL=YES DUMPFILE=expfull.dmp EXCLUDE=SCHEMA:"='HR'"</code></p>
<p>Note that in this situation, an import mode of <code dir="ltr">FULL</code> is specified. If no mode were specified, then the default mode, <code dir="ltr">SCHEMAS</code>, would be used. This would cause an error because the command would indicate that the schema should be both imported and excluded at the same time.</p>
<p>If you try to exclude a user by using a statement such as <code dir="ltr">EXCLUDE</code>=<code dir="ltr">USER</code>:"= '<code dir="ltr">HR</code>'", then only <code dir="ltr">CREATE USER hr</code> DDL statements will be excluded, and you may not get the results you expect.</p>
<p class="subhead1"><a id="SUTIL3127"></a>Restrictions</p>
<ul>
<li>
<p>The <code dir="ltr">EXCLUDE</code> and <code dir="ltr">INCLUDE</code> parameters are mutually exclusive.</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3128"></a>Example</p>
<p>Assume the following is in a parameter file, <code dir="ltr">exclude.par</code>, being used by a DBA or some other user with the <code dir="ltr">DATAPUMP_IMP_FULL_DATABASE</code> role. (If you want to try the example, then you must create this file.)</p>
<pre dir="ltr">
EXCLUDE=FUNCTION
EXCLUDE=PROCEDURE
EXCLUDE=PACKAGE
EXCLUDE=INDEX:"LIKE 'EMP%' "
</pre>
<p>You could then issue the following command. You can create the <code dir="ltr">expfull.dmp</code> dump file used in this command by running the example provided for the Export <code dir="ltr">FULL</code> parameter. See <a href="dp_export.htm#i1006790">"FULL"</a>.</p>
<pre dir="ltr">
&gt; impdp system DIRECTORY=dpump_dir1 DUMPFILE=expfull.dmp PARFILE=exclude.par
</pre>
<p>All data from the <code dir="ltr">expfull.dmp</code> dump file will be loaded except for functions, procedures, packages, and indexes whose names start with <code dir="ltr">emp</code>.</p>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<a href="#i1009204">"Filtering During Import Operations"</a> for more information about the effects of using the <code dir="ltr">EXCLUDE</code> parameter</div>
</div>
<!-- class="sect2" -->
<a id="i1007383"></a>
<div id="SUTIL912" class="sect2">
<h3 class="sect2">FLASHBACK_SCN<a id="sthref235"></a></h3>
<p>Default: There is no default</p>
<p class="subhead1"><a id="SUTIL3129"></a>Purpose</p>
<p>Specifies<a id="sthref236"></a> the system change number (SCN) that Import will use to enable the Flashback utility.</p>
<p class="subhead1"><a id="SUTIL3130"></a>Syntax and Description</p>
<pre dir="ltr">
FLASHBACK_SCN=<span class="italic">scn_number</span>
</pre>
<p>The import operation is performed with data that is consistent up to the specified <code dir="ltr"><span class="codeinlineitalic">scn_number</span></code>.</p>
<div class="infobox-note">
<p class="notep1">Note:</p>
If you are on a logical standby system, then the <code dir="ltr">FLASHBACK_SCN</code> parameter is ignored because SCNs are selected by logical standby. See <a class="olink SBYDB" href="../e41134/toc.htm"><span class="italic">Oracle Data Guard Concepts and Administration</span></a> for information about logical standby databases.</div>
<p class="subhead1"><a id="SUTIL3131"></a>Restrictions</p>
<ul>
<li>
<p>The <code dir="ltr">FLASHBACK_SCN</code> parameter is valid only when the <code dir="ltr">NETWORK_LINK</code> parameter is also specified.</p>
</li>
<li>
<p>The <code dir="ltr">FLASHBACK_SCN</code> parameter pertains only to the Flashback Query capability of Oracle Database. It is not applicable to Flashback Database, Flashback Drop, or Flashback Data Archive.</p>
</li>
<li>
<p><code dir="ltr">FLASHBACK_SCN</code> and <code dir="ltr">FLASHBACK_TIME</code> are mutually exclusive.</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3132"></a>Example</p>
<p>The following is an example of using the <code dir="ltr">FLASHBACK_SCN</code> parameter.</p>
<pre dir="ltr">
&gt; impdp hr DIRECTORY=dpump_dir1 FLASHBACK_SCN=<span class="italic">123456</span> 
NETWORK_LINK=<span class="italic">source_database_link</span>
</pre>
<p>The <code dir="ltr"><span class="codeinlineitalic">source_database_link</span></code> in this example would be replaced with the name of a source database from which you were importing data.</p>
</div>
<!-- class="sect2" -->
<a id="i1007384"></a>
<div id="SUTIL913" class="sect2">
<h3 class="sect2">FLASHBACK_TIME<a id="sthref237"></a></h3>
<p>Default: There is no default</p>
<p class="subhead1"><a id="SUTIL3133"></a>Purpose</p>
<p>Specifies the system change number (SCN) that Import will use to enable the Flashback utility.</p>
<p class="subhead1"><a id="SUTIL3134"></a>Syntax and Description</p>
<pre dir="ltr">
FLASHBACK_TIME="TO_TIMESTAMP()"
</pre>
<p>The SCN that most closely matches<a id="sthref238"></a> the specified time is found, and this SCN is used to enable the Flashback utility. The import operation is performed with data that is consistent up to this SCN. Because the <code dir="ltr">TO_TIMESTAMP</code> value is enclosed in quotation marks, it would be best to put this parameter in a parameter file. See <a href="#BEHECGCA">"Use of Quotation Marks On the Data Pump Command Line"</a>.</p>
<div class="infobox-note">
<p class="notep1">Note:</p>
If you are on a logical standby system, then the <code dir="ltr">FLASHBACK_TIME</code> parameter is ignored because SCNs are selected by logical standby. See <a class="olink SBYDB" href="../e41134/toc.htm"><span class="italic">Oracle Data Guard Concepts and Administration</span></a> for information about logical standby databases.</div>
<p class="subhead1"><a id="SUTIL3135"></a>Restrictions</p>
<ul>
<li>
<p>This parameter is valid only when the <code dir="ltr">NETWORK_LINK</code> parameter is also specified.</p>
</li>
<li>
<p>The <code dir="ltr">FLASHBACK_TIME</code> parameter pertains only to the flashback query capability of Oracle Database. It is not applicable to Flashback Database, Flashback Drop, or Flashback Data Archive.</p>
</li>
<li>
<p><code dir="ltr">FLASHBACK_TIME</code> and <code dir="ltr">FLASHBACK_SCN</code> are mutually exclusive.</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3136"></a>Example</p>
<p>You can specify the time in any format that the <code dir="ltr">DBMS_FLASHBACK.ENABLE_AT_TIME</code> procedure accepts,. For example, suppose you have a parameter file, flashback_imp.par, that contains the following:</p>
<pre dir="ltr">
FLASHBACK_TIME="TO_TIMESTAMP('25-08-2008 14:35:00', 'DD-MM-YYYY HH24:MI:SS')"
</pre>
<p>You could then issue the following command:</p>
<pre dir="ltr">
&gt; impdp hr DIRECTORY=dpump_dir1 PARFILE=flashback_imp.par NETWORK_LINK=<span class="codeinlineitalic">source_database_link</span>
</pre>
<p>The import operation will be performed with data that is consistent with the SCN that most closely matches the specified time.</p>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<a class="olink ADFNS" href="../../appdev.112/e41502/toc.htm"><span class="italic">Oracle Database Advanced Application Developer's Guide</span></a> for information about using flashback</div>
</div>
<!-- class="sect2" -->
<a id="i1007012"></a>
<div id="SUTIL914" class="sect2">
<h3 class="sect2">FULL<a id="sthref239"></a></h3>
<p>Default: <code dir="ltr">Y</code>ES</p>
<p class="subhead1"><a id="SUTIL3137"></a>Purpose</p>
<p>Specifies that you want to perform a full database import.</p>
<p class="subhead1"><a id="SUTIL3138"></a>Syntax and Description</p>
<pre dir="ltr">
FULL=YES
</pre>
<p>A value of <code dir="ltr">FULL=YES</code> indicates that all data and metadata from the source (either a dump file set or another database) is imported.</p>
<p>Filtering can restrict what is imported using this import mode (see <a href="#i1009204">"Filtering During Import Operations"</a>).<a id="sthref240"></a></p>
<p>If the <code dir="ltr">NETWORK_LINK</code> parameter is used and the <code dir="ltr">USERID</code> that is executing the import job has the <code dir="ltr">DATAPUMP_IMP_FULL_DATABASE</code> role on the target database, then that user must also have the <code dir="ltr">DATAPUMP_EXP_FULL_DATABASE</code> role on the source database.</p>
<p>If you are an unprivileged user importing from a file, then only schemas that map to your own schema are imported.</p>
<p><code dir="ltr">FULL</code> is the default mode when you are performing a file-based import.</p>
<p class="subhead1"><a id="SUTIL3139"></a>Example</p>
<p>The following is an example of using the <code dir="ltr">FULL</code> parameter. You can create the <code dir="ltr">expfull.dmp</code> dump file used in this example by running the example provided for the Export <code dir="ltr">FULL</code> parameter. See <a href="dp_export.htm#i1006790">"FULL"</a>.</p>
<pre dir="ltr">
&gt; impdp hr DUMPFILE=dpump_dir1:expfull.dmp FULL=YES 
LOGFILE=dpump_dir2:full_imp.log
</pre>
<p>This example imports everything from the <code dir="ltr">expfull.dmp</code> dump file. In this example, a <code dir="ltr">DIRECTORY</code> parameter is not provided. Therefore, a directory object must be provided on both the <code dir="ltr">DUMPFILE</code> parameter and the <code dir="ltr">LOGFILE</code> parameter. The directory objects can be different, as shown in this example.</p>
</div>
<!-- class="sect2" -->
<div id="SUTIL915" class="sect2"><a id="sthref241"></a>
<h3 class="sect2">HELP<a id="sthref242"></a></h3>
<p>Default: <code dir="ltr">NO</code></p>
<p class="subhead1"><a id="SUTIL3140"></a>Purpose</p>
<p>Displays online help for the Import utility.</p>
<p class="subhead1"><a id="SUTIL3141"></a>Syntax and Description</p>
<pre dir="ltr">
HELP=YES
</pre>
<p>If <code dir="ltr">HELP</code>=<code dir="ltr">YES</code> is specified, then Import displays a summary<a id="sthref243"></a> of all Import command-line parameters and interactive commands.</p>
<p class="subhead1"><a id="SUTIL3142"></a>Example</p>
<pre dir="ltr">
&gt; impdp HELP = YES
</pre>
<p>This example will display a brief description of all Import parameters and commands.</p>
</div>
<!-- class="sect2" -->
<a id="i1007761"></a>
<div id="SUTIL916" class="sect2">
<h3 class="sect2">INCLUDE<a id="sthref244"></a></h3>
<p>Default: There is no default</p>
<p class="subhead1"><a id="SUTIL3143"></a>Purpose</p>
<p><a id="sthref245"></a>Enables you to filter<a id="sthref246"></a> the metadata that is imported by specifying objects and object types for the current import mode.</p>
<p class="subhead1"><a id="SUTIL3144"></a>Syntax and Description</p>
<pre dir="ltr">
INCLUDE = <span class="italic">object_type</span>[:<span class="italic">name_clause</span>] [, ...]
</pre>
<p>The <code dir="ltr"><span class="codeinlineitalic">object_type</span></code> specifies the type of object to be included. To see a list of valid values for <code dir="ltr"><span class="codeinlineitalic">object_type</span></code>, query the following views: <code dir="ltr">DATABASE_EXPORT_OBJECTS</code> for full mode, <code dir="ltr">SCHEMA_EXPORT_OBJECTS</code> for schema mode, and <code dir="ltr">TABLE_EXPORT_OBJECTS</code> for table and tablespace mode. The values listed in the <code dir="ltr">OBJECT_PATH</code> column are the valid object types.</p>
<p>Only object types in the source (and their dependents) that are explicitly specified in the <code dir="ltr">INCLUDE</code> statement are imported.</p>
<p>The <code dir="ltr"><span class="codeinlineitalic">name_clause</span></code> is optional. It allows fine-grained selection of specific objects within an object type. It is a SQL expression used as a filter on the object names of the type. It consists of a SQL operator and the values against which the object names of the specified type are to be compared. The <code dir="ltr"><span class="codeinlineitalic">name_clause</span></code> applies only to object types whose instances have names (for example, it is applicable to <code dir="ltr">TABLE</code>, but not to <code dir="ltr">GRANT</code>). It must be separated from the object type with a colon and enclosed in double quotation marks, because single quotation marks are required to delimit the name strings.</p>
<p>The name that you supply for the <code dir="ltr"><span class="codeinlineitalic">name_clause</span></code> must exactly match, including upper and lower casing, an existing object in the database. For example, if the <code dir="ltr"><span class="codeinlineitalic">name_clause</span></code> you supply is for a table named <code dir="ltr">EMPLOYEES</code>, then there must be an existing table named <code dir="ltr">EMPLOYEES</code> using all upper case. If the <code dir="ltr"><span class="codeinlineitalic">name_clause</span></code> were supplied as <code dir="ltr">Employees</code> or <code dir="ltr">employees</code> or any other variation, then the table would not be found.</p>
<p>More than one <code dir="ltr">INCLUDE</code> statement can be specified.</p>
<p>Depending on your operating system, the use of quotation marks when you specify a value for this parameter may also require that you use escape characters. Oracle recommends that you place this parameter in a parameter file, which can reduce the number of escape characters that might otherwise be needed on the command line. See <a href="#BEHECGCA">"Use of Quotation Marks On the Data Pump Command Line"</a>.</p>
<p>To see a list of valid paths for use with the <code dir="ltr">INCLUDE</code> parameter, you can query the following views: <code dir="ltr">DATABASE_EXPORT_OBJECTS</code> for Full mode, <code dir="ltr">SCHEMA_EXPORT_OBJECTS</code> for schema mode, and <code dir="ltr">TABLE_EXPORT_OBJECTS</code> for table and tablespace mode.</p>
<p class="subhead1"><a id="SUTIL3145"></a>Restrictions</p>
<ul>
<li>
<p>The <code dir="ltr">INCLUDE</code> and <code dir="ltr">EXCLUDE</code> parameters are mutually exclusive.</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3146"></a>Example</p>
<p>Assume the following is in a parameter file, <code dir="ltr">imp_include.par</code>, being used by a DBA or some other user with the <code dir="ltr">DATAPUMP_IMP_FULL_DATABASE</code> role:</p>
<pre dir="ltr">
INCLUDE=FUNCTION
INCLUDE=PROCEDURE
INCLUDE=PACKAGE
INCLUDE=INDEX:"LIKE 'EMP%' "
</pre>
<p>You can then issue the following command:</p>
<pre dir="ltr">
&gt; impdp system SCHEMAS=hr DIRECTORY=dpump_dir1 DUMPFILE=expfull.dmp 
PARFILE=imp_include.par
</pre>
<p>You can create the <code dir="ltr">expfull.dmp</code> dump file used in this example by running the example provided for the Export <code dir="ltr">FULL</code> parameter. See <a href="dp_export.htm#i1006790">"FULL"</a>.</p>
<p>The Import operation will load only functions, procedures, and packages from the <code dir="ltr">hr</code> schema and indexes whose names start with <code dir="ltr">EMP</code>. Although this is a privileged-mode import (the user must have the <code dir="ltr">DATAPUMP_IMP_FULL_DATABASE</code> role), the schema definition is not imported, because the <code dir="ltr">USER</code> object type was not specified in an <code dir="ltr">INCLUDE</code> statement.</p>
</div>
<!-- class="sect2" -->
<div id="SUTIL917" class="sect2"><a id="sthref247"></a>
<h3 class="sect2">JOB_NAME<a id="sthref248"></a></h3>
<p>Default: system-generated name of the form <code dir="ltr">SYS_&lt;IMPORT or SQLFILE&gt;_&lt;mode&gt;_NN</code></p>
<p class="subhead1"><a id="SUTIL3147"></a>Purpose</p>
<p>The job name is used to identify the import job in subsequent actions, such as when the <code dir="ltr">ATTACH</code> parameter is used to attach to a job, or to identify the job via the <code dir="ltr">DBA_DATAPUMP_JOBS</code> or <code dir="ltr">USER_DATAPUMP_JOBS</code> views.</p>
<p class="subhead1"><a id="SUTIL3148"></a>Syntax and Description</p>
<pre dir="ltr">
JOB_NAME=<span class="italic">jobname_string</span>
</pre>
<p>The <code dir="ltr"><span class="codeinlineitalic">jobname_string</span></code> specifies<a id="sthref249"></a> a name<a id="sthref250"></a> of up to 30 bytes for this import job. The bytes must represent printable characters and spaces. If spaces are included, then the name must be enclosed in single quotation marks (for example, 'Thursday Import'). The job name is implicitly qualified by the schema of the user performing the import operation. The job name is used as the name of the master table, which controls the export job.</p>
<p>The default job name is system-generated in the form <code dir="ltr">SYS_IMPORT_mode_NN</code> or <code dir="ltr">SYS_SQLFILE_mode_NN</code>, where <code dir="ltr">NN</code> expands to a 2-digit incrementing integer starting at 01. An example of a default name is <code dir="ltr">'SYS_IMPORT_TABLESPACE_02</code>'.</p>
<p class="subhead1"><a id="SUTIL3149"></a>Example</p>
<p>The following is an example of using the <code dir="ltr">JOB_NAME</code> parameter. You can create the <code dir="ltr">expfull.dmp</code> dump file used in this example by running the example provided for the Export <code dir="ltr">FULL</code> parameter. See <a href="dp_export.htm#i1006790">"FULL"</a>.</p>
<pre dir="ltr">
&gt; impdp hr DIRECTORY=dpump_dir1 DUMPFILE=expfull.dmp JOB_NAME=impjob01
</pre></div>
<!-- class="sect2" -->
<div id="SUTIL3867" class="sect2"><!-- infolevel="all" infotype="General" --><a id="sthref251"></a>
<h3 class="sect2">KEEP_MASTER</h3>
<p>Default: <code dir="ltr">NO</code></p>
<p class="subhead1"><a id="SUTIL3868"></a>Purpose</p>
<p>Indicates whether the master table should be deleted or retained at the end of a Data Pump job that completes successfully. The master table is automatically retained for jobs that do not complete successfully.</p>
<p class="subhead1"><a id="SUTIL3869"></a>Syntax and Description</p>
<pre dir="ltr">
KEEP_MASTER=[YES | NO]
</pre>
<p class="subhead1"><a id="SUTIL3870"></a>Restrictions</p>
<ul>
<li>
<p>None</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3871"></a>Example</p>
<pre dir="ltr">
&gt; impdp hr SCHEMAS=hr DIRECTORY=dpump_dir1 LOGFILE=schemas.log
DUMPFILE=expdat.dmp KEEP_MASTER=YES
</pre></div>
<!-- class="sect2" -->
<a id="BABGBCBH"></a>
<div id="SUTIL918" class="sect2">
<h3 class="sect2">LOGFILE<a id="sthref252"></a></h3>
<p>Default: <code dir="ltr">import</code>.<code dir="ltr">log</code></p>
<p class="subhead1"><a id="SUTIL3150"></a>Purpose</p>
<p>Specifies the name<a id="sthref253"></a>, and optionally, a directory object, for the log file of the import job.</p>
<p class="subhead1"><a id="SUTIL3151"></a>Syntax and Description</p>
<pre dir="ltr">
LOGFILE=[<span class="italic">directory_object</span>:]<span class="italic">file_name</span>
</pre>
<p>If you specify a <code dir="ltr"><span class="codeinlineitalic">directory_object</span></code>, then it must be one that was previously established by the DBA and that you have access to. This overrides the directory object specified with the <code dir="ltr">DIRECTORY</code> parameter. The default behavior is to create <code dir="ltr">import</code>.<code dir="ltr">log</code> in the directory referenced by the directory object specified in the <code dir="ltr">DIRECTORY</code> parameter.</p>
<p>If the <code dir="ltr"><span class="codeinlineitalic">file_name</span></code> you specify already exists, then it will be overwritten.</p>
<p>All messages regarding work in progress, work completed, and errors encountered are written to the log file. (For a real-time status of the job, use the <code dir="ltr">STATUS</code> command in interactive mode.)</p>
<p>A log file is always created unless the <code dir="ltr">NOLOGFILE</code> parameter is specified. As with the dump file set, the log file is relative to the server and not the client.</p>
<div class="infobox-note">
<p class="notep1">Note:</p>
Data Pump Import writes the log file using the database character set. If your client <code dir="ltr">NLS_LANG</code> environment sets up a different client character set from the database character set, then it is possible that table names may be different in the log file than they are when displayed on the client output screen.</div>
<p class="subhead1"><a id="SUTIL3152"></a>Restrictions</p>
<ul>
<li>
<p>To perform a Data Pump Import using Oracle Automatic Storage Management (Oracle ASM), you must specify a <code dir="ltr">LOGFILE</code> parameter that includes a directory object that does not include the Oracle ASM + notation. That is, the log file must be written to a disk file, and not written into the Oracle ASM storage. Alternatively, you can specify <code dir="ltr">NOLOGFILE=YES</code>. However, this prevents the writing of the log file.</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3153"></a>Example</p>
<p>The following is an example of using the <code dir="ltr">LOGFILE</code> parameter. You can create the <code dir="ltr">expfull.dmp</code> dump file used in this example by running the example provided for the Export <code dir="ltr">FULL</code> parameter. See <a href="dp_export.htm#i1006790">"FULL"</a>.</p>
<pre dir="ltr">
&gt; impdp hr SCHEMAS=HR DIRECTORY=dpump_dir2 LOGFILE=imp.log
 DUMPFILE=dpump_dir1:expfull.dmp
</pre>
<p>Because no directory object is specified on the <code dir="ltr">LOGFILE</code> parameter, the log file is written to the directory object specified on the <code dir="ltr">DIRECTORY</code> parameter.</p>
<div class="infoboxnotealso">
<p class="notep1"><span class="bold">See Also</span>:</p>
<ul>
<li>
<p><a href="#i1008677">"STATUS"</a></p>
</li>
<li>
<p><a href="dp_overview.htm#i1009537">"Using Directory Objects When Oracle Automatic Storage Management Is Enabled"</a> for information about Oracle Automatic Storage Management and directory objects</p>
</li>
</ul>
</div>
</div>
<!-- class="sect2" -->
<div id="SUTIL3872" class="sect2"><!-- infolevel="all" infotype="General" --><a id="sthref254"></a>
<h3 class="sect2">MASTER_ONLY</h3>
<p>Default: <code dir="ltr">NO</code></p>
<p class="subhead1"><a id="SUTIL3873"></a>Purpose</p>
<p>Indicates whether to import just the master table and then stop the job so that the contents of the master table can be examined.</p>
<p class="subhead1"><a id="SUTIL3874"></a>Syntax and Description</p>
<pre dir="ltr">
MASTER_ONLY=[YES | NO]
</pre>
<p class="subhead1"><a id="SUTIL3875"></a>Restrictions</p>
<ul>
<li>
<p>If the <code dir="ltr">NETWORK_LINK</code> parameter is also specified, then <code dir="ltr">MASTER_ONLY=YES</code> is not supported.</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3876"></a>Example</p>
<pre dir="ltr">
&gt; impdp hr SCHEMAS=hr DIRECTORY=dpump_dir1 LOGFILE=schemas.log
DUMPFILE=expdat.dmp MASTER_ONLY=YES
</pre></div>
<!-- class="sect2" -->
<div id="SUTIL3877" class="sect2"><!-- infolevel="all" infotype="General" --><a id="sthref255"></a>
<h3 class="sect2">METRICS</h3>
<p>Default: <code dir="ltr">NO</code></p>
<p class="subhead1"><a id="SUTIL3878"></a>Purpose</p>
<p>Indicates whether additional information about the job should be reported to the Data Pump log file.</p>
<p class="subhead1"><a id="SUTIL3879"></a>Syntax and Description</p>
<pre dir="ltr">
METRICS=[YES | NO]
</pre>
<p>When <code dir="ltr">METRICS=YES</code> is used, the number of objects and the elapsed time are recorded in the Data Pump log file.</p>
<p class="subhead1"><a id="SUTIL3880"></a>Restrictions</p>
<ul>
<li>
<p>None</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3881"></a>Example</p>
<pre dir="ltr">
&gt; impdp hr SCHEMAS=hr DIRECTORY=dpump_dir1 LOGFILE=schemas.log
DUMPFILE=expdat.dmp METRICS=YES
</pre></div>
<!-- class="sect2" -->
<a id="i1007380"></a>
<div id="SUTIL919" class="sect2">
<h3 class="sect2">NETWORK_LINK<a id="sthref256"></a></h3>
<p>Default: There is no default</p>
<p class="subhead1"><a id="SUTIL3154"></a>Purpose</p>
<p>Enables an import from a (source) database identified by a valid database link. The data from the source database instance is written directly back to the connected database instance.</p>
<p class="subhead1"><a id="SUTIL3155"></a>Syntax and Description</p>
<pre dir="ltr">
NETWORK_LINK=<span class="italic">source_database_link</span>
</pre>
<p>The <code dir="ltr">NETWORK_LINK</code> parameter initiates an import via a database link. This means that the system to which the <code dir="ltr">impdp</code> client is connected contacts the source database referenced by the <code dir="ltr"><span class="codeinlineitalic">source_database_link</span></code>, retrieves data from it, and writes the data directly to the database on the connected instance. There are no dump files involved.</p>
<p>The <code dir="ltr"><span class="codeinlineitalic">source_database_link</span></code> provided must be the name of a database link to an available database. If the database on that instance does not already have a database link, then you or your DBA must create one using the SQL <code dir="ltr">CREATE DATABASE LINK</code> statement.</p>
<p>When you perform a network import using the transportable method, you must copy the source data files to the target database <span class="italic">before</span> you start the import.</p>
<p>If the source database is read-only, then the connected user must have a locally managed tablespace assigned as the default temporary tablespace on the source database. Otherwise, the job will fail.</p>
<p>This parameter is required when any of the following parameters are specified: <code dir="ltr">FLASHBACK_SCN</code>, <code dir="ltr">FLASHBACK_TIME</code>, <code dir="ltr">ESTIMATE</code>, <code dir="ltr">TRANSPORT_TABLESPACES</code>, or <code dir="ltr">TRANSPORTABLE</code>.</p>
<div class="infobox-note">
<p class="notep1">Caution:</p>
If an import operation is performed over an unencrypted network link, then all data is imported as clear text even if it is encrypted in the database. See <a class="olink ASOAG" href="../../network.112/e40393/toc.htm"><span class="italic">Oracle Database Advanced Security Administrator's Guide</span></a> for more information about network security.</div>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<ul>
<li>
<p><a class="olink ADMIN12083" href="../../server.112/e25494/ds_concepts.htm#ADMIN12083"><span class="italic">Oracle Database Administrator's Guide</span></a> for more information about database links</p>
</li>
<li>
<p><a class="olink SQLRF01205" href="../../server.112/e41084/statements_5005.htm#SQLRF01205"><span class="italic">Oracle Database SQL Language Reference</span></a> for more information about the <code dir="ltr">CREATE DATABASE LINK</code> statement</p>
</li>
<li>
<p><a class="olink ADMIN11367" href="../../server.112/e25494/tspaces.htm#ADMIN11367"><span class="italic">Oracle Database Administrator's Guide</span></a> for more information about locally managed tablespaces</p>
</li>
</ul>
</div>
<p class="subhead1"><a id="SUTIL3156"></a>Restrictions</p>
<ul>
<li>
<p>The Import <code dir="ltr">NETWORK_LINK</code> parameter is not supported for tables containing SecureFiles that have ContentType set or that are currently stored outside of the SecureFiles segment through Oracle Database File System Links.</p>
</li>
<li>
<p>Network imports do not support the use of evolved types.</p>
</li>
<li>
<p>Network imports do not support <code dir="ltr">LONG</code> columns.</p>
</li>
<li>
<p>When operating across a network link, Data Pump requires that the source and target databases differ by no more than one version. For example, if one database is Oracle Database 11<span class="italic">g</span>, then the other database must be either 11<span class="italic">g</span> or 10<span class="italic">g</span>. Note that Data Pump checks only the major version number (for example, 10<span class="italic">g</span> and 11<span class="italic">g</span>), not specific release numbers (for example, 10.1, 10.2, 11.1, or 11.2).</p>
</li>
<li>
<p>If the <code dir="ltr">USERID</code> that is executing the import job has the <code dir="ltr">DATAPUMP_IMP_FULL_DATABASE</code> role on the target database, then that user must also have the <code dir="ltr">DATAPUMP_EXP_FULL_DATABASE</code> role on the source database.</p>
</li>
<li>
<p>The only types of database links supported by Data Pump Import are: public, fixed user, and connected user. Current-user database links are not supported.</p>
</li>
<li>
<p>Network mode import does not use parallel query (PQ) slaves. See <a href="#BEHFCBEI">"Using PARALLEL During a Network Mode Import"</a>.</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3157"></a>Example</p>
<p>In the following example, the <code dir="ltr"><span class="codeinlineitalic">source_database_link</span></code> would be replaced with the name of a valid database link.</p>
<pre dir="ltr">
&gt; impdp hr TABLES=employees DIRECTORY=dpump_dir1
NETWORK_LINK=<span class="italic">source_database_link</span> EXCLUDE=CONSTRAINT
</pre>
<p>This example results in an import of the <code dir="ltr">employees</code> table (excluding constraints) from the source database. The log file is written to <code dir="ltr">dpump_dir1</code>, specified on the <code dir="ltr">DIRECTORY</code> parameter.</p>
</div>
<!-- class="sect2" -->
<a id="i1007381"></a>
<div id="SUTIL920" class="sect2">
<h3 class="sect2">NOLOGFILE<a id="sthref257"></a><a id="sthref258"></a></h3>
<p>Default: <code dir="ltr">NO</code></p>
<p class="subhead1"><a id="SUTIL3158"></a>Purpose</p>
<p>Specifies whether to suppress the default behavior of creating a log file.</p>
<p class="subhead1"><a id="SUTIL3159"></a>Syntax and Description</p>
<pre dir="ltr">
NOLOGFILE=[YES | NO]
</pre>
<p>If you specify <code dir="ltr">NOLOGFILE=YES</code> to suppress creation of a log file, then progress and error information is still written to the standard output device of any attached clients, including the client that started the original export operation. If there are no clients attached to a running job and you specify <code dir="ltr">NOLOGFILE=YES</code>, then you run the risk of losing important progress and error information.</p>
<p class="subhead1"><a id="SUTIL3160"></a>Example</p>
<p>The following is an example of using the <code dir="ltr">NOLOGFILE</code> parameter.</p>
<pre dir="ltr">
&gt; impdp hr DIRECTORY=dpump_dir1 DUMPFILE=expfull.dmp NOLOGFILE=YES
</pre>
<p>This command results in a full mode import (the default for file-based imports) of the <code dir="ltr">expfull.dmp</code> dump file. No log file is written because <code dir="ltr">NOLOGFILE</code> is set to <code dir="ltr">YES</code>.</p>
</div>
<!-- class="sect2" -->
<a id="i1006596"></a>
<div id="SUTIL921" class="sect2">
<h3 class="sect2">PARALLEL<a id="sthref259"></a></h3>
<p>Default: <code dir="ltr">1</code></p>
<p class="subhead1"><a id="SUTIL3161"></a>Purpose</p>
<p>Specifies the maximum number of processes of active execution operating on behalf of the import job.</p>
<p class="subhead1"><a id="SUTIL3162"></a>Syntax and Description</p>
<pre dir="ltr">
PARALLEL=<span class="italic">integer</span>
</pre>
<p>The value you specify for <code dir="ltr"><span class="codeinlineitalic">integer</span></code> specifies<a id="sthref260"></a> the maximum number of processes of active execution operating on behalf of the import job. This execution set consists of a combination of worker processes and parallel I/O server processes. The master control process, idle workers, and worker processes acting as parallel execution coordinators in parallel I/O operations do not count toward this total. This parameter enables you to make trade-offs between resource consumption and elapsed time.</p>
<p>If the source of the import is a dump file set consisting of files, then multiple processes can read from the same file, but performance may be limited by I/O contention.</p>
<p>To increase or decrease the value of <code dir="ltr">PARALLEL</code> during job execution, use interactive-command mode.</p>
<p>Parallelism is used for loading user data and package bodies, and for building indexes.</p>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<a href="dp_perf.htm#i1005599">"Controlling Resource Consumption"</a></div>
<p class="subhead2"><a id="BEHFCBEI"></a><a id="SUTIL3771"></a>Using PARALLEL During a Network Mode Import</p>
<p>During a network mode import, the <code dir="ltr">PARALLEL</code> parameter defines the maximum number of worker processes that can be assigned to the job. To understand the effect of the <code dir="ltr">PARALLEL</code> parameter during a network import mode, it is important to understand the concept of "table_data objects" as defined by Data Pump. When Data Pump moves data, it considers the following items to be individual "table_data objects":</p>
<ul>
<li>
<p>a complete table (one that is not partitioned or subpartitioned)</p>
</li>
<li>
<p>partitions, if the table is partitioned but not subpartitioned</p>
</li>
<li>
<p>subpartitions, if the table is subpartitioned</p>
</li>
</ul>
<p>For example:</p>
<ul>
<li>
<p>A nonpartitioned table, <code dir="ltr">scott.non_part_table</code>, has 1 table_data object:</p>
<p><code dir="ltr">scott.non_part_table</code></p>
</li>
<li>
<p>A partitioned table, <code dir="ltr">scott.part_table</code> (having partition <code dir="ltr">p1</code> and partition <code dir="ltr">p2</code>), has 2 table_data objects:</p>
<p><code dir="ltr">scott.part_table:p1</code></p>
<p><code dir="ltr">scott.part_table:p</code>2</p>
</li>
<li>
<p>A subpartitioned table, <code dir="ltr">scott.sub_part_table</code> (having partition <code dir="ltr">p1</code> and <code dir="ltr">p2</code>, and subpartitions <code dir="ltr">p1s1</code>, <code dir="ltr">p1s2</code>, <code dir="ltr">p2s1</code>, and <code dir="ltr">p2s2</code>) has 4 table_data objects:</p>
<p><code dir="ltr">scott.sub_part_table:p1s1</code></p>
<p><code dir="ltr">scott.sub_part_table:p1s2</code></p>
<p><code dir="ltr">scott.sub_part_table:p2s1</code></p>
<p><code dir="ltr">scott.sub_part_table:p2s2</code></p>
</li>
</ul>
<p>During a network mode import, each table_data object is assigned its own worker process, up to the value specified for the <code dir="ltr">PARALLEL</code> parameter. No parallel query (PQ) slaves are assigned because network mode import does not use parallel query (PQ) slaves. Multiple table_data objects <span class="italic">can</span> be unloaded at the same time, but each table_data object is unloaded using a single process.</p>
<p class="subhead2"><a id="CIHFEFCD"></a><a id="SUTIL3163"></a>Using PARALLEL During An Import In An Oracle RAC Environment</p>
<p>In an Oracle Real Application Clusters (Oracle RAC) environment, if an import operation has <code dir="ltr">PARALLEL=1</code>, then all Data Pump processes reside on the instance where the job is started. Therefore, the directory object can point to local storage for that instance.</p>
<p>If the import operation has <code dir="ltr">PARALLEL</code> set to a value greater than 1, then Data Pump processes can reside on instances other than the one where the job was started. Therefore, the directory object must point to shared storage that is accessible by all instances of the Oracle RAC.</p>
<p class="subhead1"><a id="SUTIL3164"></a>Restrictions</p>
<ul>
<li>
<p>This parameter is valid only in the Enterprise Edition of Oracle Database 11<span class="italic">g</span>.</p>
</li>
<li>
<p>To import a table or table partition in parallel (using PQ slaves), you must have the <code dir="ltr">DATAPUMP_IMP_FULL_DATABASE</code> role.</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3165"></a>Example</p>
<p>The following is an example of using the <code dir="ltr">PARALLEL</code> parameter.</p>
<pre dir="ltr">
&gt; impdp hr DIRECTORY=dpump_dir1 LOGFILE=parallel_import.log 
JOB_NAME=imp_par3 DUMPFILE=par_exp%U.dmp PARALLEL=3
</pre>
<p>This command imports the dump file set that is created when you run the example for the Export <code dir="ltr">PARALLEL</code> parameter. (See <a href="dp_export.htm#i1006404">"PARALLEL"</a>.) The names of the dump files are <code dir="ltr">par_exp01.dmp</code>, <code dir="ltr">par_exp02.dmp</code>, and <code dir="ltr">par_exp03.dmp</code>.</p>
</div>
<!-- class="sect2" -->
<a id="CIHGFACC"></a>
<div id="SUTIL922" class="sect2">
<h3 class="sect2">PARFILE<a id="sthref261"></a></h3>
<p>Default: There is no default</p>
<p class="subhead1"><a id="SUTIL3166"></a>Purpose</p>
<p>Specifies<a id="sthref262"></a> the name of an import parameter file.</p>
<p class="subhead1"><a id="SUTIL3167"></a>Syntax and Description</p>
<pre dir="ltr">
PARFILE=[<span class="italic">directory_path</span>]<span class="italic">file_name</span>
</pre>
<p>Unlike dump files, log files, and SQL files which are created and written by the server, the parameter file is opened and read by the <code dir="ltr">impdp</code> client. Therefore, a directory object name is neither required nor appropriate. The default is the user's current directory. The use of parameter files is highly recommended if you are using parameters whose values require the use of quotation marks.</p>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<a href="#BEHECGCA">"Use of Quotation Marks On the Data Pump Command Line"</a></div>
<p class="subhead1"><a id="SUTIL3168"></a>Restrictions</p>
<ul>
<li>
<p>The <code dir="ltr">PARFILE</code> parameter cannot be specified within a parameter file.</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3169"></a>Example</p>
<p>The content of an example parameter file, <code dir="ltr">hr_imp.par</code>, might be as follows:</p>
<pre dir="ltr">
TABLES= countries, locations, regions
DUMPFILE=dpump_dir2:exp1.dmp,exp2%U.dmp
DIRECTORY=dpump_dir1
PARALLEL=3 
</pre>
<p>You could then issue the following command to execute the parameter file:</p>
<pre dir="ltr">
&gt; impdp hr PARFILE=hr_imp.par
</pre>
<p>The tables named <code dir="ltr">countries</code>, <code dir="ltr">locations</code>, and <code dir="ltr">regions</code> will be imported from the dump file set that is created when you run the example for the Export <code dir="ltr">DUMPFILE</code> parameter. (See <a href="dp_export.htm#i1006912">"DUMPFILE"</a>.) The import job looks for the <code dir="ltr">exp1.dmp</code> file in the location pointed to by <code dir="ltr">dpump_dir2</code>. It looks for any dump files of the form <code dir="ltr">exp2</code><code dir="ltr"><span class="codeinlineitalic">nn</span></code><code dir="ltr">.dmp</code> in the location pointed to by <code dir="ltr">dpump_dir1</code>. The log file for the job will also be written to <code dir="ltr">dpump_dir1</code>.</p>
</div>
<!-- class="sect2" -->
<a id="BABIGFDG"></a>
<div id="SUTIL923" class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2">PARTITION_OPTIONS<a id="sthref263"></a><a id="sthref264"></a></h3>
<p>Default: The default is <code dir="ltr">departition</code> when partition names are specified on the <code dir="ltr">TABLES</code> parameter and <code dir="ltr">TRANPORTABLE=ALWAYS</code> is set (whether on the import operation or during the export). Otherwise, the default is <code dir="ltr">none</code>.</p>
<p class="subhead1"><a id="SUTIL3170"></a>Purpose</p>
<p>Specifies how table partitions should be created during an import operation.</p>
<p class="subhead1"><a id="SUTIL3171"></a>Syntax and Description</p>
<pre dir="ltr">
PARTITION_OPTIONS=[NONE | DEPARTITION | MERGE]
</pre>
<p>A value of <code dir="ltr">none</code> creates tables as they existed on the system from which the export operation was performed. You cannot use the <code dir="ltr">none</code> option or the <code dir="ltr">merge</code> option if the export was performed with the transportable method, along with a partition or subpartition filter. In such a case, you must use the departition option.</p>
<p>A value of <code dir="ltr">departition</code> promotes each partition or subpartition to a new individual table. The default name of the new table will be the concatenation of the table and partition name or the table and subpartition name, as appropriate.</p>
<p>A value of <code dir="ltr">merge</code> combines all partitions and subpartitions into one table.</p>
<p>Parallel processing during import of partitioned tables is subject to the following:</p>
<ul>
<li>
<p>If a partitioned table is imported into an existing partitioned table, then Data Pump only processes one partition or subpartition at a time, regardless of any value that might be specified with the <code dir="ltr">PARALLEL</code> parameter.</p>
</li>
<li>
<p>If the table into which you are importing does not already exist and Data Pump has to create it, then the import runs in parallel up to the parallelism specified on the <code dir="ltr">PARALLEL</code> parameter when the import is started.</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3172"></a>Restrictions</p>
<ul>
<li>
<p>If the export operation that created the dump file was performed with the transportable method and if a partition or subpartition was specified, then the import operation must use the <code dir="ltr">departition</code> option.</p>
</li>
<li>
<p>If the export operation that created the dump file was performed with the transportable method, then the import operation cannot use <code dir="ltr">PARTITION_OPTIONS=MERGE</code>.</p>
</li>
<li>
<p>If there are any grants on objects being departitioned, then an error message is generated and the objects are not loaded.</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3173"></a>Example</p>
<p>The following example assumes that the <code dir="ltr">sh.sales</code> table has been exported into a dump file named <code dir="ltr">sales.dmp</code>. It uses the <code dir="ltr">merge</code> option to merge all the partitions in <code dir="ltr">sh.sales</code> into one non-partitioned table in <code dir="ltr">scott</code> schema.</p>
<pre dir="ltr">
&gt; impdp system TABLES=sh.sales PARTITION_OPTIONS=MERGE 
DIRECTORY=dpump_dir1 DUMPFILE=sales.dmp REMAP_SCHEMA=sh:scott
</pre>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<a href="dp_export.htm#BABCIEEI">"TRANSPORTABLE"</a> for an example of performing an import operation using <code dir="ltr">PARTITION_OPTIONS=DEPARTITION</code></div>
</div>
<!-- class="sect2" -->
<a id="i1007846"></a>
<div id="SUTIL924" class="sect2">
<h3 class="sect2">QUERY<a id="sthref265"></a></h3>
<p>Default: There is no default</p>
<p class="subhead1"><a id="SUTIL3174"></a>Purpose</p>
<p><a id="sthref266"></a>Allows you to specify a query clause that filters the data that gets imported.</p>
<p class="subhead1"><a id="SUTIL3175"></a>Syntax and Description</p>
<pre dir="ltr">
QUERY=[[<span class="italic">schema_name</span>.]<span class="italic">table_name</span>:]<span class="italic">query_clause</span>
</pre>
<p>The <code dir="ltr"><span class="codeinlineitalic">query_clause</span></code> is typically a SQL <code dir="ltr">WHERE</code> clause for fine-grained row selection, but could be any SQL clause. For example, an <code dir="ltr">ORDER BY</code> clause could be used to speed up a migration from a heap-organized table to an index-organized table. If a schema and table name are not supplied, then the query is applied to (and must be valid for) all tables in the source dump file set or database. A table-specific query overrides a query applied to all tables.</p>
<p>When the query is to be applied to a specific table, a colon (:) must separate the table name from the query clause. More than one table-specific query can be specified, but only one query can be specified per table.</p>
<p>If the <code dir="ltr">NETWORK_LINK</code> parameter is specified along with the <code dir="ltr">QUERY</code> parameter, then any objects specified in the <code dir="ltr"><span class="codeinlineitalic">query_clause</span></code> that are on the remote (source) node must be explicitly qualified with the <code dir="ltr">NETWORK_LINK</code> value. Otherwise, Data Pump assumes that the object is on the local (target) node; if it is not, then an error is returned and the import of the table from the remote (source) system fails.</p>
<p>For example, if you specify <code dir="ltr">NETWORK_LINK=dblink1</code>, then the <code dir="ltr"><span class="codeinlineitalic">query_clause</span></code> of the <code dir="ltr">QUERY</code> parameter must specify that link, as shown in the following example:</p>
<pre dir="ltr">
QUERY=(hr.employees:"WHERE last_name IN(SELECT last_name 
FROM hr.employees@dblink1)")
</pre>
<p>Depending on your operating system, the use of quotation marks when you specify a value for this parameter may also require that you use escape characters. Oracle recommends that you place this parameter in a parameter file, which can reduce the number of escape characters that might otherwise be needed on the command line. See <a href="#BEHECGCA">"Use of Quotation Marks On the Data Pump Command Line"</a>.</p>
<p>When the <code dir="ltr">QUERY</code> parameter is used, the external tables method (rather than the direct path method) is used for data access.</p>
<p>To specify a schema other than your own in a table-specific query, you must be granted access to that specific table.</p>
<p class="subhead1"><a id="SUTIL3176"></a>Restrictions</p>
<ul>
<li>
<p>The <code dir="ltr">QUERY</code> parameter cannot be used with the following parameters:</p>
<ul>
<li>
<p><code dir="ltr">CONTENT=METADATA_ONLY</code></p>
</li>
<li>
<p><code dir="ltr">SQLFILE</code></p>
</li>
<li>
<p><code dir="ltr">TRANSPORT_DATAFILES</code></p>
</li>
</ul>
</li>
<li>
<p>When the <code dir="ltr">QUERY</code> parameter is specified for a table, Data Pump uses external tables to load the target table. External tables uses a SQL <code dir="ltr">INSERT</code> statement with a <code dir="ltr">SELECT</code> clause. The value of the <code dir="ltr">QUERY</code> parameter is included in the <code dir="ltr">WHERE</code> clause of the <code dir="ltr">SELECT</code> portion of the <code dir="ltr">INSERT</code> statement. If the <code dir="ltr">QUERY</code> parameter includes references to another table with columns whose names match the table being loaded, and if those columns are used in the query, then you will need to use a table alias to distinguish between columns in the table being loaded and columns in the <code dir="ltr">SELECT</code> statement with the same name. The table alias used by Data Pump for the table being loaded is <code dir="ltr">KU$</code>.</p>
<p>For example, suppose you are importing a subset of the <code dir="ltr">sh.sales</code> table based on the credit limit for a customer in the <code dir="ltr">sh.customers</code> table. In the following example, <code dir="ltr">KU$</code> is used to qualify the <code dir="ltr">cust_id</code> field in the <code dir="ltr">QUERY</code> parameter for loading <code dir="ltr">sh.sales</code>. As a result, Data Pump imports only rows for customers whose credit limit is greater than $10,000.</p>
<pre dir="ltr">
QUERY='sales:"WHERE EXISTS (SELECT cust_id FROM customers c
WHERE cust_credit_limit &gt; 10000 AND ku$.cust_id = c.cust_id)"'
</pre>
<p>If <code dir="ltr">KU$</code> is not used for a table alias, then all rows are loaded:</p>
<pre dir="ltr">
QUERY='sales:"WHERE EXISTS (SELECT cust_id FROM customers c
WHERE cust_credit_limit &gt; 10000 AND cust_id = c.cust_id)"'
</pre></li>
<li>
<p>The maximum length allowed for a <code dir="ltr">QUERY</code> string is 4000 bytes including quotation marks, which means that the actual maximum length allowed is 3998 bytes.</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3177"></a>Example</p>
<p>The following is an example of using the <code dir="ltr">QUERY</code> parameter. You can create the <code dir="ltr">expfull.dmp</code> dump file used in this example by running the example provided for the Export <code dir="ltr">FULL</code> parameter. See <a href="dp_export.htm#i1006790">"FULL"</a>. Because the <code dir="ltr">QUERY</code> value uses quotation marks, Oracle recommends that you use a parameter file.</p>
<p>Suppose you have a parameter file, <code dir="ltr">query_imp.par</code>, that contains the following:</p>
<pre dir="ltr">
QUERY=departments:"WHERE department_id &lt; 120"
</pre>
<p>You can then enter the following command:</p>
<pre dir="ltr">
&gt; impdp hr DIRECTORY=dpump_dir1 DUMPFILE=expfull.dmp 
  PARFILE=query_imp.par NOLOGFILE=YES
</pre>
<p>All tables in <code dir="ltr">expfull.dmp</code> are imported, but for the <code dir="ltr">departments</code> table, only data that meets the criteria specified in the <code dir="ltr">QUERY</code> parameter is imported.</p>
</div>
<!-- class="sect2" -->
<a id="BABFBIFD"></a>
<div id="SUTIL925" class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2">REMAP_DATA<a id="sthref267"></a><a id="sthref268"></a></h3>
<p>Default: There is no default</p>
<p class="subhead1"><a id="SUTIL3178"></a>Purpose</p>
<p>The <code dir="ltr">REMAP_DATA</code> parameter allows you to remap data as it is being inserted into a new database. A common use is to regenerate primary keys to avoid conflict when importing a table into a preexisting table on the target database.</p>
<p>You can specify a remap function that takes as a source the value of the designated column from either the dump file or a remote database. The remap function then returns a remapped value that will replace the original value in the target database.</p>
<p>The same function can be applied to multiple columns being dumped. This is useful when you want to guarantee consistency in remapping both the child and parent column in a referential constraint.</p>
<p class="subhead1"><a id="SUTIL3179"></a>Syntax and Description</p>
<pre dir="ltr">
REMAP_DATA=[<span class="italic">schema</span>.]<span class="italic">tablename</span>.<span class="italic">column_name</span>:[<span class="italic">schema</span>.]<span class="italic">pkg</span>.<span class="italic">function</span>
</pre>
<p>The description of each syntax element, in the order in which they appear in the syntax, is as follows:</p>
<p><span class="italic">schema</span> -- the schema containing the table to be remapped. By default, this is the schema of the user doing the import.</p>
<p><span class="italic">tablename</span> -- the table whose column will be remapped.</p>
<p><span class="italic">column_name</span> -- the column whose data is to be remapped. The maximum number of columns that can be remapped for a single table is 10.</p>
<p><span class="italic">schema</span> -- the schema containing the PL/SQL package you created that contains the remapping function. As a default, this is the schema of the user doing the import.</p>
<p><span class="italic">pkg</span> -- the name of the PL/SQL package you created that contains the remapping function.</p>
<p><span class="italic">function</span> -- the name of the function within the PL/SQL that will be called to remap the column table in each row of the specified table.</p>
<p class="subhead1"><a id="SUTIL3180"></a>Restrictions</p>
<ul>
<li>
<p>The datatypes of the source argument and the returned value should both match the datatype of the designated column in the table.</p>
</li>
<li>
<p>Remapping functions should not perform commits or rollbacks except in autonomous transactions.</p>
</li>
<li>
<p>The maximum number of columns you can remap on a single table is 10. You can remap 9 columns on table <code dir="ltr">a</code> and 8 columns on table <code dir="ltr">b</code>, and so on, but the maximum for each table is 10.</p>
</li>
<li>
<p>The use of synonyms as values for the <code dir="ltr">REMAP_DATA</code> parameter is not supported. For example, if the <code dir="ltr">regions</code> table in the <code dir="ltr">hr</code> schema had a synonym of <code dir="ltr">regn</code>, an error would be returned if you specified <code dir="ltr">regn</code> as part of the <code dir="ltr">REMPA_DATA</code> specification.</p>
</li>
<li>
<p>Remapping LOB column data of a remote table is not supported.</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3181"></a>Example</p>
<p>The following example assumes a package named <code dir="ltr">remap</code> has been created that contains a function named <code dir="ltr">plusx</code> that changes the values for <code dir="ltr">first_name</code> in the <code dir="ltr">employees</code> table.</p>
<pre dir="ltr">
&gt; impdp hr DIRECTORY=dpump_dir1 DUMPFILE=expschema.dmp
TABLES=hr.employees REMAP_DATA=hr.employees.first_name:hr.remap.plusx
</pre></div>
<!-- class="sect2" -->
<a id="i1007385"></a>
<div id="SUTIL926" class="sect2">
<h3 class="sect2">REMAP_DATAFILE<a id="sthref269"></a></h3>
<p>Default: There is no default</p>
<p class="subhead1"><a id="SUTIL3182"></a>Purpose</p>
<p>Changes the name<a id="sthref270"></a> of the source data file<a id="sthref271"></a> to the target data file name in all SQL statements where the source data file is referenced: <code dir="ltr">CREATE TABLESPACE</code>, <code dir="ltr">CREATE LIBRARY</code>, and <code dir="ltr">CREATE DIRECTORY</code>.</p>
<p class="subhead1"><a id="SUTIL3183"></a>Syntax and Description</p>
<pre dir="ltr">
REMAP_DATAFILE=<span class="italic">source_datafile</span>:<span class="italic">target_datafile</span>
</pre>
<p>Remapping data files is useful when you move databases between platforms that have different file naming conventions. The <code dir="ltr"><span class="codeinlineitalic">source_datafile</span></code> and <code dir="ltr"><span class="codeinlineitalic">target_datafile</span></code> names should be exactly as you want them to appear in the SQL statements where they are referenced. Oracle recommends that you enclose data file names in quotation marks to eliminate ambiguity on platforms for which a colon is a valid file specification character.</p>
<p>Depending on your operating system, the use of quotation marks when you specify a value for this parameter may also require that you use escape characters. Oracle recommends that you place this parameter in a parameter file, which can reduce the number of escape characters that might otherwise be needed on the command line.</p>
<p>You must have the <code dir="ltr">DATAPUMP_IMP_FULL_DATABASE</code> role to specify this parameter.</p>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<a href="#BEHECGCA">"Use of Quotation Marks On the Data Pump Command Line"</a></div>
<p class="subhead1"><a id="SUTIL3184"></a>Example</p>
<p>Suppose you had a parameter file, <code dir="ltr">payroll.par</code>, with the following content:</p>
<pre dir="ltr">
DIRECTORY=dpump_dir1
FULL=YES
DUMPFILE=db_full.dmp
REMAP_DATAFILE="'DB1$:[HRDATA.PAYROLL]tbs6.dbf':'/db1/hrdata/payroll/tbs6.dbf'"
</pre>
<p>You can then issue the following command:</p>
<pre dir="ltr">
&gt; impdp hr PARFILE=payroll.par
</pre>
<p>This example remaps a VMS file specification (<code dir="ltr">DR1$:[HRDATA.PAYROLL]tbs6.dbf</code>) to a UNIX file specification, (<code dir="ltr">/db1/hrdata/payroll/tbs6.dbf</code>) for all SQL DDL statements during the import. The dump file, <code dir="ltr">db_full.dmp,</code> is located by the directory object, <code dir="ltr">dpump_dir1</code>.</p>
</div>
<!-- class="sect2" -->
<a id="BEHFIEIH"></a>
<div id="SUTIL927" class="sect2">
<h3 class="sect2">REMAP_SCHEMA<a id="sthref272"></a></h3>
<p>Default: There is no default</p>
<p class="subhead1"><a id="SUTIL3185"></a>Purpose</p>
<p>Loads<a id="sthref273"></a> all objects from the source schema into a target schema.</p>
<p class="subhead1"><a id="SUTIL3186"></a>Syntax and Description</p>
<pre dir="ltr">
REMAP_SCHEMA=<span class="italic">source_schema</span>:<span class="italic">target_schema</span>
</pre>
<p>Multiple <code dir="ltr">REMAP_SCHEMA</code> lines can be specified, but the source schema must be different for each one. However, different source schemas can map to the same target schema. The mapping may not be 100 percent complete, because there are certain schema references that Import is not capable of finding; see the Restrictions section below.</p>
<p>If the schema you are remapping to does not already exist, then the import operation creates it, provided that the dump file set contains the necessary <code dir="ltr">CREATE</code> <code dir="ltr">USER</code> metadata for the source schema, and provided that you are importing with enough privileges. For example, the following Export commands create dump file sets with the necessary metadata to create a schema, because the user <code dir="ltr">SYSTEM</code> has the necessary privileges:</p>
<pre dir="ltr">
&gt; expdp system SCHEMAS=hr
Password: <span class="italic">password</span>

&gt; expdp system FULL=YES
Password: <span class="italic">password</span>
</pre>
<p>If your dump file set does not contain the metadata necessary to create a schema, or if you do not have privileges, then the target schema must be created before the import operation is performed. This is because the unprivileged dump files do not contain the necessary information for the import to create the schema automatically.</p>
<p>If the import operation does create the schema, then after the import is complete, you must assign it a valid password to connect to it. The SQL statement to do this, which requires privileges, is:</p>
<pre dir="ltr">
SQL&gt; ALTER USER <span class="italic">schema_name</span> IDENTIFIED BY <span class="italic">new_password</span> 
</pre>
<p class="subhead1"><a id="SUTIL3187"></a>Restrictions</p>
<ul>
<li>
<p>Unprivileged users can perform schema remaps only if their schema is the target schema of the remap. (Privileged users can perform unrestricted schema remaps.) For example, <code dir="ltr">SCOTT</code> can remap his <code dir="ltr">BLAKE</code>'s objects to <code dir="ltr">SCOTT</code>, but <code dir="ltr">SCOTT</code> cannot remap <code dir="ltr">SCOTT</code>'s objects to <code dir="ltr">BLAKE</code>.</p>
</li>
<li>
<p>The mapping may not be 100 percent complete because there are certain schema references that Import is not capable of finding. For example, Import will not find schema references embedded within the body of definitions of triggers, types, views, procedures, and packages.</p>
</li>
<li>
<p>If any table in the schema being remapped contains user-defined object types and that table changes between the time it is exported and the time you attempt to import it, then the import of that table will fail. However, the import operation itself will continue.</p>
</li>
<li>
<p>By default, if schema objects on the source database have object identifiers (OIDs), then they are imported to the target database with those same OIDs. If an object is imported back into the same database from which it was exported, but into a different schema, then the OID of the new (imported) object would be the same as that of the existing object and the import would fail. For the import to succeed you must also specify the <code dir="ltr">TRANFORM=OID:N</code> parameter on the import. The transform <code dir="ltr">OID:N</code> causes a new OID to be created for the new object, allowing the import to succeed.</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3188"></a>Example</p>
<p>Suppose that, as user <code dir="ltr">SYSTEM</code>, you execute the following Export and Import commands to remap the <code dir="ltr">hr</code> schema into the <code dir="ltr">scott</code> schema:</p>
<pre dir="ltr">
&gt; expdp system SCHEMAS=hr DIRECTORY=dpump_dir1 DUMPFILE=hr.dmp

&gt; impdp system DIRECTORY=dpump_dir1 DUMPFILE=hr.dmp REMAP_SCHEMA=hr:scott
</pre>
<p>In this example, if user <code dir="ltr">scott</code> already exists before the import, then the Import <code dir="ltr">REMAP_SCHEMA</code> command will add objects from the <code dir="ltr">hr</code> schema into the existing <code dir="ltr">scott</code> schema. You can connect to the <code dir="ltr">scott</code> schema after the import by using the existing password (without resetting it).</p>
<p>If user <code dir="ltr">scott</code> does not exist before you execute the import operation, then Import automatically creates it with an unusable password. This is possible because the dump file, <code dir="ltr">hr</code>.<code dir="ltr">dmp</code>, was created by <code dir="ltr">SYSTEM,</code> which has the privileges necessary to create a dump file that contains the metadata needed to create a schema. However, you cannot connect to <code dir="ltr">scott</code> on completion of the import, unless you reset the password for <code dir="ltr">scott</code> on the target database after the import completes.</p>
</div>
<!-- class="sect2" -->
<a id="BABIGHCC"></a>
<div id="SUTIL928" class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2">REMAP_TABLE<a id="sthref274"></a><a id="sthref275"></a></h3>
<p>Default: There is no default</p>
<p class="subhead1"><a id="SUTIL3189"></a>Purpose</p>
<p>Allows you to rename tables during an import operation.</p>
<p class="subhead1"><a id="SUTIL3190"></a>Syntax and Description</p>
<p>You can use either of the following syntaxes (see the Usage Notes below):</p>
<pre dir="ltr">
REMAP_TABLE=[<span class="italic">schema.</span>]<span class="italic">old_tablename</span>[<span class="italic">.partition</span>]<span class="italic">:new_tablename</span>
</pre>
<p>OR</p>
<pre dir="ltr">
REMAP_TABLE=[<span class="italic">schema.</span>]<span class="italic">old_tablename</span>[<span class="italic">:partition</span>]<span class="italic">:new_tablename</span>
</pre>
<p>You can use the <code dir="ltr">REMAP_TABLE</code> parameter to rename entire tables or to rename table partitions if the table is being departitioned. (See <a href="#BABIGFDG">"PARTITION_OPTIONS"</a>.)</p>
<p>You can also use it to override the automatic naming of table partitions that were exported.</p>
<p class="subhead2"><a id="SUTIL3191"></a>Usage Notes</p>
<p>Be aware that with the first syntax, if you specify <code dir="ltr">REMAP_TABLE=A.B:C</code>, then Import assumes that <code dir="ltr">A</code> is a schema name, <code dir="ltr">B</code> is the old table name, and <code dir="ltr">C</code> is the new table name. To use the first syntax to rename a partition that is being promoted to a nonpartitioned table, you must specify a schema name.</p>
<p>To use the second syntax to rename a partition being promoted to a nonpartitioned table, you only need to qualify it with the old table name. No schema name is required.</p>
<p class="subhead1"><a id="SUTIL3192"></a>Restrictions</p>
<ul>
<li>
<p>Only objects created by the Import will be remapped. In particular, preexisting tables will not be remapped.</p>
</li>
<li>
<p>The <code dir="ltr">REMAP_TABLE</code> parameter will not work if the table being remapped has named constraints in the same schema and the constraints need to be created when the table is created.</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3193"></a>Example</p>
<p>The following is an example of using the <code dir="ltr">REMAP_TABLE</code> parameter to rename the <code dir="ltr">employees</code> table to a new name of <code dir="ltr">emps</code>:</p>
<pre dir="ltr">
&gt; impdp hr DIRECTORY=dpump_dir1 DUMPFILE=expschema.dmp
TABLES=hr.employees REMAP_TABLE=hr.employees:emps 
</pre></div>
<!-- class="sect2" -->
<a id="i1010424"></a>
<div id="SUTIL929" class="sect2">
<h3 class="sect2">REMAP_TABLESPACE<a id="sthref276"></a></h3>
<p>Default: There is no default</p>
<p class="subhead1"><a id="SUTIL3194"></a>Purpose</p>
<p>Remaps all objects<a id="sthref277"></a> selected for import with persistent data in the source tablespace to be created in the target tablespace.</p>
<p class="subhead1"><a id="SUTIL3195"></a>Syntax and Description</p>
<pre dir="ltr">
REMAP_TABLESPACE=<span class="italic">source_tablespace</span>:<span class="italic">target_tablespace</span>
</pre>
<p>Multiple <code dir="ltr">REMAP_TABLESPACE</code> parameters can be specified, but no two can have the same source tablespace. The target schema must have sufficient quota in the target tablespace.</p>
<p>Note that use of the <code dir="ltr">REMAP_TABLESPACE</code> parameter is the <span class="italic">only</span> way to remap a tablespace in Data Pump Import. This is a simpler and cleaner method than the one provided in the original Import utility. That method was subject to many restrictions (including the number of tablespace subclauses) which sometimes resulted in the failure of some DDL commands.</p>
<p>By contrast, the Data Pump Import method of using the <code dir="ltr">REMAP_TABLESPACE</code> parameter works for all objects, including the user, and it works regardless of how many tablespace subclauses are in the DDL statement.</p>
<p class="subhead1"><a id="SUTIL3196"></a>Restrictions</p>
<ul>
<li>
<p>Data Pump Import can only remap tablespaces for transportable imports in databases where the compatibility level is set to 10.1 or later.</p>
</li>
<li>
<p>Only objects created by the Import will be remapped. In particular, the tablespaces for preexisting tables will not be remapped if <code dir="ltr">TABLE_EXISTS_ACTION</code> is set to <code dir="ltr">SKIP</code>, <code dir="ltr">TRUNCATE</code>, or <code dir="ltr">APPEND</code>.</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3197"></a>Example</p>
<p>The following is an example of using the <code dir="ltr">REMAP_TABLESPACE</code> parameter.</p>
<pre dir="ltr">
&gt; impdp hr REMAP_TABLESPACE=tbs_1:tbs_6 DIRECTORY=dpump_dir1
  DUMPFILE=employees.dmp 
</pre></div>
<!-- class="sect2" -->
<div id="SUTIL930" class="sect2"><a id="sthref278"></a>
<h3 class="sect2">REUSE_DATAFILES<a id="sthref279"></a></h3>
<p>Default: <code dir="ltr">NO</code></p>
<p class="subhead1"><a id="SUTIL3198"></a>Purpose</p>
<p>Specifies whether the import job should reuse existing data files for tablespace creation.</p>
<p class="subhead1"><a id="SUTIL3199"></a>Syntax and Description</p>
<pre dir="ltr">
REUSE_DATAFILES=[YES | NO]
</pre>
<p>If the default (<code dir="ltr">n</code>) is used and the data files<a id="sthref280"></a> specified in <code dir="ltr">CREATE TABLESPACE</code> statements already exist, then an error message from the failing <code dir="ltr">CREATE TABLESPACE</code> statement is issued, but the import job continues.</p>
<p>If this parameter is specified as <code dir="ltr">y</code>, then the existing data files are reinitialized.</p>
<div class="infobox-note">
<p class="notep1">Caution:</p>
Specifying <code dir="ltr">REUSE_DATAFILES=YES</code> may result in a loss of data.</div>
<p class="subhead1"><a id="SUTIL3200"></a>Example</p>
<p>The following is an example of using the <code dir="ltr">REUSE_DATAFILES</code> parameter. You can create the <code dir="ltr">expfull.dmp</code> dump file used in this example by running the example provided for the Export <code dir="ltr">FULL</code> parameter. See <a href="dp_export.htm#i1006790">"FULL"</a>.</p>
<pre dir="ltr">
&gt; impdp hr DIRECTORY=dpump_dir1 DUMPFILE=expfull.dmp LOGFILE=reuse.log
REUSE_DATAFILES=YES
</pre>
<p>This example reinitializes data files referenced by <code dir="ltr">CREATE</code> <code dir="ltr">TABLESPACE</code> statements in the <code dir="ltr">expfull.dmp</code> file.</p>
</div>
<!-- class="sect2" -->
<a id="i1007024"></a>
<div id="SUTIL931" class="sect2">
<h3 class="sect2">SCHEMAS<a id="sthref281"></a></h3>
<p>Default: There is no default</p>
<p class="subhead1"><a id="SUTIL3201"></a>Purpose</p>
<p>Specifies that a schema-mode import is to be performed.</p>
<p class="subhead1"><a id="SUTIL3202"></a>Syntax and Description</p>
<pre dir="ltr">
SCHEMAS=<span class="italic">schema_name</span> [,...]
</pre>
<p>If you have the <code dir="ltr">DATAPUMP_IMP_FULL_DATABASE</code> role, then you can use this parameter to perform a schema-mode import by specifying a list of schemas<a id="sthref282"></a> to import. First, the user definitions are imported (if they do not already exist), including system and role grants, password history, and so on. Then all objects contained within the schemas are imported. Unprivileged users can specify only their own schemas or schemas remapped to their own schemas. In that case, no information about the schema definition is imported, only the objects contained within it.</p>
<p>The use of filtering can restrict what is imported using this import mode. See <a href="#i1009204">"Filtering During Import Operations"</a>.</p>
<p>Schema mode is the default mode when you are performing a network-based import.</p>
<p class="subhead1"><a id="SUTIL3203"></a>Example</p>
<p>The following is an example of using the <code dir="ltr">SCHEMAS</code> parameter. You can create the <code dir="ltr">expdat.dmp</code> file used in this example by running the example provided for the Export <code dir="ltr">SCHEMAS</code> parameter. See <a href="dp_export.htm#i1006804">"SCHEMAS"</a>.</p>
<pre dir="ltr">
&gt; impdp hr SCHEMAS=hr DIRECTORY=dpump_dir1 LOGFILE=schemas.log
DUMPFILE=expdat.dmp
</pre>
<p>The <code dir="ltr">hr</code> schema is imported from the <code dir="ltr">expdat.dmp</code> file. The log file, <code dir="ltr">schemas.log</code>, is written to <code dir="ltr">dpump_dir1</code>.</p>
</div>
<!-- class="sect2" -->
<a id="CIHHFIDE"></a>
<div id="SUTIL3204" class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2">SERVICE_NAME<a id="sthref283"></a><a id="sthref284"></a></h3>
<p>Default: There is no default</p>
<p class="subhead1"><a id="SUTIL3205"></a>Purpose</p>
<p>Used to specify a service name to be used in conjunction with the <code dir="ltr">CLUSTER</code> parameter.</p>
<p class="subhead1"><a id="SUTIL3206"></a>Syntax and Description</p>
<pre dir="ltr">
SERVICE_NAME=<span class="italic">name</span>
</pre>
<p>The <code dir="ltr">SERVICE_NAME</code> parameter can be used with the <code dir="ltr">CLUSTER=YES</code> parameter to specify an existing service associated with a resource group that defines a set of Oracle Real Application Clusters (Oracle RAC) instances belonging to that resource group, typically a subset of all the Oracle RAC instances.</p>
<p>The service name is only used to determine the resource group and instances defined for that resource group. The instance where the job is started is always used, regardless of whether it is part of the resource group.</p>
<p>The <code dir="ltr">SERVICE_NAME</code> parameter is ignored if <code dir="ltr">CLUSTER=NO</code> is also specified.</p>
<p>Suppose you have an Oracle RAC configuration containing instances A, B, C, and D. Also suppose that a service named <code dir="ltr">my_service</code> exists with a resource group consisting of instances A, B, and C only. In such a scenario, the following would be true:</p>
<ul>
<li>
<p>If you start a Data Pump job on instance A and specify <code dir="ltr">CLUSTER=YES</code> (or accept the default, which is <code dir="ltr">YES</code>) and you do not specify the <code dir="ltr">SERVICE_NAME</code> parameter, then Data Pump creates workers on all instances: A, B, C, and D, depending on the degree of parallelism specified.</p>
</li>
<li>
<p>If you start a Data Pump job on instance A and specify <code dir="ltr">CLUSTER=YES</code> and <code dir="ltr">SERVICE_NAME=my_service</code>, then workers can be started on instances A, B, and C only.</p>
</li>
<li>
<p>If you start a Data Pump job on instance D and specify <code dir="ltr">CLUSTER=YES</code> and <code dir="ltr">SERVICE_NAME=my_service</code>, then workers can be started on instances A, B, C, and D. Even though instance D is not in <code dir="ltr">my_service</code> it is included because it is the instance on which the job was started.</p>
</li>
<li>
<p>If you start a Data Pump job on instance A and specify <code dir="ltr">CLUSTER=NO</code>, then any <code dir="ltr">SERVICE_NAME</code> parameter you specify is ignored and all processes will start on instance A.</p>
</li>
</ul>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<a href="#CIHHJIBE">"CLUSTER"</a></div>
<p class="subhead1"><a id="SUTIL3207"></a>Example</p>
<pre dir="ltr">
&gt; impdp system DIRECTORY=dpump_dir1 SCHEMAS=hr
  SERVICE_NAME=sales NETWORK_LINK=dbs1
</pre>
<p>This example starts a schema-mode network import of the hr schema. Even though <code dir="ltr">CLUSTER=YES</code> is not specified on the command line, it is the default behavior, so the job will use all instances in the resource group associated with the service name <code dir="ltr">sales</code>. The <code dir="ltr">NETWORK_LINK</code> value of <code dir="ltr">dbs1</code> would be replaced with the name of the source database from which you were importing data. (Note that there is no dump file generated because this is a network import.)</p>
<p>The <code dir="ltr">NETWORK_LINK</code> parameter is simply being used as part of the example. It is not required when using the <code dir="ltr">SERVICE_NAME</code> parameter.</p>
</div>
<!-- class="sect2" -->
<div id="SUTIL932" class="sect2"><a id="sthref285"></a>
<h3 class="sect2">SKIP_UNUSABLE_INDEXES<a id="sthref286"></a></h3>
<p>Default: the value of the Oracle Database configuration parameter, <code dir="ltr">SKIP_UNUSABLE_INDEXES</code>.</p>
<p class="subhead1"><a id="SUTIL3208"></a>Purpose</p>
<p>Specifies whether Import skips loading tables that have indexes<a id="sthref287"></a> that were set to the Index Unusable state (by either the system or the user).</p>
<p class="subhead1"><a id="SUTIL3209"></a>Syntax and Description</p>
<pre dir="ltr">
SKIP_UNUSABLE_INDEXES=[YES | NO]
</pre>
<p>If <code dir="ltr">SKIP_UNUSABLE_INDEXES</code> is set to <code dir="ltr">YES</code>, and a table or partition with an index in the Unusable state is encountered, then the load of that table or partition proceeds anyway, as if the unusable index did not exist.</p>
<p>If <code dir="ltr">SKIP_UNUSABLE_INDEXES</code> is set to <code dir="ltr">NO</code>, and a table or partition with an index in the Unusable state is encountered, then that table or partition is not loaded. Other tables, with indexes not previously set Unusable, continue to be updated as rows are inserted.</p>
<p>If the <code dir="ltr">SKIP_UNUSABLE_INDEXES</code> parameter is not specified, then the setting of the Oracle Database configuration parameter, <code dir="ltr">SKIP_UNUSABLE_INDEXES</code> (whose default value is <code dir="ltr">y</code>), will be used to determine how to handle unusable indexes.</p>
<p>If indexes used to enforce constraints are marked unusable, then the data is not imported into that table.</p>
<div class="infobox-note">
<p class="notep1">Note:</p>
This parameter is useful only when importing data into an existing table. It has no practical effect when a table is created as part of an import because in that case, the table and indexes are newly created and will not be marked unusable.</div>
<p class="subhead1"><a id="SUTIL3210"></a>Example</p>
<p>The following is an example of using the <code dir="ltr">SKIP_UNUSABLE_INDEXES</code> parameter. You can create the <code dir="ltr">expfull.dmp</code> dump file used in this example by running the example provided for the Export <code dir="ltr">FULL</code> parameter. See <a href="dp_export.htm#i1006790">"FULL"</a>.</p>
<pre dir="ltr">
&gt; impdp hr DIRECTORY=dpump_dir1 DUMPFILE=expfull.dmp LOGFILE=skip.log
SKIP_UNUSABLE_INDEXES=YES
</pre></div>
<!-- class="sect2" -->
<div id="SUTIL3211" class="sect2"><!-- infolevel="all" infotype="General" --><a id="sthref288"></a>
<h3 class="sect2">SOURCE_EDITION<a id="sthref289"></a><a id="sthref290"></a></h3>
<p>Default: the default database edition on the remote node from which objects will be fetched</p>
<p class="subhead1"><a id="SUTIL3212"></a>Purpose</p>
<p>Specifies the database edition on the remote node from which objects will be fetched.</p>
<p class="subhead1"><a id="SUTIL3213"></a>Syntax and Description</p>
<pre dir="ltr">
SOURCE_EDITION=<span class="italic">edition_name</span>
</pre>
<p>If <code dir="ltr">SOURCE_EDITION=</code><code dir="ltr"><span class="codeinlineitalic">edition_name</span></code> is specified, then the objects from that edition are imported. Data Pump selects all inherited objects that have not changed and all actual objects that have changed.</p>
<p>If this parameter is not specified, then the default edition is used. If the specified edition does not exist or is not usable, then an error message is returned.</p>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<ul>
<li>
<p><a class="olink SQLRF" href="../e41084/toc.htm"><span class="italic">Oracle Database SQL Language Reference</span></a> for information about how editions are created</p>
</li>
<li>
<p><a class="olink ADFNS" href="../../appdev.112/e41502/toc.htm"><span class="italic">Oracle Database Advanced Application Developer's Guide</span></a> for more information about the editions feature, including inherited and actual objects</p>
</li>
</ul>
</div>
<p class="subhead1"><a id="SUTIL3214"></a>Restrictions</p>
<ul>
<li>
<p>The <code dir="ltr">SOURCE_EDITION</code> parameter is valid on an import operation only when the <code dir="ltr">NETWORK_LINK</code> parameter is also specified. See <a href="#i1007380">"NETWORK_LINK"</a>.</p>
</li>
<li>
<p>This parameter is only useful if there are two or more versions of the same versionable objects in the database.</p>
</li>
<li>
<p>The job version must be set to 11.2 or higher. See <a href="#i1007382">"VERSION"</a>.</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3215"></a>Example</p>
<p>The following is an example of using the import <code dir="ltr">SOURCE_EDITION</code> parameter:</p>
<pre dir="ltr">
&gt; impdp hr DIRECTORY=dpump_dir1 SOURCE_EDITION=exp_edition
NETWORK_LINK=<span class="italic">source_database_link</span> EXCLUDE=USER
</pre>
<p>This example assumes the existence of an edition named <code dir="ltr">exp_edition</code> on the system from which objects are being imported. Because no import mode is specified, the default of schema mode will be used. The <code dir="ltr"><span class="codeinlineitalic">source_database_link</span></code> would be replaced with the name of the source database from which you were importing data. The <code dir="ltr">EXCLUDE=USER</code> parameter excludes only the definitions of users, not the objects contained within users' schemas. (Note that there is no dump file generated because this is a network import.)</p>
</div>
<!-- class="sect2" -->
<a id="BEHEIDFA"></a>
<div id="SUTIL933" class="sect2">
<h3 class="sect2">SQLFILE<a id="sthref291"></a></h3>
<p>Default: There is no default</p>
<p class="subhead1"><a id="SUTIL3216"></a>Purpose</p>
<p>Specifies a file<a id="sthref292"></a> into which all of the SQL DDL that Import would have executed, based on other parameters, is written.</p>
<p class="subhead1"><a id="SUTIL3217"></a>Syntax and Description</p>
<pre dir="ltr">
SQLFILE=[<span class="italic">directory_object</span>:]<span class="italic">file_name</span>
</pre>
<p>The <code dir="ltr"><span class="codeinlineitalic">file_name</span></code> specifies where the import job will write the DDL that would be executed during the job. The SQL is not actually executed, and the target system remains unchanged. The file is written to the directory object specified in the <code dir="ltr">DIRECTORY</code> parameter, unless another <code dir="ltr"><span class="codeinlineitalic">directory_object</span></code> is explicitly specified here. Any existing file that has a name matching the one specified with this parameter is overwritten.</p>
<p>Note that passwords are not included in the SQL file. For example, if a <code dir="ltr">CONNECT</code> statement is part of the DDL that was executed, then it will be replaced by a comment with only the schema name shown. In the following example, the dashes (--) indicate that a comment follows, and the <code dir="ltr">hr</code> schema name is shown, but not the password.</p>
<pre dir="ltr">
-- CONNECT hr
</pre>
<p>Therefore, before you can execute the SQL file, you must edit it by removing the dashes indicating a comment and adding the password for the <code dir="ltr">hr</code> schema.</p>
<p>For Streams and other Oracle database options, anonymous PL/SQL blocks may appear within the <code dir="ltr">SQLFILE</code> output. They should not be executed directly.</p>
<p class="subhead1"><a id="SUTIL3218"></a>Restrictions</p>
<ul>
<li>
<p>If <code dir="ltr">SQLFILE</code> is specified, then the <code dir="ltr">CONTENT</code> parameter is ignored if it is set to either <code dir="ltr">ALL</code> or <code dir="ltr">DATA_ONLY</code>.</p>
</li>
<li>
<p>To perform a Data Pump Import to a SQL file using Oracle Automatic Storage Management (Oracle ASM), the <code dir="ltr">SQLFILE</code> parameter that you specify must include a directory object that does not use the Oracle ASM + notation. That is, the SQL file must be written to a disk file, not into the Oracle ASM storage.</p>
</li>
<li>
<p>The <code dir="ltr">SQLFILE</code> parameter cannot be used in conjunction with the <code dir="ltr">QUERY</code> parameter.</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3219"></a>Example</p>
<p>The following is an example of using the <code dir="ltr">SQLFILE</code> parameter. You can create the <code dir="ltr">expfull.dmp</code> dump file used in this example by running the example provided for the Export <code dir="ltr">FULL</code> parameter. See <a href="dp_export.htm#i1006790">"FULL"</a>.</p>
<pre dir="ltr">
&gt; impdp hr DIRECTORY=dpump_dir1 DUMPFILE=expfull.dmp
SQLFILE=dpump_dir2:expfull.sql
</pre>
<p>A SQL file named <code dir="ltr">expfull.sql</code> is written to <code dir="ltr">dpump_dir2</code>.</p>
</div>
<!-- class="sect2" -->
<a id="i1008677"></a>
<div id="SUTIL934" class="sect2">
<h3 class="sect2">STATUS<a id="sthref293"></a><a id="sthref294"></a></h3>
<p>Default: <code dir="ltr">0</code></p>
<p class="subhead1"><a id="SUTIL3220"></a>Purpose</p>
<p>Specifies the frequency at which the job status will be displayed.</p>
<p class="subhead1"><a id="SUTIL3221"></a>Syntax and Description</p>
<pre dir="ltr">
STATUS[=<span class="italic">integer</span>]
</pre>
<p>If you supply a value for <code dir="ltr"><span class="codeinlineitalic">integer</span></code>, it specifies how frequently, in seconds, job status should be displayed in logging mode. If no value is entered or if the default value of 0 is used, then no additional information is displayed beyond information about the completion of each object type, table, or partition.</p>
<p>This status information is written only to your standard output device, not to the log file (if one is in effect).</p>
<p class="subhead1"><a id="SUTIL3222"></a>Example</p>
<p>The following is an example of using the <code dir="ltr">STATUS</code> parameter. You can create the <code dir="ltr">expfull.dmp</code> dump file used in this example by running the example provided for the Export <code dir="ltr">FULL</code> parameter. See <a href="dp_export.htm#i1006790">"FULL"</a>.</p>
<pre dir="ltr">
&gt; impdp hr NOLOGFILE=YES STATUS=120 DIRECTORY=dpump_dir1 DUMPFILE=expfull.dmp
</pre>
<p>In this example, the status is shown every two minutes (120 seconds).</p>
</div>
<!-- class="sect2" -->
<div id="SUTIL935" class="sect2"><a id="sthref295"></a>
<h3 class="sect2">STREAMS_CONFIGURATION<a id="sthref296"></a><a id="sthref297"></a></h3>
<p>Default: <code dir="ltr">YES</code></p>
<p class="subhead1"><a id="SUTIL3223"></a>Purpose</p>
<p>Specifies whether to import any Streams metadata that may be present in the export dump file.</p>
<p class="subhead1"><a id="SUTIL3224"></a>Syntax and Description</p>
<pre dir="ltr">
STREAMS_CONFIGURATION=[YES | NO]
</pre>
<p class="subhead1"><a id="SUTIL3225"></a>Example</p>
<p>The following is an example of using the <code dir="ltr">STREAMS_CONFIGURATION</code> parameter. You can create the <code dir="ltr">expfull.dmp</code> dump file used in this example by running the example provided for the Export <code dir="ltr">FULL</code> parameter. See <a href="dp_export.htm#i1006790">"FULL"</a>.</p>
<pre dir="ltr">
&gt; impdp hr DIRECTORY=dpump_dir1 DUMPFILE=expfull.dmp STREAMS_CONFIGURATION=NO
</pre>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<a class="olink STREP113" href="../../server.112/e10705/instant.htm#STREP113"><span class="italic">Oracle Streams Replication Administrator's Guide</span></a></div>
</div>
<!-- class="sect2" -->
<div id="SUTIL936" class="sect2"><a id="sthref298"></a>
<h3 class="sect2">TABLE_EXISTS_ACTION<a id="sthref299"></a></h3>
<p>Default: <code dir="ltr">SKIP</code> (Note that if <code dir="ltr">CONTENT=</code><code dir="ltr">DATA_ONLY</code> is specified, then the default is <code dir="ltr">APPEND</code>, not <code dir="ltr">SKIP</code>.)</p>
<p class="subhead1"><a id="SUTIL3226"></a>Purpose</p>
<p>Tells Import<a id="sthref300"></a> what to do if the table it is trying to create already exists.</p>
<p class="subhead1"><a id="SUTIL3227"></a>Syntax and Description</p>
<pre dir="ltr">
TABLE_EXISTS_ACTION=[SKIP | APPEND | TRUNCATE | REPLACE]
</pre>
<p>The possible values have the following effects:</p>
<ul>
<li>
<p><code dir="ltr">SKIP</code> leaves the table as is and moves on to the next object. This is not a valid option if the <code dir="ltr">CONTENT</code> parameter is set to <code dir="ltr">DATA_ONLY</code>.</p>
</li>
<li>
<p><code dir="ltr">APPEND</code> loads rows from the source and leaves existing rows unchanged.</p>
</li>
<li>
<p><code dir="ltr">TRUNCATE</code> deletes existing rows and then loads rows from the source.</p>
</li>
<li>
<p><code dir="ltr">REPLACE</code> drops the existing table and then creates and loads it from the source. This is not a valid option if the <code dir="ltr">CONTENT</code> parameter is set to <code dir="ltr">DATA_ONLY</code>.</p>
</li>
</ul>
<p>The following considerations apply when you are using these options:</p>
<ul>
<li>
<p>When you use <code dir="ltr">TRUNCATE</code> or <code dir="ltr">REPLACE</code>, ensure that rows in the affected tables are not targets of any referential constraints.</p>
</li>
<li>
<p>When you use <code dir="ltr">SKIP</code>, <code dir="ltr">APPEND</code>, or <code dir="ltr">TRUNCATE</code>, existing table-dependent objects in the source, such as indexes, grants, triggers, and constraints, are not modified. For <code dir="ltr">REPLACE</code>, the dependent objects are dropped and re-created from the source, if they were not explicitly or implicitly excluded (using <code dir="ltr">EXCLUDE</code>) and they exist in the source dump file or system.</p>
</li>
<li>
<p>When you use <code dir="ltr">APPEND</code> or <code dir="ltr">TRUNCATE</code>, checks are made to ensure that rows from the source are compatible with the existing table before performing any action.</p>
<p>If the existing table has active constraints and triggers, then it is loaded using the external tables access method. If any row violates an active constraint, then the load fails and no data is loaded. You can override this behavior by specifying <code dir="ltr">DATA_OPTIONS=SKIP_CONSTRAINT_ERRORS</code> on the Import command line.</p>
<p>If you have data that must be loaded, but may cause constraint violations, then consider disabling the constraints, loading the data, and then deleting the problem rows before reenabling the constraints.</p>
</li>
<li>
<p>When you use <code dir="ltr">APPEND</code>, the data is always loaded into new space; existing space, even if available, is not reused. For this reason, you may want to compress your data after the load.</p>
</li>
<li>
<p>Also see the description of the Import <a href="#BABIGFDG">PARTITION_OPTIONS</a> parameter for information about how parallel processing of partitioned tables is affected depending on whether the target table already exists or not.</p>
</li>
</ul>
<div class="infobox-note">
<p class="notep1">Note:</p>
When Data Pump detects that the source table and target table do not match (the two tables do not have the same number of columns or the target table has a column name that is not present in the source table), it compares column names between the two tables. If the tables have at least one column in common, then the data for the common columns is imported into the table (assuming the datatypes are compatible). The following restrictions apply:
<ul>
<li>
<p>This behavior is not supported for network imports.</p>
</li>
<li>
<p>The following types of columns cannot be dropped: object columns, object attributes, nested table columns, and ref columns based on a primary key.</p>
</li>
</ul>
</div>
<p class="subhead2"><a id="SUTIL3228"></a>Restrictions</p>
<ul>
<li>
<p><code dir="ltr">TRUNCATE</code> cannot be used on clustered tables.</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3229"></a>Example</p>
<p>The following is an example of using the <code dir="ltr">TABLE_EXISTS_ACTION</code> parameter. You can create the <code dir="ltr">expfull.dmp</code> dump file used in this example by running the example provided for the Export <code dir="ltr">FULL</code> parameter. See <a href="dp_export.htm#i1006790">"FULL"</a>.</p>
<pre dir="ltr">
&gt; impdp hr TABLES=employees DIRECTORY=dpump_dir1 DUMPFILE=expfull.dmp
TABLE_EXISTS_ACTION=REPLACE
</pre></div>
<!-- class="sect2" -->
<a id="i1007036"></a>
<div id="SUTIL937" class="sect2">
<h3 class="sect2">TABLES<a id="sthref301"></a></h3>
<p>Default: There is no default</p>
<p class="subhead1"><a id="SUTIL3230"></a>Purpose</p>
<p>Specifies that you want to perform a table-mode import.</p>
<p class="subhead1"><a id="SUTIL3231"></a>Syntax and Description</p>
<pre dir="ltr">
TABLES=[<span class="italic">schema_name</span>.]<span class="italic">table_name</span>[:<span class="italic">partition_name</span>]
</pre>
<p>In a table-mode import, you can filter the data that is imported from the source<a id="sthref302"></a> by specifying a comma-delimited list of tables and partitions or subpartitions.</p>
<p>If you do not supply a <code dir="ltr"><span class="codeinlineitalic">schema_name</span></code>, then it defaults to that of the current user. To specify a schema other than your own, you must either have the <code dir="ltr">DATAPUMP_IMP_FULL_DATABASE</code> role or remap the schema to the current user.</p>
<p>The use of filtering can restrict what is imported using this import mode. See <a href="#i1009204">"Filtering During Import Operations"</a>.</p>
<p>If a <code dir="ltr"><span class="codeinlineitalic">partition_name</span></code> is specified, then it must be the name of a partition or subpartition in the associated table.</p>
<p>Use of the wildcard character, %, to specify table names and partition names is supported.</p>
<p>The following restrictions apply to table names:</p>
<ul>
<li>
<p>By default, table names in a database are stored as uppercase. If you have a table name in mixed-case or lowercase, and you want to preserve case-sensitivity for the table name, then you must enclose the name in quotation marks. The name must exactly match the table name stored in the database.</p>
<p>Some operating systems require that quotation marks on the command line be preceded by an escape character. The following are examples of how case-sensitivity can be preserved in the different Import modes.</p>
<ul>
<li>
<p>In command-line mode:</p>
<pre dir="ltr">
TABLES='\"Emp\"'
</pre></li>
<li>
<p>In parameter file mode:</p>
<pre dir="ltr">
TABLES='"Emp"'
</pre></li>
</ul>
</li>
<li>
<p><a id="sthref303"></a>Table names specified on the command line cannot include a pound sign (#), unless the table name is enclosed in quotation marks. Similarly, in the parameter file, if a table name includes a pound sign (#), then the Import utility interprets the rest of the line as a comment, unless the table name is enclosed in quotation marks.</p>
<p><a id="sthref304"></a><a id="sthref305"></a>F<a id="sthref306"></a>or example, if the parameter file contains the following line, then Import interprets everything on the line after <code dir="ltr">emp#</code> as a comment and does not import the tables <code dir="ltr">dept</code> and <code dir="ltr">mydata:</code></p>
<pre dir="ltr">
TABLES=(emp#, dept, mydata)
</pre>
<p>However, if the parameter file contains the following line, then the Import utility imports all three tables because <code dir="ltr">emp#</code> is enclosed in quotation marks:</p>
<pre dir="ltr">
TABLES=('"emp#"', dept, mydata)
</pre>
<div class="infobox-note">
<p class="notep1">Note:</p>
Some operating systems require single quotation marks rather than double quotation marks, or the reverse; see your Oracle operating system-specific documentation. Different operating systems also have other restrictions on table naming.
<p>For example, the UNIX C shell attaches a special meaning to a dollar sign ($) or pound sign (#) (or certain other special characters). You must use escape characters to get such characters in the name past the shell and into Import.</p>
</div>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3232"></a>Restrictions</p>
<ul>
<li>
<p>The use of synonyms as values for the <code dir="ltr">TABLES</code> parameter is not supported. For example, if the <code dir="ltr">regions</code> table in the <code dir="ltr">hr</code> schema had a synonym of <code dir="ltr">regn</code>, then it would not be valid to use <code dir="ltr">TABLES=regn</code>. An error would be returned.</p>
</li>
<li>
<p>You can only specify partitions from one table if <code dir="ltr">PARTITION_OPTIONS=DEPARTITION</code> is also specified on the import.</p>
</li>
<li>
<p>If you specify <code dir="ltr">TRANSPORTABLE=ALWAYS</code>, then all partitions specified on the <code dir="ltr">TABLES</code> parameter must be in the same table.</p>
</li>
<li>
<p>The length of the table name list specified for the <code dir="ltr">TABLES</code> parameter is limited to a maximum of 4 MB, unless you are using the <code dir="ltr">NETWORK_LINK</code> parameter to an Oracle Database release 10.2.0.3 or earlier or to a read-only database. In such cases, the limit is 4 KB.</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3233"></a>Example</p>
<p>The following example shows a simple use of the <code dir="ltr">TABLES</code> parameter to import only the <code dir="ltr">employees</code> and <code dir="ltr">jobs</code> tables from the <code dir="ltr">expfull.dmp</code> file. You can create the <code dir="ltr">expfull.dmp</code> dump file used in this example by running the example provided for the Export <code dir="ltr">FULL</code> parameter. See <a href="dp_export.htm#i1006790">"FULL"</a>.</p>
<pre dir="ltr">
&gt; impdp hr DIRECTORY=dpump_dir1 DUMPFILE=expfull.dmp TABLES=employees,jobs
</pre>
<p>The following example shows the use of the <code dir="ltr">TABLES</code> parameter to import partitions:</p>
<pre dir="ltr">
&gt; impdp hr DIRECTORY=dpump_dir1 DUMPFILE=expdat.dmp 
TABLES=sh.sales:sales_Q1_2008,sh.sales:sales_Q2_2008
</pre>
<p>This example imports the partitions <code dir="ltr">sales_Q1_2008</code> and <code dir="ltr">sales_Q2_2008</code> for the table <code dir="ltr">sales</code> in the schema <code dir="ltr">sh</code>.</p>
</div>
<!-- class="sect2" -->
<a id="i1007048"></a>
<div id="SUTIL938" class="sect2">
<h3 class="sect2">TABLESPACES<a id="sthref307"></a></h3>
<p>Default: There is no default</p>
<p class="subhead1"><a id="SUTIL3234"></a>Purpose</p>
<p>Specifies that you want to perform a tablespace-mode import.</p>
<p class="subhead1"><a id="SUTIL3235"></a>Syntax and Description</p>
<pre dir="ltr">
TABLESPACES=<span class="italic">tablespace_name</span> [, ...]
</pre>
<p>Use <code dir="ltr">TABLESPACES</code> to specify a list of tablespace<a id="sthref308"></a> names whose tables and dependent objects are to be imported from the source (full, schema, tablespace, or table-mode export dump file set or another database).</p>
<p>During the following import situations, Data Pump automatically creates the tablespaces into which the data will be imported:</p>
<ul>
<li>
<p>The import is being done in <code dir="ltr">FULL</code> or <code dir="ltr">TRANSPORT_TABLESPACES</code> mode</p>
</li>
<li>
<p>The import is being done in table mode with <code dir="ltr">TRANSPORTABLE=ALWAYS</code></p>
</li>
</ul>
<p>In all other cases, the tablespaces for the selected objects must already exist on the import database. You could also use the Import <code dir="ltr">REMAP_TABLESPACE</code> parameter to map the tablespace name to an existing tablespace on the import database.</p>
<p>The use of filtering can restrict what is imported using this import mode. See <a href="#i1009204">"Filtering During Import Operations"</a>.</p>
<p class="subhead1"><a id="SUTIL3236"></a>Restrictions</p>
<ul>
<li>
<p>The length of the list of tablespace names specified for the <code dir="ltr">TABLESPACES</code> parameter is limited to a maximum of 4 MB, unless you are using the <code dir="ltr">NETWORK_LINK</code> parameter to a 10.2.0.3 or earlier database or to a read-only database. In such cases, the limit is 4 KB.</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3237"></a>Example</p>
<p>The following is an example of using the <code dir="ltr">TABLESPACES</code> parameter. It assumes that the tablespaces already exist. You can create the <code dir="ltr">expfull.dmp</code> dump file used in this example by running the example provided for the Export <code dir="ltr">FULL</code> parameter. See <a href="dp_export.htm#i1006790">"FULL"</a>.</p>
<pre dir="ltr">
&gt; impdp hr DIRECTORY=dpump_dir1 DUMPFILE=expfull.dmp TABLESPACES=tbs_1,tbs_2,tbs_3,tbs_4
</pre>
<p>This example imports all tables that have data in tablespaces <code dir="ltr">tbs_1</code>, <code dir="ltr">tbs_2</code>, <code dir="ltr">tbs_3</code>, and <code dir="ltr">tbs_4</code>.</p>
</div>
<!-- class="sect2" -->
<a id="CIHGDICJ"></a>
<div id="SUTIL3238" class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2">TARGET_EDITION<a id="sthref309"></a><a id="sthref310"></a></h3>
<p>Default: the default database edition on the system</p>
<p class="subhead1"><a id="SUTIL3239"></a>Purpose</p>
<p>Specifies the database edition into which objects should be imported.</p>
<p class="subhead1"><a id="SUTIL3240"></a>Syntax and Description</p>
<pre dir="ltr">
TARGET_EDITION=<span class="italic">name</span>
</pre>
<p>If <code dir="ltr">TARGET_EDITION=</code><code dir="ltr"><span class="codeinlineitalic">name</span></code> is specified, then Data Pump Import creates all of the objects found in the dump file. Objects that are <span class="italic">not</span> editionable are created in all editions. For example, tables are not editionable, so if there is a table in the dump file, then it will be created, and all editions will see it. Objects in the dump file that <span class="italic">are</span> editionable, such as procedures, are created only in the specified target edition.</p>
<p>If this parameter is not specified, then the default edition on the target database is used, even if an edition was specified in the export job. If the specified edition does not exist or is not usable, then an error message is returned.</p>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<ul>
<li>
<p><a class="olink SQLRF" href="../e41084/toc.htm"><span class="italic">Oracle Database SQL Language Reference</span></a> for information about how editions are created</p>
</li>
<li>
<p><a class="olink ADFNS" href="../../appdev.112/e41502/toc.htm"><span class="italic">Oracle Database Advanced Application Developer's Guide</span></a> for more information about the editions feature</p>
</li>
</ul>
</div>
<p class="subhead1"><a id="SUTIL3241"></a>Restrictions</p>
<ul>
<li>
<p>This parameter is only useful if there are two or more versions of the same versionable objects in the database.</p>
</li>
<li>
<p>The job version must be 11.2 or higher. See <a href="#i1007382">"VERSION"</a>.</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3242"></a>Example</p>
<p>The following is an example of using the <code dir="ltr">TARGET_EDITION</code> parameter:</p>
<pre dir="ltr">
&gt; impdp hr DIRECTORY=dpump_dir1 DUMPFILE=exp_dat.dmp TARGET_EDITION=exp_edition
</pre>
<p>This example assumes the existence of an edition named <code dir="ltr">exp_edition</code> on the system to which objects are being imported. Because no import mode is specified, the default of schema mode will be used.</p>
</div>
<!-- class="sect2" -->
<a id="BEHEDGJJ"></a>
<div id="SUTIL939" class="sect2">
<h3 class="sect2">TRANSFORM<a id="sthref311"></a><a id="sthref312"></a></h3>
<p>Default: There is no default</p>
<p class="subhead1"><a id="SUTIL3243"></a>Purpose</p>
<p>Enables you to alter object creation DDL for objects being imported.</p>
<p class="subhead1"><a id="SUTIL3244"></a>Syntax and Description</p>
<pre dir="ltr">
TRANSFORM = <span class="italic">transform_name</span>:<span class="italic">value</span>[:<span class="italic">object_type</span>]
</pre>
<p>The <code dir="ltr"><span class="codeinlineitalic">transform_name</span></code> specifies the name of the transform. The possible options are as follows:</p>
<ul>
<li>
<p><code dir="ltr">SEGMENT_ATTRIBUTES</code> - If the value is specified as <code dir="ltr">y</code>, then segment attributes (physical attributes, storage attributes, tablespaces, and logging) are included, with appropriate DDL. The default is <code dir="ltr">y</code>.</p>
</li>
<li>
<p><code dir="ltr">STORAGE</code> - If the value is specified as <code dir="ltr">y</code>, then the storage clauses are included, with appropriate DDL. The default is <code dir="ltr">y</code>. This parameter is ignored if <code dir="ltr">SEGMENT_ATTRIBUTES</code>=<code dir="ltr">n</code>.</p>
</li>
<li>
<p><code dir="ltr">OID</code> - If the value is specified as <code dir="ltr">n</code>, then the assignment of the exported OID during the creation of object tables and types is inhibited. Instead, a new OID is assigned. This can be useful for cloning schemas, but does not affect referenced objects. The default value is <code dir="ltr">y</code>.</p>
</li>
<li>
<p><code dir="ltr">PCTSPACE</code> - The <code dir="ltr">value</code> supplied for this transform must be a number greater than zero. It represents the percentage multiplier used to alter extent allocations and the size of data files.</p>
<p>Note that you can use the <code dir="ltr">PCTSPACE</code> transform with the Data Pump Export <code dir="ltr">SAMPLE</code> parameter so that the size of storage allocations matches the sampled data subset. (See <a href="dp_export.htm#BABBFAJD">"SAMPLE"</a>.)</p>
</li>
<li>
<p><code dir="ltr">SEGMENT_CREATION</code> - If set to <code dir="ltr">y</code> (the default), then this transform causes the SQL <code dir="ltr">SEGMENT CREATION</code> clause to be added to the <code dir="ltr">CREATE TABLE</code> statement. That is, the <code dir="ltr">CREATE TABLE</code> statement will explicitly say either <code dir="ltr">SEGMENT CREATION DEFERRED</code> or <code dir="ltr">SEGMENT CREATION IMMEDIATE</code>. If the value is <code dir="ltr">n</code>, then the <code dir="ltr">SEGMENT CREATION</code> clause is omitted from the <code dir="ltr">CREATE TABLE</code> statement. Set this parameter to <code dir="ltr">n</code> to use the default segment creation attributes for the table(s) being loaded. (This functionality is available starting with Oracle Database 11<span class="italic">g</span> release 2 (11.2.0.2).)</p>
</li>
</ul>
<p>The type of <code dir="ltr"><span class="codeinlineitalic">value</span></code> specified depends on the transform used. Boolean values (y/n) are required for the <code dir="ltr">SEGMENT_ATTRIBUTES</code>, <code dir="ltr">STORAGE</code>, and <code dir="ltr">OID</code> transforms. Integer values are required for the <code dir="ltr">PCTSPACE</code> transform.</p>
<p>The <code dir="ltr"><span class="codeinlineitalic">object_type</span></code> is optional. If supplied, it designates the object type to which the transform will be applied. If no object type is specified, then the transform applies to all valid object types. The valid object types for each transform are shown in <a href="#BABEGHHB">Table 3-1</a>.</p>
<div id="SUTIL3245" class="tblformal">
<p class="titleintable"><a id="sthref313"></a><a id="BABEGHHB"></a>Table 3-1 Valid Object Types For the Data Pump Import TRANSFORM Parameter</p>
<table class="cellalignment1394" title="Valid Object Types For the Data Pump Import TRANSFORM Parameter" summary="Valid object types for Data Pump Import TRANSFORM parameter" dir="ltr">
<thead>
<tr class="cellalignment1388">
<th class="cellalignment1395" id="r1c1-t39"><br /></th>
<th class="cellalignment1395" id="r1c2-t39">SEGMENT_ATTRIBUTES</th>
<th class="cellalignment1395" id="r1c3-t39">STORAGE</th>
<th class="cellalignment1395" id="r1c4-t39">OID</th>
<th class="cellalignment1395" id="r1c5-t39">PCTSPACE</th>
<th class="cellalignment1395" id="r1c6-t39">SEGMENT_CREATION</th>
</tr>
</thead>
<tbody>
<tr class="cellalignment1388">
<td class="cellalignment1396" id="r2c1-t39" headers="r1c1-t39">
<p><code dir="ltr">CLUSTER</code></p>
</td>
<td class="cellalignment1396" headers="r2c1-t39 r1c2-t39">
<p>X</p>
</td>
<td class="cellalignment1396" headers="r2c1-t39 r1c3-t39">
<p>X</p>
</td>
<td class="cellalignment1396" headers="r2c1-t39 r1c4-t39">&nbsp;</td>
<td class="cellalignment1396" headers="r2c1-t39 r1c5-t39">
<p>X</p>
</td>
<td class="cellalignment1396" headers="r2c1-t39 r1c6-t39">&nbsp;</td>
</tr>
<tr class="cellalignment1388">
<td class="cellalignment1396" id="r3c1-t39" headers="r1c1-t39">
<p><code dir="ltr">CONSTRAINT</code></p>
</td>
<td class="cellalignment1396" headers="r3c1-t39 r1c2-t39">
<p>X</p>
</td>
<td class="cellalignment1396" headers="r3c1-t39 r1c3-t39">
<p>X</p>
</td>
<td class="cellalignment1396" headers="r3c1-t39 r1c4-t39">&nbsp;</td>
<td class="cellalignment1396" headers="r3c1-t39 r1c5-t39">
<p>X</p>
</td>
<td class="cellalignment1396" headers="r3c1-t39 r1c6-t39">&nbsp;</td>
</tr>
<tr class="cellalignment1388">
<td class="cellalignment1396" id="r4c1-t39" headers="r1c1-t39">
<p><code dir="ltr">INC_TYPE</code></p>
</td>
<td class="cellalignment1396" headers="r4c1-t39 r1c2-t39">&nbsp;</td>
<td class="cellalignment1396" headers="r4c1-t39 r1c3-t39">&nbsp;</td>
<td class="cellalignment1396" headers="r4c1-t39 r1c4-t39">
<p>X</p>
</td>
<td class="cellalignment1396" headers="r4c1-t39 r1c5-t39">&nbsp;</td>
<td class="cellalignment1396" headers="r4c1-t39 r1c6-t39">&nbsp;</td>
</tr>
<tr class="cellalignment1388">
<td class="cellalignment1396" id="r5c1-t39" headers="r1c1-t39">
<p><code dir="ltr">INDEX</code></p>
</td>
<td class="cellalignment1396" headers="r5c1-t39 r1c2-t39">
<p>X</p>
</td>
<td class="cellalignment1396" headers="r5c1-t39 r1c3-t39">
<p>X</p>
</td>
<td class="cellalignment1396" headers="r5c1-t39 r1c4-t39">&nbsp;</td>
<td class="cellalignment1396" headers="r5c1-t39 r1c5-t39">
<p>X</p>
</td>
<td class="cellalignment1396" headers="r5c1-t39 r1c6-t39">&nbsp;</td>
</tr>
<tr class="cellalignment1388">
<td class="cellalignment1396" id="r6c1-t39" headers="r1c1-t39">
<p><code dir="ltr">ROLLBACK_SEGMENT</code></p>
</td>
<td class="cellalignment1396" headers="r6c1-t39 r1c2-t39">
<p>X</p>
</td>
<td class="cellalignment1396" headers="r6c1-t39 r1c3-t39">
<p>X</p>
</td>
<td class="cellalignment1396" headers="r6c1-t39 r1c4-t39">&nbsp;</td>
<td class="cellalignment1396" headers="r6c1-t39 r1c5-t39">
<p>X</p>
</td>
<td class="cellalignment1396" headers="r6c1-t39 r1c6-t39">&nbsp;</td>
</tr>
<tr class="cellalignment1388">
<td class="cellalignment1396" id="r7c1-t39" headers="r1c1-t39">
<p><code dir="ltr">TABLE</code></p>
</td>
<td class="cellalignment1396" headers="r7c1-t39 r1c2-t39">
<p>X</p>
</td>
<td class="cellalignment1396" headers="r7c1-t39 r1c3-t39">
<p>X</p>
</td>
<td class="cellalignment1396" headers="r7c1-t39 r1c4-t39">
<p>X</p>
</td>
<td class="cellalignment1396" headers="r7c1-t39 r1c5-t39">
<p>X</p>
</td>
<td class="cellalignment1396" headers="r7c1-t39 r1c6-t39">
<p>X</p>
</td>
</tr>
<tr class="cellalignment1388">
<td class="cellalignment1396" id="r8c1-t39" headers="r1c1-t39">
<p><code dir="ltr">TABLESPACE</code></p>
</td>
<td class="cellalignment1396" headers="r8c1-t39 r1c2-t39">
<p>X</p>
</td>
<td class="cellalignment1396" headers="r8c1-t39 r1c3-t39">&nbsp;</td>
<td class="cellalignment1396" headers="r8c1-t39 r1c4-t39">&nbsp;</td>
<td class="cellalignment1396" headers="r8c1-t39 r1c5-t39">
<p>X</p>
</td>
<td class="cellalignment1396" headers="r8c1-t39 r1c6-t39">&nbsp;</td>
</tr>
<tr class="cellalignment1388">
<td class="cellalignment1396" id="r9c1-t39" headers="r1c1-t39">
<p><code dir="ltr">TYPE</code></p>
</td>
<td class="cellalignment1396" headers="r9c1-t39 r1c2-t39">&nbsp;</td>
<td class="cellalignment1396" headers="r9c1-t39 r1c3-t39">&nbsp;</td>
<td class="cellalignment1396" headers="r9c1-t39 r1c4-t39">
<p>X</p>
</td>
<td class="cellalignment1396" headers="r9c1-t39 r1c5-t39">&nbsp;</td>
<td class="cellalignment1396" headers="r9c1-t39 r1c6-t39">&nbsp;</td>
</tr>
</tbody>
</table>
<br /></div>
<!-- class="tblformal" -->
<p class="subhead1"><a id="SUTIL3246"></a>Example</p>
<p>For the following example, assume that you have exported the <code dir="ltr">employees</code> table in the <code dir="ltr">hr</code> schema. The SQL <code dir="ltr">CREATE</code> <code dir="ltr">TABLE</code> statement that results when you then import the table is similar to the following:</p>
<pre dir="ltr">
CREATE TABLE "HR"."EMPLOYEES" 
   ( "EMPLOYEE_ID" NUMBER(6,0), 
     "FIRST_NAME" VARCHAR2(20), 
     "LAST_NAME" VARCHAR2(25) CONSTRAINT "EMP_LAST_NAME_NN" NOT NULL ENABLE, 
     "EMAIL" VARCHAR2(25) CONSTRAINT "EMP_EMAIL_NN" NOT NULL ENABLE, 
     "PHONE_NUMBER" VARCHAR2(20), 
     "HIRE_DATE" DATE CONSTRAINT "EMP_HIRE_DATE_NN" NOT NULL ENABLE, 
     "JOB_ID" VARCHAR2(10) CONSTRAINT "EMP_JOB_NN" NOT NULL ENABLE, 
     "SALARY" NUMBER(8,2), 
     "COMMISSION_PCT" NUMBER(2,2), 
     "MANAGER_ID" NUMBER(6,0), 
     "DEPARTMENT_ID" NUMBER(4,0)
   ) PCTFREE 10 PCTUSED 40 INITRANS 1 MAXTRANS 255 NOCOMPRESS LOGGING
  STORAGE(INITIAL 10240 NEXT 16384 MINEXTENTS 1 MAXEXTENTS 121
  PCTINCREASE 50 FREELISTS 1 FREELIST GROUPS 1 BUFFER_POOL DEFAULT)
  TABLESPACE "SYSTEM" ;
</pre>
<p>If you do not want to retain the <code dir="ltr">STORAGE</code> clause or <code dir="ltr">TABLESPACE</code> clause, then you can remove them from the <code dir="ltr">CREATE</code> <code dir="ltr">STATEMENT</code> by using the Import <code dir="ltr">TRANSFORM</code> parameter. Specify the value of <code dir="ltr">SEGMENT_ATTRIBUTES</code> as <code dir="ltr">n</code>. This results in the exclusion of segment attributes (both storage and tablespace) from the table.</p>
<pre dir="ltr">
&gt; impdp hr TABLES=hr.employees DIRECTORY=dpump_dir1 DUMPFILE=hr_emp.dmp
  TRANSFORM=SEGMENT_ATTRIBUTES:n:table
</pre>
<p>The resulting <code dir="ltr">CREATE</code> <code dir="ltr">TABLE</code> statement for the <code dir="ltr">employees</code> table would then look similar to the following. It does not contain a <code dir="ltr">STORAGE</code> or <code dir="ltr">TABLESPACE</code> clause; the attributes for the default tablespace for the <code dir="ltr">HR</code> schema will be used instead.</p>
<pre dir="ltr">
CREATE TABLE "HR"."EMPLOYEES" 
   ( "EMPLOYEE_ID" NUMBER(6,0), 
     "FIRST_NAME" VARCHAR2(20), 
     "LAST_NAME" VARCHAR2(25) CONSTRAINT "EMP_LAST_NAME_NN" NOT NULL ENABLE, 
     "EMAIL" VARCHAR2(25) CONSTRAINT "EMP_EMAIL_NN" NOT NULL ENABLE, 
     "PHONE_NUMBER" VARCHAR2(20), 
     "HIRE_DATE" DATE CONSTRAINT "EMP_HIRE_DATE_NN" NOT NULL ENABLE, 
     "JOB_ID" VARCHAR2(10) CONSTRAINT "EMP_JOB_NN" NOT NULL ENABLE, 
     "SALARY" NUMBER(8,2), 
     "COMMISSION_PCT" NUMBER(2,2), 
     "MANAGER_ID" NUMBER(6,0), 
     "DEPARTMENT_ID" NUMBER(4,0)
   );
</pre>
<p>As shown in the previous example, the <code dir="ltr">SEGMENT_ATTRIBUTES</code> transform applies to both storage and tablespace attributes. To omit only the <code dir="ltr">STORAGE</code> clause and retain the <code dir="ltr">TABLESPACE</code> clause, you can use the <code dir="ltr">STORAGE</code> transform, as follows:</p>
<pre dir="ltr">
&gt; impdp hr TABLES=hr.employees DIRECTORY=dpump_dir1 DUMPFILE=hr_emp.dmp
  TRANSFORM=STORAGE:n:table
</pre>
<p>The <code dir="ltr">SEGMENT_ATTRIBUTES</code> and <code dir="ltr">STORAGE</code> transforms can be applied to all applicable table and index objects by not specifying the object type on the <code dir="ltr">TRANSFORM</code> parameter, as shown in the following command:</p>
<pre dir="ltr">
&gt; impdp hr DIRECTORY=dpump_dir1 DUMPFILE=hr.dmp SCHEMAS=hr TRANSFORM=SEGMENT_ATTRIBUTES:n
</pre></div>
<!-- class="sect2" -->
<a id="BABJIDCB"></a>
<div id="SUTIL940" class="sect2">
<h3 class="sect2">TRANSPORT_DATAFILES<a id="sthref314"></a></h3>
<p>Default: There is no default</p>
<p class="subhead1"><a id="SUTIL3247"></a>Purpose</p>
<p>Specifies a list of data files<a id="sthref315"></a> to be imported into the target database by a transportable-tablespace mode import, or by a table-mode import if <code dir="ltr">TRANSPORTABLE=ALWAYS</code> was set during the export. The data files must already exist on the target database system.</p>
<p class="subhead1"><a id="SUTIL3248"></a>Syntax and Description</p>
<pre dir="ltr">
TRANSPORT_DATAFILES=<span class="italic">datafile_name</span>
</pre>
<p>The <code dir="ltr"><span class="codeinlineitalic">datafile_name</span></code> must include an absolute directory path specification (<span class="italic">not</span> a directory object name) that is valid on the system where the target database resides.</p>
<p>At some point before the import operation, you must copy the data files from the source system to the target system. You can do this using any copy method supported by your operating stem. If desired, you can rename the files when you copy them to the target system (see <a href="#CIHCAHFB">Example 2</a>).</p>
<p>If you already have a dump file set generated by a transportable-tablespace mode export, then you can perform a transportable-mode import of that dump file, by specifying the dump file (which contains the metadata) and the <code dir="ltr">TRANSPORT_DATAFILES</code> parameter. The presence of the <code dir="ltr">TRANSPORT_DATAFILES</code> parameter tells import that it is a transportable-mode import and where to get the actual data.</p>
<p>Depending on your operating system, the use of quotation marks when you specify a value for this parameter may also require that you use escape characters. Oracle recommends that you place this parameter in a parameter file, which can reduce the number of escape characters that might otherwise be needed on the command line.</p>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<a href="#BEHECGCA">"Use of Quotation Marks On the Data Pump Command Line"</a></div>
<p class="subhead1"><a id="SUTIL3759"></a>Restrictions</p>
<ul>
<li>
<p>The <code dir="ltr">TRANSPORT_DATAFILES</code> parameter cannot be used in conjunction with the <code dir="ltr">QUERY</code> parameter.</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3249"></a>Example 1</p>
<p>The following is an example of using the <code dir="ltr">TRANSPORT_DATAFILES</code> parameter. Assume you have a parameter file, <code dir="ltr">trans_datafiles.par,</code> with the following content:</p>
<pre dir="ltr">
DIRECTORY=dpump_dir1
DUMPFILE=tts.dmp
TRANSPORT_DATAFILES='/user01/data/tbs1.dbf'
</pre>
<p>You can then issue the following command:</p>
<pre dir="ltr">
&gt; impdp hr PARFILE=trans_datafiles.par
</pre>
<p class="subhead1"><a id="CIHCAHFB"></a><a id="SUTIL3250"></a>Example 2</p>
<p>This example illustrates the renaming of data files as part of a transportable tablespace export and import operation. Assume that you have a data file named <code dir="ltr">employees.dat</code> on your source system.</p>
<ol>
<li>
<p>Using a method supported by your operating system, manually copy the data file named <code dir="ltr">employees.dat</code> from your source system to the system where your target database resides. As part of the copy operation, rename it to <code dir="ltr">workers.dat</code>.</p>
</li>
<li>
<p>Perform a transportable tablespace export of tablespace <code dir="ltr">tbs_1</code>.</p>
<pre dir="ltr">
&gt; expdp hr DIRECTORY=dpump_dir1 DUMPFILE=tts.dmp TRANSPORT_TABLESPACES=tbs_1
</pre>
<p>The metadata only (no data) for <code dir="ltr">tbs_1</code> is exported to a dump file named <code dir="ltr">tts.dmp</code>. The actual data was copied over to the target database in step 1.</p>
</li>
<li>
<p>Perform a transportable tablespace import, specifying an absolute directory path for the data file named <code dir="ltr">workers.dat</code>:</p>
<pre dir="ltr">
&gt; impdp hr DIRECTORY=dpump_dir1 DUMPFILE=tts.dmp
TRANSPORT_DATAFILES='/user01/data/workers.dat'
</pre>
<p>The metadata contained in <code dir="ltr">tts.dmp</code> is imported and Data Pump then assigns the information in the <code dir="ltr">workers.dat</code> file to the correct place in the database.</p>
</li>
</ol>
</div>
<!-- class="sect2" -->
<a id="i1007060"></a>
<div id="SUTIL941" class="sect2">
<h3 class="sect2">TRANSPORT_FULL_CHECK<a id="sthref316"></a></h3>
<p>Default: <code dir="ltr">NO</code></p>
<p class="subhead1"><a id="SUTIL3251"></a>Purpose</p>
<p>Specifies whether to verify that the specified transportable tablespace set is being referenced by objects in other tablespaces.</p>
<p class="subhead1"><a id="SUTIL3252"></a>Syntax and Description</p>
<pre dir="ltr">
TRANSPORT_FULL_CHECK=[YES | NO]
</pre>
<p>If <code dir="ltr">TRANSPORT_FULL_CHECK=</code><code dir="ltr">YES</code>, then <a id="sthref317"></a>Import verifies that there are no dependencies between those objects inside the transportable set and those outside the transportable set. The check addresses two-way dependencies. For example, if a table is inside the transportable set but its index is not, then a failure is returned and the import operation is terminated. Similarly, a failure is also returned if an index is in the transportable set but the table is not.</p>
<p>If <code dir="ltr">TRANSPORT_FULL_CHECK=NO</code><code dir="ltr">,</code> then Import verifies only that there are no objects within the transportable set that are dependent on objects outside the transportable set. This check addresses a one-way dependency. For example, a table is not dependent on an index, but an index <span class="italic">is</span> dependent on a table, because an index without a table has no meaning. Therefore, if the transportable set contains a table, but not its index, then this check succeeds. However, if the transportable set contains an index, but not the table, then the import operation is terminated.</p>
<p>In addition to this check, Import always verifies that all storage segments of all tables (and their indexes) defined within the tablespace set specified by <code dir="ltr">TRANSPORT_TABLESPACES</code> are actually contained within the tablespace set.</p>
<p class="subhead1"><a id="SUTIL3253"></a>Restrictions</p>
<ul>
<li>
<p>This parameter is valid for transportable mode (or table mode when <code dir="ltr">TRANSPORTABLE=ALWAYS</code> was specified on the export) only when the <code dir="ltr">NETWORK_LINK</code> parameter is specified.</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3254"></a>Example</p>
<p>In the following example, <code dir="ltr"><span class="codeinlineitalic">source_database_link</span></code> would be replaced with the name of a valid database link. The example also assumes that a data file named <code dir="ltr">tbs6.dbf</code> already exists.</p>
<p>Assume you have a parameter file, <code dir="ltr">full_check.par</code>, with the following content:</p>
<pre dir="ltr">
DIRECTORY=dpump_dir1
TRANSPORT_TABLESPACES=tbs_6
NETWORK_LINK=<span class="italic">source_database_link</span>
TRANSPORT_FULL_CHECK=YES
TRANSPORT_DATAFILES='/wkdir/data/tbs6.dbf'
</pre>
<p>You can then issue the following command:</p>
<pre dir="ltr">
&gt; impdp hr PARFILE=full_check.par
</pre></div>
<!-- class="sect2" -->
<a id="BEHFFDCD"></a>
<div id="SUTIL942" class="sect2">
<h3 class="sect2">TRANSPORT_TABLESPACES<a id="sthref318"></a></h3>
<p>Default: There is no default.</p>
<p class="subhead1"><a id="SUTIL3255"></a>Purpose</p>
<p>Specifies that you want to perform an import in transportable-tablespace mode over a database link (as specified with the <code dir="ltr">NETWORK_LINK</code> parameter.)</p>
<p class="subhead1"><a id="SUTIL3256"></a>Syntax and Description</p>
<pre dir="ltr">
TRANSPORT_TABLESPACES=<span class="italic">tablespace_name</span> [, ...]
</pre>
<p>Use the <code dir="ltr">TRANSPORT_TABLESPACES</code> parameter to specify a list of tablespace<a id="sthref319"></a> names for which object metadata will be imported from the source database into the target database.</p>
<p>Because this is a transportable-mode import, the tablespaces into which the data is imported are automatically created by Data Pump.You do not need to pre-create them. However, the data files should be copied to the target database before starting the import.</p>
<p>When you specify <code dir="ltr">TRANSPORT_TABLESPACES</code> on the import command line, you must also use the <code dir="ltr">NETWORK_LINK</code> parameter to specify a database link. A database link is a connection between two physical database servers that allows a client to access them as one logical database. Therefore, the <code dir="ltr">NETWORK_LINK</code> parameter is required because the object metadata is exported from the source (the database being pointed to by <code dir="ltr">NETWORK_LINK</code>) and then imported directly into the target (database from which the impdp command is issued), using that database link. There are no dump files involved in this situation. You would also need to specify the <code dir="ltr">TRANSPORT_DATAFILES</code> parameter to let the import know where to find the actual data, which had been copied to the target in a separate operation using some other means.</p>
<div class="infobox-note">
<p class="notep1">Note:</p>
If you already have a dump file set generated by a transportable-tablespace mode export, then you can perform a transportable-mode import of that dump file, but in this case you do not specify <code dir="ltr">TRANSPORT_TABLESPACES</code> or <code dir="ltr">NETWORK_LINK</code>. Doing so would result in an error. Rather, you specify the dump file (which contains the metadata) and the <code dir="ltr">TRANSPORT_DATAFILES</code> parameter. The presence of the <code dir="ltr">TRANSPORT_DATAFILES</code> parameter tells import that it's a transportable-mode import and where to get the actual data.</div>
<p>Depending on your operating system, the use of quotation marks when you specify a value for this parameter may also require that you use escape characters. Oracle recommends that you place this parameter in a parameter file, which can reduce the number of escape characters that might otherwise be needed on the command line.</p>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<ul>
<li>
<p><a class="olink ADMIN12083" href="../../server.112/e25494/ds_concepts.htm#ADMIN12083"><span class="italic">Oracle Database Administrator's Guide</span></a> for more information about database links</p>
</li>
<li>
<p><a href="#BEHDHCAF">"Considerations for Time Zone File Versions in Transportable Tablespace Mode"</a></p>
</li>
<li>
<p><a href="#BEHECGCA">"Use of Quotation Marks On the Data Pump Command Line"</a></p>
</li>
</ul>
</div>
<p class="subhead1"><a id="SUTIL3257"></a>Restrictions</p>
<ul>
<li>
<p>You cannot export transportable tablespaces and then import them into a database at a lower release level. The target database into which you are importing must be at the same or higher release level as the source database.</p>
</li>
<li>
<p>The <code dir="ltr">TRANSPORT_TABLESPACES</code> parameter is valid only when the <code dir="ltr">NETWORK_LINK</code> parameter is also specified.</p>
</li>
<li>
<p>Transportable mode does not support encrypted columns.</p>
</li>
<li>
<p>Transportable tablespace jobs do not support the <code dir="ltr">ACCESS_METHOD</code> parameter for Data Pump Import.</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3258"></a>Example</p>
<p>In the following example, the <code dir="ltr"><span class="codeinlineitalic">source_database_link</span></code> would be replaced with the name of a valid database link. The example also assumes that a data file named <code dir="ltr">tbs6.dbf</code> has already been copied from the source database to the local system. Suppose you have a parameter file, <code dir="ltr">tablespaces.par,</code> with the following content:</p>
<pre dir="ltr">
DIRECTORY=dpump_dir1
NETWORK_LINK=<span class="italic">source_database_link</span>
TRANSPORT_TABLESPACES=tbs_6
TRANSPORT_FULL_CHECK=NO
TRANSPORT_DATAFILES='user01/data/tbs6.dbf'
</pre>
<p>You can then issue the following command:</p>
<pre dir="ltr">
&gt; impdp hr PARFILE=tablespaces.par
</pre></div>
<!-- class="sect2" -->
<a id="BABIDIFA"></a>
<div id="SUTIL943" class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2">TRANSPORTABLE<a id="sthref320"></a><a id="sthref321"></a></h3>
<p>Default: <code dir="ltr">NEVER</code></p>
<p class="subhead1"><a id="SUTIL3259"></a>Purpose</p>
<p>Specifies whether the transportable option should be used during a table mode import (specified with the <code dir="ltr">TABLES</code> parameter) to import only metadata for specific tables, partitions, and subpartitions.</p>
<p class="subhead1"><a id="SUTIL3260"></a>Syntax and Description</p>
<pre dir="ltr">
TRANSPORTABLE = [ALWAYS | NEVER]
</pre>
<p>The definitions of the allowed values are as follows:</p>
<p><code dir="ltr">ALWAYS</code> - Instructs the import job to use the transportable option. If transportable is not possible, then the job will fail. The transportable option imports only metadata for the specified tables, partitions, or subpartitions specified by the <code dir="ltr">TABLES</code> parameter. You must copy the actual data files to the target database. See <a href="dp_overview.htm#CEGFEEJE">"Using Data File Copying to Move Data"</a>.</p>
<p><code dir="ltr">NEVER</code> - Instructs the import job to use either the direct path or external table method to load data rather than the transportable option. This is the default.</p>
<p>If only a subset of a table's partitions are imported and the <code dir="ltr">TRANSPORTABLE=ALWAYS</code> parameter is used, then each partition becomes a non-partitioned table.</p>
<p>If only a subset of a table's partitions are imported and the <code dir="ltr">TRANSPORTABLE</code> parameter is <span class="italic">not</span> used or is set to <code dir="ltr">NEVER</code> (the default), then:</p>
<ul>
<li>
<p>If <code dir="ltr">PARTITION_OPTIONS=DEPARTITION</code> is used, then each partition is created as a non-partitioned table.</p>
</li>
<li>
<p>If <code dir="ltr">PARTITION_OPTIONS</code> is <span class="italic">not</span> used, then the complete table is created. That is, all the metadata for the complete table is present so that the table definition looks the same on the target system as it did on the source. But only the data for the specified partitions is inserted into the table.</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3261"></a>Restrictions</p>
<ul>
<li>
<p>The Import <code dir="ltr">TRANSPORTABLE</code> parameter is valid only if the <code dir="ltr">NETWORK_LINK</code> parameter is also specified.</p>
</li>
<li>
<p>The <code dir="ltr">TRANSPORTABLE</code> parameter is only valid in table mode imports (the tables do not have to be partitioned or subpartitioned).</p>
</li>
<li>
<p>The user performing a transportable import requires the <code dir="ltr">DATAPUMP_EXP_FULL_DATABASE</code> role on the source database and the <code dir="ltr">DATAPUMP_IMP_FULL_DATABASE</code> role on the target database.</p>
</li>
<li>
<p>To make full use of the <code dir="ltr">TRANSPORTABLE</code> parameter, the <code dir="ltr">COMPATIBLE</code> initialization parameter must be set to at least 11.0.0.</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3262"></a>Example</p>
<p>The following example shows the use of the <code dir="ltr">TRANSPORTABLE</code> parameter during a network link import.</p>
<pre dir="ltr">
&gt; impdp system TABLES=hr.sales TRANSPORTABLE=ALWAYS
  DIRECTORY=dpump_dir1 NETWORK_LINK=dbs1 PARTITION_OPTIONS=DEPARTITION
  TRANSPORT_DATAFILES=<span class="italic">datafile_name</span> 
</pre></div>
<!-- class="sect2" -->
<a id="i1007382"></a>
<div id="SUTIL944" class="sect2">
<h3 class="sect2">VERSION<a id="sthref322"></a></h3>
<p>Default: <code dir="ltr">COMPATIBLE</code></p>
<p class="subhead1"><a id="SUTIL3263"></a>Purpose</p>
<p>Specifies the version<a id="sthref323"></a> of database objects to be imported (that is, only database objects and attributes that are compatible with the specified release will be imported). Note that this does <span class="italic">not</span> mean that Data Pump Import can be used with releases of Oracle Database earlier than 10.1. Data Pump Import only works with Oracle Database 10<span class="italic">g</span> release 1 (10.1) or later. The <code dir="ltr">VERSION</code> parameter simply allows you to identify the version of the objects being imported.</p>
<p class="subhead1"><a id="SUTIL3264"></a>Syntax and Description</p>
<pre dir="ltr">
VERSION=[COMPATIBLE | LATEST | <span class="italic">version_string</span>]
</pre>
<p>This parameter can be used to load a target system whose Oracle database is at an earlier compatibility release than that of the source system. Database objects or attributes on the source system that are incompatible with the specified release will not be moved to the target. For example, tables containing new datatypes that are not supported in the specified release will not be imported. Legal values for this parameter are as follows:</p>
<ul>
<li>
<p><code dir="ltr">COMPATIBLE</code> - This is the default value. The version of the metadata corresponds to the database compatibility level. Database compatibility must be set to 9.2.0 or higher.</p>
</li>
<li>
<p><code dir="ltr">LATEST</code> - The version of the metadata corresponds to the database release.</p>
</li>
<li>
<p><code dir="ltr"><span class="codeinlineitalic">version_string</span></code> - A specific database release (for example, 11.2.0). In Oracle Database 11<span class="italic">g,</span> this value must be 9.2.0 or higher.</p>
</li>
</ul>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<a href="dp_overview.htm#CEGFCFFI">"Moving Data Between Different Database Releases"</a></div>
<p class="subhead1"><a id="SUTIL3265"></a>Example</p>
<p>The following is an example of using the <code dir="ltr">VERSION</code> parameter. You can create the <code dir="ltr">expfull.dmp</code> dump file used in this example by running the example provided for the Export <code dir="ltr">FULL</code> parameter. See <a href="dp_export.htm#i1006790">"FULL"</a>.</p>
<pre dir="ltr">
&gt; impdp hr DIRECTORY=dpump_dir1 DUMPFILE=expfull.dmp TABLES=employees
VERSION=LATEST
</pre></div>
<!-- class="sect2" --></div>
<!-- class="sect1" -->
<a id="i1005692"></a>
<div id="SUTIL945" class="sect1">
<h2 class="sect1">Commands Available in Import's Interactive-Command Mode</h2>
<p>In interactive-command<a id="sthref324"></a> mode, the current job continues running, but logging to the terminal is suspended and the Import prompt (<code dir="ltr">Import&gt;</code>) is displayed.</p>
<p>To start interactive-command mode, do one of the following:</p>
<ul>
<li>
<p>From an attached client, press Ctrl+C.</p>
</li>
<li>
<p>From a terminal other than the one on which the job is running, use the <code dir="ltr">ATTACH</code> parameter to attach to the job. This is a useful feature in situations in which you start a job at one location and need to check on it at a later time from a different location.</p>
</li>
</ul>
<p><a href="#g1016776">Table 3-2</a> lists the activities you can perform for the current job from the Data Pump Import prompt in interactive-command mode.</p>
<div id="SUTIL3266" class="tblformal">
<p class="titleintable"><a id="sthref325"></a><a id="g1016776"></a>Table 3-2 Supported Activities in Data Pump Import's Interactive-Command Mode</p>
<table class="cellalignment1394" title="Supported Activities in Data Pump Import's Interactive-Command Mode" summary="Commands for Data Pump Import interactive mode" dir="ltr">
<thead>
<tr class="cellalignment1388">
<th class="cellalignment1395" id="r1c1-t44">Activity</th>
<th class="cellalignment1395" id="r1c2-t44">Command Used</th>
</tr>
</thead>
<tbody>
<tr class="cellalignment1388">
<td class="cellalignment1396" id="r2c1-t44" headers="r1c1-t44">
<p>Exit interactive-command mode.</p>
</td>
<td class="cellalignment1396" headers="r2c1-t44 r1c2-t44">
<p><a href="#i1007515">CONTINUE_CLIENT</a></p>
</td>
</tr>
<tr class="cellalignment1388">
<td class="cellalignment1396" id="r3c1-t44" headers="r1c1-t44">
<p>Stop the import client session, but leave the current job running.</p>
</td>
<td class="cellalignment1396" headers="r3c1-t44 r1c2-t44">
<p><a href="#BABBHHBG">EXIT_CLIENT</a></p>
</td>
</tr>
<tr class="cellalignment1388">
<td class="cellalignment1396" id="r4c1-t44" headers="r1c1-t44">
<p>Display a summary of available commands.</p>
</td>
<td class="cellalignment1396" headers="r4c1-t44 r1c2-t44">
<p><a href="#i1007523">HELP</a></p>
</td>
</tr>
<tr class="cellalignment1388">
<td class="cellalignment1396" id="r5c1-t44" headers="r1c1-t44">
<p>Detach all currently attached client sessions and terminate the current job.</p>
</td>
<td class="cellalignment1396" headers="r5c1-t44 r1c2-t44">
<p><a href="#i1007527">KILL_JOB</a></p>
</td>
</tr>
<tr class="cellalignment1388">
<td class="cellalignment1396" id="r6c1-t44" headers="r1c1-t44">
<p>Increase or decrease the number of active worker processes for the current job. This command is valid only in Oracle Database Enterprise Edition.</p>
</td>
<td class="cellalignment1396" headers="r6c1-t44 r1c2-t44">
<p><a href="#i1007531">PARALLEL</a></p>
</td>
</tr>
<tr class="cellalignment1388">
<td class="cellalignment1396" id="r7c1-t44" headers="r1c1-t44">
<p>Restart a stopped job to which you are attached.</p>
</td>
<td class="cellalignment1396" headers="r7c1-t44 r1c2-t44">
<p><a href="#i1007535">START_JOB</a></p>
</td>
</tr>
<tr class="cellalignment1388">
<td class="cellalignment1396" id="r8c1-t44" headers="r1c1-t44">
<p>Display detailed status for the current job.</p>
</td>
<td class="cellalignment1396" headers="r8c1-t44 r1c2-t44">
<p><a href="#i1007539">STATUS</a></p>
</td>
</tr>
<tr class="cellalignment1388">
<td class="cellalignment1396" id="r9c1-t44" headers="r1c1-t44">
<p>Stop the current job.</p>
</td>
<td class="cellalignment1396" headers="r9c1-t44 r1c2-t44">
<p><a href="#i1007543">STOP_JOB</a></p>
</td>
</tr>
</tbody>
</table>
<br /></div>
<!-- class="tblformal" -->
<p>The following are descriptions of the commands available in the interactive-command mode of Data Pump Import.</p>
<a id="i1007515"></a>
<div id="SUTIL946" class="sect2">
<h3 class="sect2">CONTINUE_CLIENT<a id="sthref326"></a></h3>
<p class="subhead1"><a id="SUTIL3267"></a>Purpose</p>
<p>Changes<a id="sthref327"></a> the mode from interactive-command mode to logging mode.</p>
<p class="subhead1"><a id="SUTIL3268"></a>Syntax and Description</p>
<pre dir="ltr">
CONTINUE_CLIENT
</pre>
<p>In logging mode, the job status is continually output to the terminal. If the job is currently stopped, then <code dir="ltr">CONTINUE_CLIENT</code> will also cause the client to attempt to start the job.</p>
<p class="subhead1"><a id="SUTIL3269"></a>Example</p>
<pre dir="ltr">
Import&gt; CONTINUE_CLIENT
</pre></div>
<!-- class="sect2" -->
<a id="BABBHHBG"></a>
<div id="SUTIL947" class="sect2">
<h3 class="sect2">EXIT_CLIENT<a id="sthref328"></a></h3>
<p class="subhead1"><a id="SUTIL3270"></a>Purpose</p>
<p>Stops the import client session, exits Import,<a id="sthref329"></a> and discontinues logging to the terminal, but leaves the current job running.</p>
<p class="subhead1"><a id="SUTIL3271"></a>Syntax and Description</p>
<pre dir="ltr">
EXIT_CLIENT
</pre>
<p>Because <code dir="ltr">EXIT_CLIENT</code> leaves the job running, you can attach to the job at a later time if it is still executing or in a stopped state. To see the status of the job, you can monitor the log file for the job or you can query the <code dir="ltr">USER_DATAPUMP_JOBS</code> view or the <code dir="ltr">V$SESSION_LONGOPS</code> view.</p>
<p class="subhead1"><a id="SUTIL3272"></a>Example</p>
<pre dir="ltr">
Import&gt; EXIT_CLIENT
</pre></div>
<!-- class="sect2" -->
<a id="i1007523"></a>
<div id="SUTIL948" class="sect2">
<h3 class="sect2">HELP<a id="sthref330"></a></h3>
<p class="subhead1"><a id="SUTIL3273"></a>Purpose</p>
<p>Provides information about <a id="sthref331"></a>Data Pump Import commands<a id="sthref332"></a> available in interactive-command mode.</p>
<p class="subhead1"><a id="SUTIL3274"></a>Syntax and Description</p>
<pre dir="ltr">
HELP
</pre>
<p>Displays information about the commands available in interactive-command mode.</p>
<p class="subhead1"><a id="SUTIL3275"></a>Example</p>
<pre dir="ltr">
Import&gt; HELP
</pre></div>
<!-- class="sect2" -->
<a id="i1007527"></a>
<div id="SUTIL949" class="sect2">
<h3 class="sect2">KILL_JOB<a id="sthref333"></a></h3>
<p class="subhead1"><a id="SUTIL3276"></a>Purpose</p>
<p>Detaches all currently attached client<a id="sthref334"></a> sessions and then terminates the current job. It exits Import and returns to the terminal prompt.</p>
<p class="subhead1"><a id="SUTIL3277"></a>Syntax and Description</p>
<pre dir="ltr">
KILL_JOB
</pre>
<p>A job that is terminated using <code dir="ltr">KILL_JOB</code> cannot be restarted. All attached clients, including the one issuing the <code dir="ltr">KILL_JOB</code> command, receive a warning that the job is being terminated by the current user and are then detached. After all clients are detached, the job's process structure is immediately run down and the master table and dump files are deleted. Log files are not deleted.</p>
<p class="subhead1"><a id="SUTIL3278"></a>Example</p>
<pre dir="ltr">
Import&gt; KILL_JOB
</pre></div>
<!-- class="sect2" -->
<a id="i1007531"></a>
<div id="SUTIL950" class="sect2">
<h3 class="sect2">PARALLEL<a id="sthref335"></a></h3>
<p class="subhead1"><a id="SUTIL3279"></a>Purpose</p>
<p>Enables you to increase or decrease the number of active worker processes and/or PQ slaves for the current job.</p>
<p class="subhead1"><a id="SUTIL3280"></a>Syntax and Description</p>
<pre dir="ltr">
PARALLEL=<span class="italic">integer</span>
</pre>
<p><code dir="ltr">PARALLEL<a id="sthref336"></a></code> is available as both a command-line parameter and an interactive-mode parameter. You set it to the desired number of parallel processes. An increase takes effect immediately if there are enough resources and if there is enough work requiring parallelization. A decrease does not take effect until an existing process finishes its current task. If the integer value is decreased, then workers are idled but not deleted until the job exits.</p>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<a href="#i1006596">"PARALLEL"</a> for more information about parallelism</div>
<p class="subhead1"><a id="SUTIL3281"></a>Restrictions</p>
<ul>
<li>
<p>This parameter is valid only in the Enterprise Edition of Oracle Database 11<span class="italic">g</span>.</p>
</li>
</ul>
<p class="subhead1"><a id="SUTIL3282"></a>Example</p>
<pre dir="ltr">
Import&gt; PARALLEL=10
</pre></div>
<!-- class="sect2" -->
<a id="i1007535"></a>
<div id="SUTIL951" class="sect2">
<h3 class="sect2">START_JOB<a id="sthref337"></a></h3>
<p class="subhead1"><a id="SUTIL3283"></a>Purpose</p>
<p>Starts<a id="sthref338"></a> the current job to which you are attached.</p>
<p class="subhead1"><a id="SUTIL3284"></a>Syntax and Description</p>
<pre dir="ltr">
START_JOB[=SKIP_CURRENT=YES]
</pre>
<p>The <code dir="ltr">START_JOB</code> command restarts the job to which you are currently attached (the job cannot be currently executing). The job is restarted with no data loss or corruption after an unexpected failure or after you issue a <code dir="ltr">STOP_JOB</code> command, provided the dump file set and master table remain undisturbed.</p>
<p>The <code dir="ltr">SKIP_CURRENT</code> option allows you to restart a job that previously failed to restart because execution of some DDL statement failed. The failing statement is skipped and the job is restarted from the next work item.</p>
<p>Neither SQLFILE jobs nor imports done in transportable-tablespace mode are restartable.</p>
<p class="subhead1"><a id="SUTIL3285"></a>Example</p>
<pre dir="ltr">
Import&gt; START_JOB
</pre></div>
<!-- class="sect2" -->
<a id="i1007539"></a>
<div id="SUTIL952" class="sect2">
<h3 class="sect2">STATUS<a id="sthref339"></a></h3>
<p class="subhead1"><a id="SUTIL3286"></a>Purpose</p>
<p>Displays<a id="sthref340"></a> cumulative status of the job, a description of the current operation, and an estimated completion percentage. It also allows you to reset the display interval for logging mode status.</p>
<p class="subhead1"><a id="SUTIL3287"></a>Syntax and Description</p>
<pre dir="ltr">
STATUS[=i<span class="italic">nteger</span>]
</pre>
<p>You have the option of specifying how frequently, in seconds, this status should be displayed in logging mode. If no value is entered or if the default value of <code dir="ltr">0</code> is used, then the periodic status display is turned off and status is displayed only once.</p>
<p>This status information is written only to your standard output device, not to the log file (even if one is in effect).</p>
<p class="subhead1"><a id="SUTIL3288"></a>Example</p>
<p>The following example will display the current job status and change the logging mode display interval to two minutes (120 seconds).</p>
<pre dir="ltr">
Import&gt; STATUS=120
</pre></div>
<!-- class="sect2" -->
<a id="i1007543"></a>
<div id="SUTIL953" class="sect2">
<h3 class="sect2">STOP_JOB<a id="sthref341"></a><a id="sthref342"></a></h3>
<p class="subhead1"><a id="SUTIL3289"></a>Purpose</p>
<p>Stops<a id="sthref343"></a> the current job either immediately or after an orderly shutdown, and exits Import.</p>
<p class="subhead1"><a id="SUTIL3290"></a>Syntax and Description</p>
<pre dir="ltr">
STOP_JOB[=IMMEDIATE]
</pre>
<p>If the master table and dump file set are not disturbed when or after the <code dir="ltr">STOP_JOB</code> command is issued, then the job can be attached to and restarted at a later time with the <code dir="ltr">START_JOB</code> command.</p>
<p>To perform an orderly shutdown, use <code dir="ltr">STOP_JOB</code> (without any associated value). A warning requiring confirmation will be issued. An orderly shutdown stops the job after worker processes have finished their current tasks.</p>
<p>To perform an immediate shutdown, specify <code dir="ltr">STOP_JOB</code>=<code dir="ltr">IMMEDIATE</code>. A warning requiring confirmation will be issued. All attached clients, including the one issuing the <code dir="ltr">STOP_JOB</code> command, receive a warning that the job is being stopped by the current user and they will be detached. After all clients are detached, the process structure of the job is immediately run down. That is, the master process will not wait for the worker processes to finish their current tasks. There is no risk of corruption or data loss when you specify <code dir="ltr">STOP_JOB=IMMEDIATE</code>. However, some tasks that were incomplete at the time of shutdown may have to be redone at restart time.</p>
<p class="subhead1"><a id="SUTIL3291"></a>Example</p>
<pre dir="ltr">
Import&gt; STOP_JOB=IMMEDIATE
</pre></div>
<!-- class="sect2" --></div>
<!-- class="sect1" -->
<a id="i1006564"></a>
<div id="SUTIL954" class="sect1">
<h2 class="sect1">Examples of Using Data Pump Import</h2>
<p>This section provides examples of the following ways in which you might use Data Pump Import:</p>
<ul>
<li>
<p><a href="#i1009064">Performing a Data-Only Table-Mode Import</a></p>
</li>
<li>
<p><a href="#i1009093">Performing a Schema-Mode Import</a></p>
</li>
<li>
<p><a href="#i1006584">Performing a Network-Mode Import</a></p>
</li>
</ul>
<p>For information that will help you to successfully use these examples, see <a href="#BEHFGIGF">"Using the Import Parameter Examples"</a>.</p>
<a id="i1008875"></a>
<div id="SUTIL955" class="sect2">
<h3 class="sect2">Performing a Data-Only Table-Mode Import</h3>
<p><a href="#i1009064">Example 3-1</a> shows how to perform a data-only table-mode import of the table named <code dir="ltr">employees</code>. It uses the dump file created in <a href="dp_export.htm#BEHJGFEJ">Example 2-1</a>.</p>
<div id="SUTIL3292" class="example">
<p class="titleinexample"><a id="i1009064"></a>Example 3-1 Performing a Data-Only Table-Mode Import</p>
<pre dir="ltr">
&gt; impdp hr TABLES=employees CONTENT=DATA_ONLY DUMPFILE=dpump_dir1:table.dmp
NOLOGFILE=YES
</pre></div>
<!-- class="example" -->
<p>The <code dir="ltr">CONTENT=DATA_ONLY</code> parameter filters out any database object definitions (metadata). Only table row data is loaded.</p>
</div>
<!-- class="sect2" -->
<a id="i1011133"></a>
<div id="SUTIL956" class="sect2">
<h3 class="sect2">Performing a Schema-Mode Import</h3>
<p><a href="#i1009093">Example 3-2</a> shows a schema-mode import of the dump file set created in <a href="dp_export.htm#BEHFJEJD">Example 2-4</a>.</p>
<div id="SUTIL3293" class="example">
<p class="titleinexample"><a id="i1009093"></a>Example 3-2 Performing a Schema-Mode Import</p>
<pre dir="ltr">
&gt; impdp hr SCHEMAS=hr DIRECTORY=dpump_dir1 DUMPFILE=expschema.dmp
 EXCLUDE=CONSTRAINT,REF_CONSTRAINT,INDEX TABLE_EXISTS_ACTION=REPLACE
</pre>
<p>The <code dir="ltr">EXCLUDE</code> parameter filters the metadata that is imported. For the given mode of import, all the objects contained within the source, and all their dependent objects, are included except those specified in an <code dir="ltr">EXCLUDE</code> statement. If an object is excluded, then all of its dependent objects are also excluded.The <code dir="ltr">TABLE_EXISTS_ACTION=REPLACE</code> parameter tells Import to drop the table if it already exists and to then re-create and load it using the dump file contents.</p>
</div>
<!-- class="example" --></div>
<!-- class="sect2" -->
<a id="i1006584"></a>
<div id="SUTIL957" class="sect2">
<h3 class="sect2">Performing a Network-Mode Import</h3>
<p><a href="#i1009129">Example 3-3</a> performs a network-mode import where the source is the database specified by the <code dir="ltr">NETWORK_LINK</code> parameter.</p>
<div id="SUTIL3294" class="example">
<p class="titleinexample"><a id="i1009129"></a>Example 3-3 Network-Mode Import of Schemas</p>
<pre dir="ltr">
&gt; impdp hr TABLES=employees REMAP_SCHEMA=hr:scott DIRECTORY=dpump_dir1
NETWORK_LINK=dblink
</pre>
<p>This example imports the <code dir="ltr">employees</code> table from the <code dir="ltr">hr</code> schema into the <code dir="ltr">scott</code> schema. The <code dir="ltr">dblink</code> references a source database that is different than the target database.</p>
<p>To remap the schema, user <code dir="ltr">hr</code> must have the <code dir="ltr">DATAPUMP_IMP_FULL_DATABASE</code> role on the local database and the <code dir="ltr">DATAPUMP_EXP_FULL_DATABASE</code> role on the source database.</p>
<p><code dir="ltr">REMAP_SCHEMA</code> loads all the objects from the source schema into the target schema.</p>
</div>
<!-- class="example" -->
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<a href="#i1007380">"NETWORK_LINK"</a> for more information about database links</div>
</div>
<!-- class="sect2" --></div>
<!-- class="sect1" -->
<a id="BEHIBGEC"></a>
<div id="SUTIL958" class="sect1"><!-- infolevel="all" infotype="General" -->
<h2 class="sect1">Syntax Diagrams for Data Pump Import<a id="sthref344"></a><a id="sthref345"></a></h2>
<p>This section provides syntax diagrams for Data Pump Import. These diagrams use standard SQL syntax notation. For more information about SQL syntax notation, see <a class="olink SQLRF018" href="../../server.112/e41084/ap_syntx.htm#SQLRF018"><span class="italic">Oracle Database SQL Language Reference</span></a>.</p>
<p class="subhead1"><a id="SUTIL3295"></a>ImpInit</p>
<img width="716" height="110" src="img/impinit.gif" alt="Description of impinit.gif follows" /><br />
<a id="sthref346" href="img_text/impinit.htm">Description of the illustration ''impinit.gif''</a><br />
<br />
<p class="subhead1"><a id="SUTIL3296"></a>ImpStart</p>
<img width="781" height="98" src="img/impstart.gif" alt="Description of impstart.gif follows" /><br />
<a id="sthref347" href="img_text/impstart.htm">Description of the illustration ''impstart.gif''</a><br />
<br />
<p class="subhead1"><a id="SUTIL3297"></a>ImpModes</p>
<img width="669" height="282" src="img/impmodes.gif" alt="Description of impmodes.gif follows" /><br />
<a id="sthref348" href="img_text/impmodes.htm">Description of the illustration ''impmodes.gif''</a><br />
<br />
<p class="subhead1"><a id="SUTIL3298"></a>ImpOpts</p>
<img width="723" height="1182" src="img/impopts.gif" alt="Description of impopts.gif follows" /><br />
<a id="sthref349" href="img_text/impopts.htm">Description of the illustration ''impopts.gif''</a><br />
<br />
<p class="subhead1"><a id="SUTIL3299"></a>ImpFilter</p>
<img width="690" height="218" src="img/impfilter.gif" alt="Description of impfilter.gif follows" /><br />
<a id="sthref350" href="img_text/impfilter.htm">Description of the illustration ''impfilter.gif''</a><br />
<br />
<p class="subhead1"><a id="SUTIL3300"></a>ImpRacOpt</p>
<img width="341" height="102" src="img/impracopt.gif" alt="Description of impracopt.gif follows" /><br />
<a id="sthref351" href="img_text/impracopt.htm">Description of the illustration ''impracopt.gif''</a><br />
<br />
<p class="subhead1"><a id="SUTIL3301"></a>ImpRemap</p>
<img width="937" height="265" src="img/impremap.gif" alt="Description of impremap.gif follows" /><br />
<a id="sthref352" href="img_text/impremap.htm">Description of the illustration ''impremap.gif''</a><br />
<br />
<p class="subhead1"><a id="SUTIL3302"></a>ImpFileOpts</p>
<img width="564" height="386" src="img/impfileopts.gif" alt="Description of impfileopts.gif follows" /><br />
<a id="sthref353" href="img_text/impfileopts.htm">Description of the illustration ''impfileopts.gif''</a><br />
<br />
<p class="subhead1"><a id="SUTIL3303"></a>ImpNetworkOpts</p>
<img width="897" height="340" src="img/impnetopts.gif" alt="Description of impnetopts.gif follows" /><br />
<a id="sthref354" href="img_text/impnetopts.htm">Description of the illustration ''impnetopts.gif''</a><br />
<br />
<p class="subhead1"><a id="SUTIL3304"></a>ImpDynOpts</p>
<img width="525" height="367" src="img/impdynopts.gif" alt="Description of impdynopts.gif follows" /><br />
<a id="sthref355" href="img_text/impdynopts.htm">Description of the illustration ''impdynopts.gif''</a><br />
<br />
<p class="subhead1"><a id="SUTIL3882"></a>ImpDiagnostics</p>
<img width="449" height="371" src="img/impdiagnostics.gif" alt="Description of impdiagnostics.gif follows" /><br />
<a id="sthref356" href="img_text/impdiagnostics.htm">Description of the illustration ''impdiagnostics.gif''</a><br />
<br /></div>
<!-- class="sect1" --></div>
<!-- class="chapter" --></div>
<!-- class="ind" -->
<!-- Start Footer -->
</div>
<!-- add extra wrapper close div-->
<footer><!--
<hr />
<table class="cellalignment1387">
<tr>
<td class="cellalignment1396">
<table class="cellalignment1392">
<tr>
<td class="cellalignment1391"><a href="dp_export.htm"><img width="24" height="24" src="../../dcommon/gifs/leftnav.gif" alt="Go to previous page" /><br />
<span class="icon">Previous</span></a></td>
<td class="cellalignment1391"><a href="dp_legacy.htm"><img width="24" height="24" src="../../dcommon/gifs/rightnav.gif" alt="Go to next page" /><br />
<span class="icon">Next</span></a></td>
</tr>
</table>
</td>
<td class="cellalignment-copyrightlogo"><img width="144" height="18" src="../../dcommon/gifs/oracle.gif" alt="Oracle" /><br />
Copyright&nbsp;&copy;&nbsp;1996, 2018,&nbsp;Oracle&nbsp;and/or&nbsp;its&nbsp;affiliates.&nbsp;All&nbsp;rights&nbsp;reserved.<br />
<a href="../../dcommon/html/cpyr.htm">Legal Notices</a></td>
<td class="cellalignment1398">
<table class="cellalignment1390">
<tr>
<td class="cellalignment1391"><a href="../../index.htm"><img width="24" height="24" src="../../dcommon/gifs/doclib.gif" alt="Go to Documentation Home" /><br />
<span class="icon">Home</span></a></td>
<td class="cellalignment1391"><a href="../../nav/portal_booklist.htm"><img width="24" height="24" src="../../dcommon/gifs/booklist.gif" alt="Go to Book List" /><br />
<span class="icon">Book List</span></a></td>
<td class="cellalignment1391"><a href="toc.htm"><img width="24" height="24" src="../../dcommon/gifs/toc.gif" alt="Go to Table of Contents" /><br />
<span class="icon">Contents</span></a></td>
<td class="cellalignment1391"><a href="index.htm"><img width="24" height="24" src="../../dcommon/gifs/index.gif" alt="Go to Index" /><br />
<span class="icon">Index</span></a></td>
<td class="cellalignment1391"><a href="../../nav/mindx.htm"><img width="24" height="24" src="../../dcommon/gifs/masterix.gif" alt="Go to Master Index" /><br />
<span class="icon">Master Index</span></a></td>
<td class="cellalignment1391"><a href="../../dcommon/html/feedback.htm"><img width="24" height="24" src="../../dcommon/gifs/feedbck2.gif" alt="Go to Feedback page" /><br />
<span class="icon">Contact Us</span></a></td>
</tr>
</table>
</td>
</tr>
</table>
--></footer>
<noscript>
<p>Scripting on this page enhances content navigation, but does not change the content in any way.</p>
</noscript>
</body>
</html>
